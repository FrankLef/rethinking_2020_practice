```{r include=FALSE}
library(rethinking)
library(brms)
library(tidyr)
library(dplyr)
library(ggplot2)
library(paletteer)
library(bayesplot)
```


# Multilevel Models {#MLM}



## Example: Multilevel tadpoles

```{r}
data(reedfrogs)
d <- reedfrogs %>%
  mutate(tank = seq_len(nrow(.)),
         tank = factor(tank))
glimpse(d)
```

### Example: Multilevel tadpoles - Simple

and the model, without multilevel effect, is

$$
surv_i \sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) = \alpha_{tank[i]} \\
\alpha_{tank} \sim \mathcal{N}(0, 5)
$$

and we fit this

```{r}
a_file <- here::here("fits", "b12_01.rds")  # rds file location
stopifnot(file.exists(a_file))
b12.1 <- readRDS(file = a_file)  # load the file
# b12.1 <- brm(
#   data = d,
#   family = binomial,
#   surv | trials(density) ~ 0 + tank,
#   prior = c(prior(normal(0, 5), class = b)),
#   iter = 2000, warmup = 500, chains = 4, cores = 4,
#   seed = 12)
# b12.1 <- add_criterion(b12.1, c("loo", "waic"))
# saveRDS(object = b12.1, file = a_file)
```

which gives this summary

```{r}
# summary(b12.1)
```

and visualize the intercepts which correxponds to the logit of the probabilities.

We create the data set

```{r}
pdf <- fixef(b12.1) %>%
  as.data.frame() %>%
  select(Estimate) %>%
  mutate(p = stats::plogis(Estimate)) %>%
  pivot_longer(cols = c("Estimate", "p"), names_to = "key") %>%
  mutate(key = if_else(key == "p", "exp_surv_prob", "exp_surv_log-odds"))
pdf
```

and then the plots

```{r}
p <- ggplot(pdf, aes(x = value, fill = key)) +
  geom_density(stat = "density", color = "transparent") +
  scale_y_continuous(breaks = NULL) +
  scale_fill_manual(values = c("violet", "lightcoral")) +
  ggthemes::theme_fivethirtyeight() +
  theme(legend.position = "none",
        panel.grid.major = element_blank()) +
  facet_wrap(~ key, scales = "free")
p
```



### Example: Multilevel tadpoles - Multilevel

and now the multilevel model

$$
surv_i \sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) = \alpha_{tank[i]} \\
\alpha_{tank} \sim \mathcal{N}(0, 5) \\
\alpha \sim \mathcal{N}(0, 1) \\
\sigma \sim \mathcal{HalfCauchy}(0, 1)
$$

and the fit is as follows.  Note the prior `prior(cauchy(0, 1), class = sd)`
*which is parametrized in the standard deviation metric* (Kurtz). It is common
for multilevel software to model the variance metric.  This will be further
explained in chapter 13.


```{r}
a_file <- here::here("fits", "b12_02.rds")  # rds file location
stopifnot(file.exists(a_file))
b12.2 <- readRDS(file = a_file)  # load the file
# b12.2 <- brm(
#   data = d,
#   family = binomial,
#   surv | trials(density) ~ 1 + (1 | tank),
#   prior = c(prior(normal(0, 1), class = Intercept),
#             prior(cauchy(0, 1), class = sd)),
#   iter = 4000, warmup = 1000, chains = 4, cores = 4,
#   seed = 12)
# b12.2 <- add_criterion(b12.2, c("loo", "waic"))
# saveRDS(object = b12.2, file = a_file)
```



### Example: Multilevel tadpoles - Comparison

and compare the models

```{r}
w <- loo_compare(b12.1, b12.2, criterion = "waic") %>%
  as.data.frame() %>%
  mutate(waic_diff = elpd_diff * -2,
         waic_diff_se = se_diff * 2)
w
print(w[, c("elpd_diff", "se_diff","waic_diff", "waic_diff_se")], simplify = FALSE)
print(w[, c("elpd_waic", "se_elpd_waic","waic", "se_waic")], simplify = FALSE)
```

```{r}
model_weights(b12.1, b12.2, weights = "waic")
```

> The results above are different than those of McElrath and Kurtz.  
They are close however, I ran the fit several times and cannot find the difference.
The difference might be caused by the fact that McElrath uses a `tank` value that
is an integer. Kurtz uses a factor for b12.1 but an integer for b12.3.
I use a factor for both b12.1 and b12.3 which is more consistent with the fact
that the `tank` value is an id, and should not be seen as an integer.



### Example: Multilevel tadpoles - Posterior distribution


This time we don't have a list of intercepts.  We have the estimates of p and
will use the posterior sample for that. The `bpost12.2` consists of 12 000 rows
which is 3 chains with 3000 rows each, that is 4000 iterations less 1000 for warmup.

The code from Kurtz is succint and now necessarily easy to follow.  McElrath
is even horter.  Below is a detailed explanation of what is being done.

```{r}
bpost12.2 <- posterior_samples(b12.2, add_chain = TRUE)
# glimpse(bpost12.2)
```


we note that the range of logodds is between -2 and 3.5

```{r}
# we use the stats::qlogis() and brms::logit()
# once more to show they are the same
t <- d %>%
  mutate(propsurv_logodd = qlogis(propsurv),
         propsurv_logodd_brms = logit(propsurv))
t
range(t$propsurv_logodd[is.finite(t$propsurv_logodd)])

```

First, we take a sampling of size 100 of the 3000 iterations from the posterior
sample with `slice_sample(n = 100)`.

Second, to simulate the **distribution** of the logodds values described by the 
`b_Intercept` and `tank_Intercepts` of **each iteration** we create a 
sequence of 100 logodds values between -4 and 5 
(based on the acutal range of -2, 3.5 shown just above)
which is done by 
`expand(nesting(iter, b_Intercept, sd_tank__Intercept), x = seq(from = -4, to = 5, length.out = 100))`
and which will result in 10000 lines.

Third, we compute the normal density for each of the 10000 lines using the
`b_Intercept` and `tank_Intercepts` of each line.  The normal density is used
because the model is $\alpha_{tank} \sim \mathcal{N}(0, 5)$ and
$\alpha \sim \mathcal{N}(0, 1)$.  This is done with


```{r}
set.seed(12)
bpost12.2_dist <- bpost12.2 %>%
  slice_sample(n = 100) %>%
  expand(nesting(iter, b_Intercept, sd_tank__Intercept),
         x = seq(from = -4, to = 5, length.out = 100)) %>%
  mutate(dens = dnorm(x, mean = b_Intercept, sd = sd_tank__Intercept))
stopifnot(nrow(bpost12.2_dist)==10000)
```

which gives this plot

```{r}
p1 <- ggplot(bpost12.2_dist, aes(x = x, y = dens, group = iter)) +
  geom_line(color = "orange") +
  scale_x_continuous(breaks = scales::breaks_width(width = 1)) +
  scale_y_continuous(breaks = scales::breaks_width(width = 0.05)) +
  coord_cartesian(xlim = c(-3, 4)) +
  ggthemes::theme_fivethirtyeight() +
  theme(legend.position = "none") +
  labs(title = "Population survival distribution",
       subtitle = "log-odds scale", x = "log odds", y = "probability")
p1
```
and to simulate the probability of **survival rate** we simply use the posterir
results as parameters for `rnorm()` as follows

```{r}
# we compue both plogis and inv_logit_scaled to show they are the same
# plogis is better, from the stats package which is base R
bpost12.2_surv <- bpost12.2 %>%
  mutate(logodd_surv = rnorm(n = nrow(bpost12.2), 
                                 mean = bpost12.2$b_Intercept,
                                 sd = bpost12.2$sd_tank__Intercept),
         surv = plogis(logodd_surv),
         surv_brms = inv_logit_scaled(logodd_surv))
stopifnot(nrow(bpost12.2_surv)==nrow(bpost12.2))
```

which we plot as follows

```{r}
p2 <- ggplot(bpost12.2_surv, aes(x = surv)) +
  geom_density(aes(y = ..scaled..),stat = "density", fill = "orange", color = "transparent") +
  theme_light() +
  labs(title = "Probability of survival",
       subtitle = "", x = "survival rate", y = "prob of the survival rate")
p2
```



## Varying effects


### The model



$$
surv_i \sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) = \alpha_{pond[i]} \\
\alpha_{pond} \sim \mathcal{N}(\alpha, \sigma) \\
\alpha \sim \mathcal{N}(0, 1) \\
\sigma \sim \mathcal{HalfCauchy}(0, 1)
$$

where we have

* $\alpha$: Average log-odd of the survival rate for entire population of ponds
* $\sigma$: Standard deviation of log-odds of survival among ponds
* $\alpha_{pond}$: vector of individual pond intercept (mean)

### Assign value to the parameters


```{r}
a <- 1.4
sigma <- 1.5
nponds <- 60
set.seed(12)

# must use as.interger because of stan, see overthinking box on p. 366
dsim <-
  tibble(pond = seq_len(nponds),
         ni = rep(as.integer(c(5, 10, 25, 35)), each = nponds/4),
         true_a = rnorm(n = nponds, mean = a, sd = sigma))
glimpse(dsim)
```

and we plot the data to see the real distributions

```{r}
dsim %>%
  mutate(ni = factor(ni)) %>%
  ggplot(aes(x = true_a, y = ni)) +
  tidybayes::stat_halfeye(.width = 0.5, fill = "orange") +
  theme_light() +
  labs(title = "Distribution of log odd of survival by pond")
  
```



### Simulate survivors

The model uses

$$
logit(p_i) = \alpha_{pond[i]} \\
\alpha_{pond} \sim \mathcal{N}(\alpha, \sigma) \\
\alpha \sim \mathcal{N}(0, 1) \\
\sigma \sim \mathcal{HalfCauchy}(0, 1)
$$
therefore

the simulation of $p_i$ must use the logistic function


```{r}
set.seed(12)
dsim <- dsim %>%
  mutate(si = rbinom(n = nrow(dsim), prob = plogis(true_a), size = ni))
dsim
```

### Compute the no-pooling estimates

```{r}
dsim <- dsim %>%
  mutate(p_nopool = si / ni)
dsim
```

### Compute the partial pooling estimates


```{r}
a_file <- here::here("fits", "b12_03.rds")  # rds file location
stopifnot(file.exists(a_file))
b12.3 <- readRDS(file = a_file)  # load the file
# b12.3 <- brm(
#   data = dsim,
#   family = binomial,
#   si | trials(ni) ~ 1 + (1 | pond),
#   prior = c(prior(normal(0, 1), class = Intercept),
#             prior(cauchy(0, 1), class = sd)),
#   iter = 10000, warmup = 1000, chains = 1, cores = 4,
#   seed = 12)
# b12.3 <- add_criterion(b12.3, c("loo", "waic"))
# saveRDS(object = b12.3, file = a_file)
```
which gives this summary

```{r}
summary(b12.3)
```

and we get the informaiton on the level 1, the fixed effect, as follows

```{r}
# fixef(b12.3)
```

The level 2, or random effect is

```{r}
# ranef(b12.3)
```

and the whole thing is obtained with the `fit` which calls the stan data

```{r}
# b12.3$fit
```

We then add the the partially-pooled estimates of the posterior distribution
to the simulated data.

>**Important**: The `coef` gives the coefficients of the posterior distribution.
It reflects all the levels of the multilevel model, that is both the fixed effects,
obtained by `fixef()`, and the random effects, obtained by `ranef()`, on the posterior
ditribution.  In our current model which only has an intercept, it is therefore, also, the
average by pond.

```{r}
p_partpool <- coef(b12.3)$pond[, , ] %>%
  as_tibble() %>%
  transmute(p_partpool = plogis(Estimate))
p_partpool

dsim <- dsim %>%
  bind_cols(p_partpool) %>%
  mutate(p_true = plogis(true_a)) %>%
  mutate(nopool_error = abs(p_nopool - p_true),
         partpool_error = abs(p_partpool - p_true))


glimpse(dsim)
```

and we plot the data

```{r}
# data to create the horizontal summary lines
# we put linetype and color in theis df since they are related and
# avoid overloading the ggplot code.
# Kurtz tend to overload functions . . . 
dfline <- dsim %>%
  select(ni, nopool_error, partpool_error) %>%
  pivot_longer(cols = c("nopool_error", "partpool_error"), 
               names_to = "key", values_to = "value") %>%
  group_by(ni, key) %>%
  summarise(mean_error = mean(value)) %>%
  ungroup() %>%
  mutate(x = case_when(ni == 5 ~ 1,
                       ni == 10 ~ 16,
                       ni == 25 ~ 31,
                       ni == 35 ~ 46,
                       TRUE ~ NA_real_),
         xend = case_when(ni == 5 ~ 15,
                       ni == 10 ~ 30,
                       ni == 25 ~ 45,
                       ni ==  35 ~ 60,
                       TRUE ~ NA_real_),
         linetype = case_when(key == "nopool_error" ~ "solid",
                              key == "partpool_error" ~ "dashed",
                              TRUE ~ as.character(key)),
         color = case_when(key == "nopool_error" ~ "orange2",
                              key == "partpool_error" ~ "black",
                              TRUE ~ as.character(key))
         )
dfline

# the subtitle text
stitle <- "The horizontal axis displays pond number. The vertical axis measures\nthe absolute error in the predicted proportion of survivors, compared to\nthe true value used in the simulation. The higher the point, the worse\nthe estimate. No-pooling shown in orange. Partial pooling shown in black.\nThe orange and dashed black lines show the average error for each kind\nof estimate, across each initial density of tadpoles (pond size). Smaller\nponds produce more error, but the partial pooling estimates are better\non average, especially in smaller ponds."

p <- ggplot(dsim, aes(x = pond)) +
  geom_vline(xintercept = c(15.5, 30.5, 45.4), color = "white", size = 2/3) +
  geom_point(aes(y = nopool_error), color = "orange2") +
  geom_point(aes(y = partpool_error), shape = 1) +
  geom_segment(data = dfline, 
               aes(x = x, xend = xend, 
                   y = mean_error, yend = mean_error), linetype = dfline$linetype,
                   color = dfline$color) +
  annotate("text", x = c(15 - 7.5, 30 - 7.5, 45 - 7.5, 60 - 7.5), y = .45,
           label = c("tiny (5)", "small (10)", "medium (25)", "large (35)")) +
  scale_x_continuous(breaks = c(1, 10, 20, 30, 40, 50, 60)) +
  labs(title = "Estimate error by model type",
       subtitle = stitle,
       y = "absolute error") +
  # theme_light() +
  ggthemes::theme_fivethirtyeight() +
  theme(panel.grid.major = element_blank(),
        plot.subtitle = element_text(size = 10))
p

```


## More than one type of cluster


### Multilevel chimpanzees

#### The model

$$
pull\_left_i \sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) = \alpha + \alpha_{actor[i]} + (\beta_P + \beta_{PC} C_i) P_i \\
\alpha_{actor} \sim \mathcal{N}(0, \sigma_{actor}) \\
\alpha \sim \mathcal{N}(0, 10) \\
\beta_P \sim \mathcal{N}(0, 10) \\
\beta_{PC} \sim \mathcal{N}(0, 10) \\
\sigma_{actor} \sim \mathcal{HalfCauchy}(0, 1)
$$
#### The fit

We load the data

```{r}
data(chimpanzees)
d <- chimpanzees
glimpse(d)
```



```{r}
a_file <- here::here("fits", "b12_04.rds")  # rds file location
stopifnot(file.exists(a_file))
b12.4 <- readRDS(file = a_file)  # load the file
# b12.4 <- brm(
#   data = d,
#   family = binomial,
#   pulled_left | trials(1) ~ 1 + prosoc_left + prosoc_left:condition + (1 | actor),
#   prior = c(prior(normal(0, 10), class = Intercept),
#             prior(normal(0, 10), class = b),
#             prior(cauchy(0, 1), class = sd)),
#   iter = 5000, warmup = 1000, chains = 4, cores = 4,
#   control = list(adapt_delta = 0.95),
#   seed = 12)
# b12.4 <- add_criterion(b12.4, c("loo", "waic"))
# saveRDS(object = b12.4, file = a_file)
```

the posterior samples is

```{r}
bpost12.4 <- posterior_samples(b12.4)
str(bpost12.4)
```

and we look at the standard deviaiton of the random effect of actor

```{r}
ggplot(bpost12.4, aes(x = sd_actor__Intercept)) +
  tidybayes::stat_halfeye(.width = 0.95, fill = "orange") +
  # scale_y_continuous(breaks = NULL) +
  ggthemes::theme_economist() +
  labs(title = expression(sigma[actor]))
```

### Two types of cluster


#### The model

$$
pull\_left_i \sim \mathcal{Binomial}(1, p_i) \\
logit(p_i) = \alpha + \alpha_{actor[i]} + \alpha_{block[i]} + (\beta_P + \beta_{PC} C_i) P_i \\
\alpha_{actor} \sim \mathcal{N}(0, \sigma_{actor}) \\
\alpha_{block} \sim \mathcal{N}(0, \sigma_{block}) \\
\alpha \sim \mathcal{N}(0, 10) \\
\beta_P \sim \mathcal{N}(0, 10) \\
\beta_{PC} \sim \mathcal{N}(0, 10) \\
\sigma_{actor} \sim \mathcal{HalfCauchy}(0, 1) \\
\sigma_{block} \sim \mathcal{HalfCauchy}(0, 1)
$$

#### The fit

```{r}
a_file <- here::here("fits", "b12_05.rds")  # rds file location
stopifnot(file.exists(a_file))
b12.5 <- readRDS(file = a_file)  # load the file
# b12.5 <- update(
#   b12.4,
#   newdata = d,
#   formula = pulled_left | trials(1) ~ 1 + prosoc_left + prosoc_left:condition + (1 | actor)  + (1 | block),
#   iter = 6000, warmup = 1000, chains = 4, cores = 4,
#   control = list(adapt_delta = 0.9),
#   seed = 12)
# b12.5 <- add_criterion(b12.5, c("loo", "waic"))
# saveRDS(object = b12.5, file = a_file)
```



## Multilevel posterior predictions


### Posterior prediction for same clusters

Predicting chimp 2 we have

```{r}
chimp <- 2
nd <-
  tibble(prosoc_left = c(0, 1, 0, 1),
         condition   = c(0, 0, 1, 1),
         actor       = chimp)
nd

chimp_2_fitted <-fitted(b12.4, newdata = nd) %>%
  as_tibble() %>%
  mutate(prosoc_left = c(0, 1, 0, 1),
         condition   = c(0, 0, 1, 1),
         prosoc_cond = paste(prosoc_left, condition, sep = "/"),
         prosoc_cond = factor(prosoc_cond, levels = c("0/0", "1/0", "0/1", "1/1")))
chimp_2_fitted
```

and we plot the fitted data

```{r}
# if you want to use `geom_line()` or `geom_ribbon()` with a factor on the x axis,
# you need to code something like `group = 1` in `aes()`
p_fit <- ggplot(chimp_2_fitted, aes(x = prosoc_cond, y = Estimate, group = 1)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "orange", alpha = 0.5) +
  geom_line(color = "blue") +
  coord_cartesian(ylim = c(0.75, 1)) +
  ggthemes:::theme_igray() +
  labs(title = "Chimp # 2", x = NULL, y = NULL)
p_fit
```



and using the average of real data we have

```{r}
chimp_2_raw <- d %>%
  filter(actor == chimp) %>%
    mutate(
      prosoc_cond = paste(prosoc_left, condition, sep = "/"),
      prosoc_cond = factor(prosoc_cond, levels = c("0/0", "1/0", "0/1", "1/1"))) %>%
  group_by(prosoc_left, condition, prosoc_cond) %>%
  summarise(prob = mean(pulled_left)) %>%
  ungroup()
chimp_2_raw
```





## Summary



## Practice
