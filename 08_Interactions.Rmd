```{r include=FALSE}
library(dplyr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(tidybayes, quietly = TRUE)
library(rethinking)
library(brms)
library(loo)
library(dagitty, quietly = TRUE)
library(ggdag, quietly = TRUE)
library(ggdist, quietly = TRUE)
library(patchwork, quietly = TRUE)
library(paletteer, quietly = TRUE)
```


# Conditional Manatees {#interactions}


## 8E1 {-}

### (1) {-}

Heat

### (2) {-}

Socio-economic situation

### (3) {-}

Electricity (e.g. from battery)

## 8E2 {-}

### (1) {-}

Interaction. Heat and moisture interact to obtain cooking effect.
The word "condition" is key here.


### (2) {-}

Additive, no interaction (although this is arguable).
The word "or" defines the situation


### (3) {-}

Additive, you can get opinions from both without
them interacting with each other. The word "unless" is a key word.

### (4) {-}

Additive, no interaction.  The word "or" indicates either one can be
used.


## 8E3 {-}

### (1) {-}

$$
\begin{align*}
cooking_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot heat_i +\beta_2 \cdot moist_i + 
\beta_{3} \cdot moist_i \cdot heat_i
\end{align*}
$$

### (2) {-}


$$
\begin{align*}
speed_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot cylinders_i +\beta_2 \cdot injection_i
\end{align*}
$$


### (3) {-}


$$
\begin{align*}
belief_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot parents_i +\beta_2 \cdot friends_i
\end{align*}
$$



### (4) {-}


$$
\begin{align*}
intelligence_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot social_i +\beta_2 \cdot appendage_i
\end{align*}
$$

## 8M1 {-}

Temperature interacts with water and/or shade to either cancel the water effect or
increase the effect of shade or both.

## 8M2 {-}

Let the binary variable $T$ be the temperature effect where $H=1$ means it is 
hot and $H=0$ when it is cold.

and the initial model

$$
\mu_i \sim \alpha + \beta_W \cdot water\_c_i + \beta_S \cdot shade\_c_i
$$

now becomes


$$
\mu_i \sim \alpha + (1 - H_i) \cdot \beta_W \cdot water\_c_i + H_i \cdot \beta_S \cdot shade\_c_i
$$


## 8M3 {-}

The relationship is that ravens depend on wolves for their food but the wolves
don't depend on the raven.  The question states that ravens depends on wolves.
It is not clear that they depend entirely as a parasite does for example.

The data would be one where ravens success increases as function of wolves
success.  It is not an interaction which would cause the presence of ravens and
wolves to impact their mutual success in a way similar as if a third variable
affected both and increase as well as decrease their mutual success.


## 8H1 {-}

```{r}
data(tulips, package = "rethinking")
d <- tulips %>%
  mutate(blooms_r = scales::rescale(blooms),
         water_c = as.vector(scale(water, scale = FALSE)),
         shade_c = as.vector(scale(shade, scale = FALSE)))
stopifnot(is.factor(d$bed))  # must be a factor to use with brms as category
rm(tulips)
skimr::skim(d)
```

### Model and fit {-}

$$
\begin{align*}
blooms\_r_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha_{bed[i]} + \beta_W \cdot water\_c_i+ \beta_S \cdot shade\_c_i \\
\alpha_{bed[i]} &\sim \mathcal{N}(0.5, 1) \\
\beta_W &\sim \mathcal{N}(0, 1) \\
\beta_S &\sim \mathcal{N}(0, 1) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$


```{r}
a_file <- here::here("fits", "b08H01.rds")
b08H01 <- readRDS(file = a_file)
# b08H01 <- brm(
#   data = d,
#   family = gaussian,
#   formula = blooms_r ~ 0 + bed + water_c + shade_c,
#   prior = c(prior(normal(0.5, 0.25), class = b),
#             prior(normal(0, 0.25), class = b, coef = water_c),
#             prior(normal(0, 0.25), class = b, coef = shade_c),
#             prior(exponential(1), class = sigma)),
#   iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H01 <- brms::add_criterion(b08H01, criterion = c("waic", "loo"))
# saveRDS(b08H01, file = a_file)
summary(b08H01)
```


## 8H2 {-}


```{r}
a_file <- here::here("fits", "b08H02.rds")
b08H02 <- readRDS(file = a_file)
# b08H02 <- brm(
#   data = d,
#   family = gaussian,
#   formula = blooms_r ~ 1 + water_c + shade_c,
#   prior = c(prior(normal(0.5, 0.25), class = Intercept),
#             prior(normal(0, 0.25), class = b),
#             prior(exponential(1), class = sigma)),
#   iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H02 <- brms::add_criterion(b08H02, criterion = c("waic", "loo"))
# saveRDS(b08H02, file = a_file)
summary(b08H02)
```


```{r}
w <- loo::loo_compare(b08H01, b08H02, criterion = "waic")
print(w, simplify = FALSE)
```

The water and shade effect is the same.  Now however the intercept or 0.36 is
the same as the mean of the 3 bed intercepts we had in 8H1 above.  In other words
the model in 8H1 breaks down the intercept into the three beds showing their ingluence
on the growth.

## 8H3 {-}


```{r}
data(rugged)
d <- rugged %>%
  filter(complete.cases(rgdppc_2000)) %>%
  mutate(log_gdp = log(rgdppc_2000),
         is_africa = if_else(cont_africa == 1, "Africa", "Not Africa"),
         is_africa = as.factor(is_africa),
         cid = if_else(cont_africa == 1, "1", "2"),
         cid = as.factor(cid),
         log_gdp_s = log_gdp / mean(log_gdp),
         rugged_s = scales::rescale(rugged),
         rugged_sc = as.vector(scale(rugged_s, center = TRUE, scale = FALSE))
         )
rm(rugged)
# glimpse(d)
```


> Errata: Model m8.5 is with the tulips data, not the rugged data.  It must be
model m8.3 that is meant.  See in first edition the practice 7H3.

Model m8.3 is as follows


$$
\begin{align*}
\log{(log\_gdp\_s_i)} &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha_{[cid]} + \beta_{[cid]} \cdot rugged\_sc_i \\
\alpha &\sim \mathcal{N}(1, 0.1) \\
\beta &\sim \mathcal{N}(0, 0.3) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

See section 8.1.3 on how to fit the b8.3 model which is the `brms` version of
m8.3.

```{r}
a_file <- here::here("fits", "b08H03.rds")
b08H03 <- readRDS(file = a_file)
# b08H03 <-
#   brm(data = d,
#       family = gaussian,
#       formula = bf(log_gdp_s ~ 0 + a + b * rugged_sc,
#          a ~ 0 + cid,
#          b ~ 0 + cid,
#          nl = TRUE),
#       prior = c(prior(normal(1, 0.1), class = b, coef = cid1, nlpar = a),
#                 prior(normal(1, 0.1), class = b, coef = cid2, nlpar = a),
#                 prior(normal(0, 0.3), class = b, coef = cid1, nlpar = b),
#                 prior(normal(0, 0.3), class = b, coef = cid2, nlpar = b),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H03 <- brms::add_criterion(b08H03, criterion = c("waic", "loo"))
# saveRDS(b08H03, file = a_file)
summary(b08H03)
```

### (a) {-}

See section 7.5.2 on how to show outliers


```{r}
dp <- tibble(pareto_k = b08H03$criteria$loo$diagnostics$pareto_k,
       p_waic = b08H03$criteria$waic$pointwise[, "p_waic"],
       country = d$country,
       is_africa = d$is_africa)
# glimpse(dp)
waic_max <- 0.3
k_max <- 0.3
ggplot(dp, aes(x = pareto_k, y = p_waic, color = is_africa)) +
  geom_vline(xintercept = waic_max, linetype = 2, color = "purple") +
  geom_hline(yintercept = k_max, linetype = 2, color = "purple") +
  geom_point() +
  ggrepel::geom_text_repel(data = . %>% filter(p_waic >= waic_max),
                           aes(label = country)) +
  scale_color_manual(values = c("Africa" = "darkgreen", "Not Africa" = "violetred")) +
  scale_shape_manual(values = c(19, 19)) +
  theme_minimal() +
  theme(legend.position = c(0.1, 0.85),
        legend.title = element_blank(),
        title = element_text(color = "midnightblue")) +
  labs(title = "Practice 8H3 (a)",
       subtitle = deparse1(b08H03$formula$formula))
```
Beside Seychelles, Swizterland is also an outlier.  Probably because Switzerland
has a high GDP in spite of being rugged.

### (b) {-}

See section 7.5.2 on ow to do the robust regression with student distribution.

```{r}
a_file <- here::here("fits", "b08H03t.rds")
b08H03t <- readRDS(file = a_file)
# b08H03t <-
#   brm(data = d,
#       family = student,
#       formula = bf(log_gdp_s ~ 0 + a + b * rugged_sc,
#          a ~ 0 + cid,
#          b ~ 0 + cid,
#          nl = TRUE,
#          nu = 2),
#       prior = c(prior(normal(1, 0.1), class = b, coef = cid1, nlpar = a),
#                 prior(normal(1, 0.1), class = b, coef = cid2, nlpar = a),
#                 prior(normal(0, 0.3), class = b, coef = cid1, nlpar = b),
#                 prior(normal(0, 0.3), class = b, coef = cid2, nlpar = b),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H03t <- brms::add_criterion(b08H03t, criterion = c("waic", "loo"))
# saveRDS(b08H03t, file = a_file)
summary(b08H03t)
```

Comparing the results

```{r}
w <- loo::loo_compare(b08H03, b08H03t, criterion = "waic")
print(w, simplify = FALSE)
```
Therefore the Student distribution has less precision . . . but is more robust.
That is, it is less impacted by outliers.  This is a clasic trade-off between
precision and robustness.


and to visualize the outliers which have much less impact now we have
the following plot


```{r}
dp <- tibble(pareto_k = b08H03t$criteria$loo$diagnostics$pareto_k,
       p_waic = b08H03t$criteria$waic$pointwise[, "p_waic"],
       country = d$country,
       is_africa = d$is_africa)
# glimpse(dp)
waic_max <- 0.3
k_max <- 0.3
ggplot(dp, aes(x = pareto_k, y = p_waic, color = is_africa)) +
  geom_vline(xintercept = waic_max, linetype = 2, color = "purple") +
  geom_hline(yintercept = k_max, linetype = 2, color = "purple") +
  geom_point() +
  ggrepel::geom_text_repel(data = . %>% filter(p_waic >= waic_max),
                           aes(label = country)) +
  scale_color_manual(values = c("Africa" = "darkgreen", "Not Africa" = "violetred")) +
  scale_shape_manual(values = c(19, 19)) +
  theme_minimal() +
  theme(legend.position = c(0.1, 0.85),
        legend.title = element_blank(),
        title = element_text(color = "midnightblue")) +
  labs(title = "Practice 8H3 (b) - Student distribution",
       subtitle = deparse1(b08H03t$formula$formula))
```

## 8H4 {-}

As required in the question, we use $log(lang.per.cap)$. This gives
$lang.per.cap.log \in [-10,0]$.  To avoid the negative outcome which cause
a positive slope (required by our hypothesis), we rescale $lang.per.cap.log$
to be in $[0,10]$

We also rescale $mean.growing.season$ and $sd.growing.season$ to $[0,10]$



```{r}
data(nettle)
d <- nettle %>%
  mutate(area.log = scales::rescale(log(area), to = c(0, 10)),
         mean.growing.season = scales::rescale(mean.growing.season, to = c(0, 10)),
         sd.growing.season = scales::rescale(sd.growing.season, to = c(0, 10)),
         lang.per.cap = num.lang / k.pop,
         lang.per.cap.log = scales::rescale(log(lang.per.cap), to = c(0, 10)))
rm(nettle)
skimr::skim(d)
```

### (a) {-}

#### The priors {-}

See section 8.1.1 on how to estimate the priors.

Since $lang.per.cap.log \in [0,10]$ with mean about 5 then we use
$\alpha \sim \mathcal{N}(5,2.5)$.

Since $lang.per.cap.log \in [0,10]$ $mean.growing.season \in [0,10]$ 
which gives a maximum slope of $\frac{10-0}{10-0} \approx 1$ which should be a 
positive slope since we have the hypothesis that language diversity increases 
with the $mean.growing.season$. Therefore $\beta_{GM} &\sim \mathcal{N}(0.5,0.25)$

Similarly, since $lang.per.cap.log \in [0,10]$ and $area.log \in [0,10]$ 
which gives a maximum slope of $\frac{10-0}{10-0} = 1$ which should be 
positive slope since we have the hypothesis that language diversity increases with the $area.log$.
Therefore $\beta_{A} &\sim \mathcal{N}(0.5,0.25)$


#### The models {-}

We will create 4 models who are variations of the following full model

$$
\begin{align*}
lang.per.cap.log_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_{GM} \cdot mean.growing.season_i + \beta_A \cdot area.log_i \\
\alpha &\sim \mathcal{N}(5,2.5) \\
\beta_{GM} &\sim \mathcal{N}(0.5,0.25) \\
\beta_{A} &\sim \mathcal{N}(0.5,0.25) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$


#### The fit {-}

The *null* model

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a0.rds")
b08H04a0 <- readRDS(file = a_file)
# b08H04a0 <- brm(
#   data = d,
#   formula = lang.per.cap.log ~ 1,
#   family = gaussian,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),
#   seed = 8
# )
# b08H04a0 <- brms::add_criterion(b08H04a0, criterion = c("waic", "loo"))
# saveRDS(b08H04a0, file = a_file)
print(b08H04a0, digits = 3)
```


with the *mean.growing.season* effect

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a1.rds")
b08H04a1 <- readRDS(file = a_file)
# b08H04a1 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + mean.growing.season,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "mean.growing.season"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04a1 <- brms::add_criterion(b08H04a1, criterion = c("waic", "loo"))
# saveRDS(b08H04a1, file = a_file)
print(b08H04a1, digits = 3)
```

with the *area.log* effect

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a2.rds")
b08H04a2 <- readRDS(file = a_file)
# b08H04a2 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + area.log,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "area.log"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04a2 <- brms::add_criterion(b08H04a2, criterion = c("waic", "loo"))
# saveRDS(b08H04a2, file = a_file)
print(b08H04a2, digits = 3)
```

with both *mean.growing.season* and *area.log*


```{r}
a_file <- here::here(getwd(), "fits", "b08H04a3.rds")
b08H04a3 <- readRDS(file = a_file)
# b08H04a3 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + mean.growing.season + area.log,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "mean.growing.season"),
#     prior(normal(0.5, 0.25), class = b, coef = "area.log"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04a3 <- brms::add_criterion(b08H04a3, criterion = c("waic", "loo"))
# saveRDS(b08H04a3, file = a_file)
print(b08H04a3, digits = 3)
```


#### Validate the priors {-}



```{r}
set.seed(8)
b08H04a1_prior <- prior_samples(b08H04a1)
# glimpse(b08H04a1_prior)
pd <-
  b08H04a1_prior %>%
  slice_sample(n = 50) %>%
  tibble::rownames_to_column() %>%
  expand(nesting(rowname, Intercept, b_mean.growing.season), mean.growing.season = c(0, 10)) %>%
  mutate(lang.per.cap.log = Intercept + b_mean.growing.season * mean.growing.season)
         # rugged_s  = rugged_sc + mean(dd$rugged_s))
glimpse(pd)

p1 <- ggplot(pd, aes(x = mean.growing.season, y = lang.per.cap.log, group = rowname)) +
  geom_line(color = "lavender") +
  geom_hline(yintercept = range(d$lang.per.cap.log),
             size = 1, linetype = 2, color = "royalblue") +
  coord_cartesian(xlim = c(0, 10), ylim = c(-5, 15)) +
  labs(
    subtitle = "Intercept ~ dnorm(5, 2.5)\nb ~ dnorm(0.5, 0.25)",
    x = "mean.growing.season",
    y = "lang.per.cap.log") +
  ggthemes::theme_hc()
# p1
b08H04a2_prior <- prior_samples(b08H04a2)
pd <-
  b08H04a2_prior %>%
  slice_sample(n = 50) %>%
  tibble::rownames_to_column() %>%
  expand(nesting(rowname, Intercept, b_area.log), area.log = c(0, 10)) %>%
  mutate(lang.per.cap.log = Intercept + b_area.log * area.log)
p2 <- ggplot(pd, aes(x = area.log, y = lang.per.cap.log, group = rowname)) +
  geom_line(color = "lavender") +
  geom_hline(yintercept = range(d$lang.per.cap.log),
             size = 1, linetype = 2, color = "royalblue") +
  coord_cartesian(xlim = c(0, 10), ylim = c(-5, 15)) +
  labs(
    subtitle = "Intercept ~ dnorm(5, 2.5)\nb ~ dnorm(0.75, 0.5)",
    x = "area.log",
    y = "lang.per.cap.log") +
  ggthemes::theme_hc()
# p2
p1 + p2
```

#### Compare the models {-}

```{r}
w <- loo::loo_compare(b08H04a0, b08H04a1, b08H04a2, b08H04a3, criterion = "waic")
print(w, simplify = FALSE)
```

with the models' weights

```{r}
brms::model_weights(b08H04a0, b08H04a1, b08H04a2, b08H04a3, weights = "waic") %>% 
  round(digits = 3)
```
which seems to indicate that the model with `mean.growing.season` is the most
informative.  A mix of the univariate model with `mean.growing.season` and the
multivariate model can be considered based on the weights.

Given that the `elpd_diff` for b08H04a3 is -0.6 which exceeds the `se_diff` of
b08H04a1 then we select b08H04a1 as our model of choice.


#### Plotting the model



```{r}
b08H04a_seq <- data.frame(
  mean.growing.season = seq(from = 0, to = 10, length.out = 30))
# glimpse(b08H04a_seq)
b08H04a_fitted <- fitted(b08H04a1, newdata = b08H04a_seq, probs = c(0.015, 0.985)) %>%
  data.frame() %>%
  bind_cols(b08H04a_seq)
# glimpse(b08H04a_fitted)
```


```{r}
ggplot(d, aes(x = mean.growing.season, 
              y = lang.per.cap.log)) +
  geom_point(aes(size = area.log, color = mean.growing.season)) +
  geom_smooth(data = b08H04a_fitted, aes(x = mean.growing.season, y = Estimate, 
                                         ymin = Q1.5, ymax = Q98.5),
              fill = "slategray1",
              color = "slateblue1",
              stat = "identity",
              alpha = 1/4, size = 1) +
  scale_color_paletteer_c(palette = "grDevices::Heat") +
  theme_minimal() +
  theme(legend.position = "right") +
  labs(title = "8H4 (a)", 
       subtitle = paste("b08H04a1:", deparse1(b08H04a1$formula$formula)),
       x = "mean.growing.season (rescaled on [0,10])",
       y = "lang.per.cap (log)",
       size = "log.area", color = "sd")
```


### (b) {-}

Using the same process as in (a) just above

#### The fit {-}

The *null* model, same as in (a) above

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a0.rds")
b08H04a0 <- readRDS(file = a_file)
print(b08H04a0, digits = 3)
```


with the *sd.growing.season* effect

```{r}
a_file <- here::here(getwd(), "fits", "b08H04b1.rds")
b08H04b1 <- readRDS(file = a_file)
# b08H04b1 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + sd.growing.season,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "sd.growing.season"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04b1 <- brms::add_criterion(b08H04b1, criterion = c("waic", "loo"))
# saveRDS(b08H04b1, file = a_file)
print(b08H04b1, digits = 3)
```

with the *area.log* effect, same as before in (a)

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a2.rds")
b08H04a2 <- readRDS(file = a_file)
print(b08H04a2, digits = 3)
```

with both *sd.growing.season* and *area.log*


```{r}
a_file <- here::here(getwd(), "fits", "b08H04b3.rds")
b08H04b3 <- readRDS(file = a_file)
# b08H04b3 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + sd.growing.season + area.log,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "sd.growing.season"),
#     prior(normal(0.5, 0.25), class = b, coef = "area.log"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04b3 <- brms::add_criterion(b08H04b3, criterion = c("waic", "loo"))
# saveRDS(b08H04b3, file = a_file)
print(b08H04b3, digits = 3)
```


#### Compare the models {-}

```{r}
w <- loo::loo_compare(b08H04a0, b08H04b1, b08H04a2, b08H04b3, criterion = "waic")
print(w, simplify = FALSE)
```

with the models' weights

```{r}
brms::model_weights(b08H04a0, b08H04b1, b08H04a2, b08H04b3, weights = "waic") %>% 
  round(digits = 3)
```
In this case, the elpd_diff are very small and the model weights similar.  None of
the effects, even together seem to make a big difference.

Therefore the anayliss support the hypothesis that $sd.gorwing.season$ has a
negative effect on language diversity.  However this effect seems rather small
with a higher degree of certeinty than the $mean.growing.season$ effect.


#### Plotting the model

We use the model b08H4b1 to visualize, there is so little elpd_diff with the
other models that its use is no worse than using the other models.

```{r}
b08H04b_seq <- data.frame(
  sd.growing.season = seq(from = 0, to = 10, length.out = 30))
# glimpse(b08H04b_seq)
b08H04b_fitted <- fitted(b08H04b1, newdata = b08H04b_seq, probs = c(0.015, 0.985)) %>%
  data.frame() %>%
  bind_cols(b08H04b_seq)
# glimpse(b08H04b_fitted)
```


```{r}
ggplot(d, aes(x = sd.growing.season, 
              y = lang.per.cap.log)) +
  geom_point(aes(size = area.log, color = mean.growing.season)) +
  geom_smooth(data = b08H04b_fitted, aes(x = sd.growing.season, y = Estimate, 
                                         ymin = Q1.5, ymax = Q98.5),
              fill = "wheat1",
              color = "tan1",
              stat = "identity",
              alpha = 1/4, size = 1) +
  scale_color_paletteer_c(palette = "grDevices::Heat 2") +
  theme_minimal() +
  theme(legend.position = "right") +
  labs(title = "8H4 (b)", 
       subtitle = paste("b08H04b1:", deparse1(b08H04b1$formula$formula)),
       x = "sd.growing.season (rescaled on [0,10])",
       y = "lang.per.cap (log)",
       size = "log.area", color = "mean")
```


### (c) {-}

Now using an interaction between $mean.growing.season$ and $sd.growing.season$
we have the following model


$$
\begin{align*}
lang.per.cap.log_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_{M} \cdot mean.growing.season_i + 
 \beta_{S} \cdot sd.growing.season_i + 
 \beta_{MS} \cdot mean.growing.season_i \cdot sd.growing.season_i \\
\alpha &\sim \mathcal{N}(5,2.5) \\
\beta_{GM} &\sim \mathcal{N}(0.5,0.25) \\
\beta_{GS} &\sim \mathcal{N}(0.5,0.25) \\
\beta_{MS} &\sim \mathcal{N}(0.5,0.25) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

```{r}
a_file <- here::here(getwd(), "fits", "b08H04c1.rds")
b08H04c1 <- readRDS(file = a_file)
# b08H04c1 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + mean.growing.season + sd.growing.season + 
#     mean.growing.season:sd.growing.season,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "mean.growing.season"),
#     prior(normal(0.5, 0.25), class = b, coef = "sd.growing.season"),
#     prior(normal(0.5, 0.25), class = b, coef = "mean.growing.season:sd.growing.season"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04c1 <- brms::add_criterion(b08H04c1, criterion = c("waic", "loo"))
# saveRDS(b08H04c1, file = a_file)
print(b08H04c1, digits = 3)
```

#### Compare the models {-}

```{r}
w <- loo::loo_compare(b08H04a0, b08H04a1, b08H04a2, b08H04a3, 
                      b08H04b1, b08H04b3,
                      b08H04c1, criterion = "waic")
print(w, simplify = FALSE)
```

with the models' weights

```{r}
brms::model_weights(b08H04a0, b08H04a1, b08H04a2, b08H04a3, 
                      b08H04b1, b08H04b3,
                      b08H04c1, weights = "waic") %>% 
  round(digits = 3)
```
In this case, the comparison is in favor of the model with interactions
between $mean.growing.season$ and $sd.growing.season$.  The model is actually
better than all models considered so far. The difference is significant as
all other models have a `elpd_diff` greater than `se_diff`.

Therefore the hypotheses defined in (c) seems to be the best one.


#### Plotting

```{r}
b08H04c_seq <- crossing(
  mean.growing.season = seq(from = 0, to =10, length.out = 20), 
  sd.growing.season = seq(from = 0, to = 10, length.out = 6))

b08H04c_fitted <- fitted(b08H04c1, newdata = b08H04c_seq, probs = c(0.015, 0.985)) %>%
  data.frame() %>%
  bind_cols(b08H04c_seq) %>%
  mutate(
    id = sprintf("sd = %02d", sd.growing.season)
  ) %>%
  arrange(id)
glimpse(b08H04c_fitted)
```

```{r}
ggplot(b08H04c_fitted, aes(x = mean.growing.season, y = Estimate, ymin = Q1.5, ymax = Q98.5)) +
  geom_smooth(stat = "identity", fill = "aquamarine",
              alpha = 1/4, size = 1/2) +
  # geom_point(data = d, color = "steelblue") +
  # scale_x_continuous(breaks = c(-1, 0, 1)) +
  # scale_y_continuous(breaks = c(0, .5, 1)) +
  # coord_cartesian(xlim = c(-1, 1), ylim = c(0, 1)) +
  theme_minimal() +
  theme(legend.position = "none",
        strip.background = element_rect(fill = "lightsalmon")) +
  labs(title = "8H4 (c)", 
       subtitle = paste("b08H04c1:", deparse1(b08H04c1$formula$formula)),
       x = "sd.growing.season (rescaled on [0,10])", y = "ang.per.cap (log)") +
  facet_wrap(. ~ id, nrow = 2)
```



## 8H5 {-}

```{r}
data(Wines2012)
d <- Wines2012 %>%
  mutate(flight = as.factor(flight),
         judge.a = ifelse(judge.amer == 0, "NotAmJudge", "AmJudge"),
         wine.a = ifelse(wine.amer == 0, "NotAmWine", "AmWine"),
         judge.a = as.factor(judge.a),
         wine.a = as.factor(wine.a),
         score.s = as.vector(scale(score)))
rm(Wines2012)
skimr::skim(d)
# glimpse(d)
```

We have to use index variables with 2 variables.  See @kurtz2020b in his
section 5.3.2 with model b5.11.

```{r}
a_file <- here::here(getwd(), "fits", "b08H05a.rds")
b08H05a <- readRDS(file = a_file)
# b08H05a <-
#   brm(data = d,
#       family = gaussian,
#       formula = bf(score.s ~ 0 + j + w,
#                    j ~ 0 + judge,
#                    w ~ 0 + wine,
#                    nl = TRUE),
#       prior = c(prior(normal(0, 0.5), nlpar = j),
#                 prior(normal(0, 0.5), nlpar = w),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H05a <- brms::add_criterion(b08H05a, criterion = c("waic", "loo"))
# saveRDS(b08H05a, file = a_file)
print(b08H05a, digits = 3)
```
```{r}
b08H05_fitted <- fitted(b08H05a) %>%
  as_tibble()
glimpse(b08H05_fitted)
```

```{r}
get_variables(b08H05a)
```

```{r}
df <- b08H05a %>%
  posterior_samples() %>%
  select(-sigma, -lp__) %>%
  pivot_longer(cols = everything(), names_to = "vars") %>%
  group_by(vars) %>%
  summarize(y = ggdist::mean_hdi(value, width = 0.97)[1, "y"],
            ymin = ggdist::mean_hdi(value, width = 0.97)[1, "ymin"],
            ymax = ggdist::mean_hdi(value, width = 0.97)[1, "ymax"]) %>%
  mutate(is_wine = grepl(pattern = "^b_w_", x = vars),
         id = gsub(pattern = "b_w_|b_j_|judge", replacement = "", x = vars))
glimpse(df)

ggplot(data = df, aes(x = id, y = y, ymin = ymin, ymax = ymax, color = is_wine)) +
  geom_pointinterval() +
  ggrepel::geom_text_repel(aes(label = round(y, 2)), size = 3) +
  scale_color_manual(values = c("FALSE" = "blue", "TRUE" = "red")) + 
  coord_flip() +
  theme_classic() +
  theme(legend.position = "none") +
  labs(title = "8H5: Coeficient plot",
       x = NULL,
       y = "mean and hdi interval of width 97%")
  # facet_wrap(. ~ is_wine)
```

The heatmap in this case will help answer the questions

```{r}
pd <- d %>%
  select(judge, wine, score.s) %>%
  pivot_wider(names_from = judge, values_from = score.s) %>%
  tibble::column_to_rownames("wine") %>%
  as.matrix()
# glimpse(pd)
pheat <- superheat::superheat(X = pd, 
                              X.text = round(pd, 2), X.text.size = 3,
                              clustering.method = "hierarchical",
                              bottom.label.text.size = 3,
                              bottom.label.text.angle = 30,
                              bottom.label.text.alignment = "right",
                              left.label.text.size = 3,
                              title = "Wine Heatmap")
pheat
```
How to interpret variations: Some judges, such as JeanMMCaderbat and Robert Hodgston 
have generally more negative views whereas John Foy if genrally more positive

Notice patterns: Yes wine I2 seems to be an outlier and John Foy more positive than all other judges.

Best rated wines: B2

Worst rated wine: I2


## 8H6 {-}


For `brms` formula, see similar treatment in 8H5 just above

```{r}
a_file <- here::here(getwd(), "fits", "b08H06a.rds")
# b08H06a <- readRDS(file = a_file)
b08H06a <-
  brm(data = d,
      family = gaussian,
      formula = bf(score.s ~ 0 + f + j + w,
                   f ~ 0 + flight,
                   j ~ 0 + judge.a,
                   w ~ 0 + wine.a,
                   nl = TRUE),
      prior = c(prior(normal(0, 0.5), nlpar = f),
                prior(normal(0, 0.5), nlpar = j),
                prior(normal(0, 0.5), nlpar = w),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
b08H06a <- brms::add_criterion(b08H06a, criterion = c("waic", "loo"))
saveRDS(b08H06a, file = a_file)
print(b08H06a, digits = 3)
```

American judges seem to be generally more favorable than non American ones.
American wine seem t obtain a more negative score on average.

Whether the wine is red or wine seems to have little effect.

The favorable american judge effect could be related to judge John Foy
as mentioned in the previous problem.

## 8H7 {-}

Not done.