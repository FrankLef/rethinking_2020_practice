```{r include=FALSE}
library(dplyr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(tidybayes, quietly = TRUE)
library(rethinking)
library(brms)
library(loo)
library(simstudy)
library(dagitty, quietly = TRUE)
library(ggdag, quietly = TRUE)
library(ggdist, quietly = TRUE)
library(patchwork, quietly = TRUE)
library(paletteer, quietly = TRUE)
```


# Conditional Manatees {#interactions}


## 8E1 {-}

### (1) {-}

Heat

### (2) {-}

Socio-economic situation

### (3) {-}

Electricity (e.g. from battery) or engine type (e.g. V6, V8).

## 8E2 {-}

### (1) {-}

Interaction. Heat and moisture interact to obtain cooking effect.
The words *requires ... and making sure ...* are key here.


### (2) {-}

Additive, no interaction (although this is arguable),
You can have effect from either cylinders or fuel injector.
The word "or" defines the situation.


### (3) {-}

Additive, you can get opinions from both without
them interacting with each other. The word *unless* is a key word.

### (4) {-}

Additive, no interaction.  The words *either ... or ...* indicates either one can be
used.


## 8E3 {-}

### (1) {-}

$$
\begin{align*}
cooking_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot heat_i +\beta_2 \cdot moist_i + 
\beta_{3} \cdot moist_i \cdot heat_i
\end{align*}
$$

### (2) {-}


$$
\begin{align*}
speed_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot cylinders_i +\beta_2 \cdot injection_i
\end{align*}
$$


### (3) {-}


$$
\begin{align*}
belief_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot parents_i +\beta_2 \cdot friends_i
\end{align*}
$$



### (4) {-}


$$
\begin{align*}
intelligence_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_1 \cdot social_i +\beta_2 \cdot appendage_i
\end{align*}
$$

## 8M1 {-}

The tulip example is found in section 8.3.1, p.253.

Temperature interacts with water and/or shade to either cancel the water effect or
increase the effect of shade or both.

## 8M2 {-}

Let the binary variable $C$ be the temperature effect where $hot=1$ means it is 
hot and $hot=0$ when it is cold.

and the initial model

$$
\begin{align*}
bloom_i &\sim \mathcal{N(\mu_i, \sigma)} \\
\mu_i &= \alpha + \beta_W \cdot water\_i + \beta_S \cdot shade\_i \\
\alpha, \beta_S,  \beta_W &\sim \mathcal{N(., .)}\\
\sigma &\sim \mathcal{Exponential(1)}
\end{align*}
$$

now becomes


$$
\begin{align*}
bloom_i &\sim \mathcal{N(\mu_i, \sigma)} \\
\mu_i &= (1 - hot_i) \cdot (\alpha + \beta_W \cdot water\_i + \beta_S \cdot shade\_i) \\
\alpha, \beta_S,  \beta_W &\sim \mathcal{N(., .)}\\
\sigma &\sim \mathcal{Exponential(1)}
\end{align*}
$$


## 8M3 {-}

The relationship is that ravens depend on wolves for their food but the wolves
don't depend on the raven.  The question states that ravens depends on wolves.
It is not clear that they depend entirely as a parasite does for example.

**Set of data?**: The data would be one where ravens success increases as function of wolves
success.  It is not an interaction which would cause the presence of ravens and
wolves to impact their mutual success in a way similar as if a third variable
affected both and increase as well as decrease their mutual success.

**Linear interaction?**: It does not seem to be a statistical interaction as it is not symmetric as
explained in section 8.2.  Therefore the interaction would not be linear.

## 8M4 {-}

See comment in section 8.3.2, p. 254, about the fact that *basic botany informs
us that water should have a postivie slope and shade a negative slope*.

A quick glance at the data shows it is pretty evenly distributed. Therefore
it is not centering and scaling on sd is not that important.

What can simplify the problem by rescaling each variable on its maximum
value.  In addition, $shade$ will be multiplied by -1 to ensure it has a negative
impact.  As a result, the problem is simplified a bit as both rescaled $water$,
called $water_r = \frac{water}{max(water)}$and $light_r = \frac{-shade}{max(shade)}$
can have the same priors and are easily understood while being in line with
the constraints that $water_r$ has a beneficial effect and $shade_r$ has a
detrimental effect.

The $blooms$ variable is also rescaled as 
$blooms_r = \frac{blooms}{median(blooms)}$ as it allows to simplify the prior
$alpha$. `median` is used rather than `mean` because $bloom_r$ is heavily
skewed.

```{r}
data(tulips, package = "rethinking")
data08M04 <- tulips %>%
  mutate(water_r = water / max(water),
         light_r = -shade / max(shade),
         blooms_r = blooms / median(blooms))
rm(tulips)
skimr::skim(data08M04)
```

### Intercept prior {-}

Because of the transformation above, $water_r$ and $light_r$ have strictly positive
effect on blooms.  Therefore their minimum should match the minimum of
$blooms_r$ and their maximum to the maximum of $blooms_r$.  Therefore the 
intercept should be at the minimum of $blooms_r$ which is 0.

We will therefore use the prior

$$
\alpha \sim \mathcal{N}(1, 0.5)
$$


### Slope prior {-}


To simulate the priors' effect on the posterior prediction we will simulate
them with `simstudy`.  We could use the prior from `rethinking::quap()` or 
`brms::brm()` also.  Using `simstudy` avoids some issues with convergence
and is more obvious (my personal taste) as it shows that analysing priors is
just a straightforward simulation exercise.

Now we simulate the prior, without interaction

```{r}
set.seed(as.integer(as.Date("2021-11-20")))
sim <- list()
sim <- within(sim, {
  defs <- defData(varname = "water", dist = "uniform", formula = "0;1")
  defs <- defData(defs, varname = "light", dist = "uniform", formula = "0;1")
  defs <- defData(defs, varname = "alpha", dist = "normal", formula = 1, variance = 0.5^2)
  defs <- defData(defs, varname = "betaw", dist = "normal", formula = 1, variance = (1/2)^2)
  defs <- defData(defs, varname = "betal", dist = "normal", formula = 1, variance = (1/2)^2)
  defs <- defData(defs, varname = "betawl", dist = "normal", formula = 1, variance = (1/2)^2)
  defs <- defData(defs, varname = "slope", dist = "nonrandom", 
                  formula = "betaw * water + betal * light")
  defs <- defData(defs, varname = "mu", dist = "nonrandom", 
                  formula = "alpha + slope")
  data <- round(genData(n = 100, dtDefs = defs), 4)
})

# skimr::skim(sim$data)
```

```{r}
p <- list()
# sim$data %>%
#   filter(light %in% quantile(light, probs = c(0.5))
p$probs <- c(0.25, 0.5, 0.75)
p$df <- sim$data %>%
  mutate(light_grp = santoku::chop_quantiles(light, 
                                             probs = p$probs,
                                             santoku::lbl_intervals(raw = TRUE)))
# sum(p$df$sel)


p$plot <- ggplot(p$df, aes(x = water, group = id)) +
  geom_abline(data = p$df, mapping = aes(intercept = alpha, slope = slope),
              color = "pink", size = 1) +
  geom_hline(yintercept = range(data08M04$blooms_r), 
             size = 1, linetype = 2, color = "royalblue") +
  scale_color_manual(values = c("FALSE" = "pink", "TRUE" = "blue")) +
  coord_cartesian(ylim = c(min(data08M04$blooms_r) - 0.25, max(data08M04$blooms_r) + 0.25)) +
  theme_minimal() +
  labs(title = "8M4: Prior predictions by light interval - NO INTERACTION", 
       subtitle = sprintf("Simulation size = %d", nrow(p$df)),
       x = "water", y = "blooms") +
  facet_wrap(. ~ light_grp)
p$plot
```

and the prior with interaction are


```{r}
# when usaing update, do not use a list (!)
set.seed(as.integer(as.Date("2021-11-20")))
defsInteract <- sim$defs
defsInteract <- updateDef(dtDefs = defsInteract, changevar = "slope", 
                      newformula = "betaw * water + betal * light + betawl * water * light")
sim$dataInteract <- round(genData(n = 100, dtDefs = defsInteract), 4)
```



```{r}
pInteract <- list()
pInteract$probs <- p$probs
pInteract$df <- sim$dataInteract %>%
  mutate(light_grp = santoku::chop_quantiles(light, 
                                             probs = pInteract$probs,
                                             santoku::lbl_intervals(raw = TRUE)))
# sum(p$pInteract$sel)


pInteract$plot <- ggplot(pInteract$df, aes(x = water, group = id)) +
  geom_abline(data = pInteract$df, mapping = aes(intercept = alpha, slope = slope),
              color = "pink", size = 1) +
  geom_hline(yintercept = range(data08M04$blooms_r), 
             size = 1, linetype = 2, color = "royalblue") +
  scale_color_manual(values = c("FALSE" = "pink", "TRUE" = "blue")) +
  coord_cartesian(ylim = c(min(data08M04$blooms_r) - 0.25, max(data08M04$blooms_r) + 0.25)) +
  theme_minimal() +
  labs(title = "8M4: Prior predictions by light interval - WITH INTERACTION", 
       subtitle = sprintf("Simulation size = %d", nrow(p$df)),
       x = "water", y = "blooms") +
  facet_wrap(. ~ light_grp)
pInteract$plot
```


```{r}
p$all <- data.frame(p$df, model = "no interact") %>%
  bind_rows(data.frame(pInteract$df, model = "interact")) %>%
  select(alpha, slope, model) %>%
  # mutate(model = rep(c("plain", "interact"), times = c(nrow(p$df), nrow(pInteract$df)))) %>%
  pivot_longer(cols = c("alpha", "slope"), names_to = "param")
  # mutate(model = as.factor(model),
  #        param = as.factor(param))
# str(p$all)

p$stats <- p$all %>%
  group_by(model, param) %>%
  mutate(mean = mean(value),
         mode = ggdist::Mode(value))
```
```{r}
ggplot(p$all %>% filter(param == "slope"), aes(x = value, color = model)) +
  geom_density(size = 1) +
  geom_vline(data = p$stats %>% filter(param == "slope"), 
             aes(xintercept = mean, color = model),
             linetype = 2, size = 1) +
  geom_vline(data = p$stats %>% filter(param == "slope"), 
             aes(xintercept = mode, color = model),
             linetype = 3, size = 1) +
  theme_minimal() +
  theme(legend.position = c(0.8, 0.8)) +
  coord_cartesian(xlim = c(0, 2)) +
  labs(title = "Slope Comparison",
       subtitle = "8M4 (mode = doted line, mean = dashed line)")
```



### Conclusion {-}

When taking the interaction into account the prior seem to favor an increased 
slope. It is supported by the scientific knowledge that the effect of
$water$ and $light$ together should be higher than their simple addition.


## 8H1 {-}

```{r}
data(tulips, package = "rethinking")
d <- tulips %>%
  mutate(blooms_r = scales::rescale(blooms),  # rescale from 0 to 1
         water_c = as.vector(scale(water, scale = FALSE)),  # center the data
         shade_c = as.vector(scale(shade, scale = FALSE)))  # center the data
stopifnot(is.factor(d$bed))  # must be a factor to use with brms as category
rm(tulips)
skimr::skim(d)
```

### Model and fit {-}

$$
\begin{align*}
blooms\_r_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha_{bed[i]} + \beta_W \cdot water\_c_i+ \beta_S \cdot shade\_c_i \\
\alpha_{bed[i]} &\sim \mathcal{N}(0.5, 1) \\
\beta_W &\sim \mathcal{N}(0, 1) \\
\beta_S &\sim \mathcal{N}(0, 1) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$


```{r}
a_file <- here::here("fits", "b08H01.rds")
b08H01 <- readRDS(file = a_file)
# b08H01 <- brm(
#   data = d,
#   family = gaussian,
#   formula = blooms_r ~ 0 + bed + water_c + shade_c,
#   prior = c(prior(normal(0.5, 0.25), class = b),
#             prior(normal(0, 0.25), class = b, coef = water_c),
#             prior(normal(0, 0.25), class = b, coef = shade_c),
#             prior(exponential(1), class = sigma)),
#   iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H01 <- brms::add_criterion(b08H01, criterion = c("waic", "loo"))
# saveRDS(b08H01, file = a_file)
summary(b08H01)
```


## 8H2 {-}


```{r}
a_file <- here::here("fits", "b08H02.rds")
b08H02 <- readRDS(file = a_file)
# b08H02 <- brm(
#   data = d,
#   family = gaussian,
#   formula = blooms_r ~ 1 + water_c + shade_c,
#   prior = c(prior(normal(0.5, 0.25), class = Intercept),
#             prior(normal(0, 0.25), class = b),
#             prior(exponential(1), class = sigma)),
#   iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H02 <- brms::add_criterion(b08H02, criterion = c("waic", "loo"))
# saveRDS(b08H02, file = a_file)
summary(b08H02)
```


```{r}
w <- loo::loo_compare(b08H01, b08H02, criterion = "waic")
print(w, simplify = FALSE)
```

The water and shade effects are the same in both models. However the intercept 
when using the bed category will vary.  This will give a better fit
as illustrated by the waic comparison just above.


## 8H3 {-}


```{r}
data(rugged)
d <- rugged %>%
  filter(complete.cases(rgdppc_2000)) %>%
  mutate(log_gdp = log(rgdppc_2000),
         is_africa = if_else(cont_africa == 1, "Africa", "Not Africa"),
         is_africa = as.factor(is_africa),
         cid = if_else(cont_africa == 1, "1", "2"),
         cid = as.factor(cid),
         log_gdp_s = log_gdp / mean(log_gdp),
         rugged_s = scales::rescale(rugged),
         rugged_sc = as.vector(scale(rugged_s, center = TRUE, scale = FALSE))
         )
rm(rugged)
# glimpse(d)
```


> Errata: Model m8.5 is with the tulips data, not the rugged data.  It must be
model m8.3 that is meant.  See in first edition the practice 7H3.

Model m8.3 is as follows


$$
\begin{align*}
\log{(log\_gdp\_s_i)} &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha_{[cid]} + \beta_{[cid]} \cdot rugged\_sc_i \\
\alpha &\sim \mathcal{N}(1, 0.1) \\
\beta &\sim \mathcal{N}(0, 0.3) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

See section 8.1.3 on how to fit the b8.3 model which is the `brms` version of
m8.3.

```{r}
a_file <- here::here("fits", "b08H03.rds")
b08H03 <- readRDS(file = a_file)
# b08H03 <-
#   brm(data = d,
#       family = gaussian,
#       formula = bf(log_gdp_s ~ 0 + a + b * rugged_sc,
#          a ~ 0 + cid,
#          b ~ 0 + cid,
#          nl = TRUE),
#       prior = c(prior(normal(1, 0.1), class = b, coef = cid1, nlpar = a),
#                 prior(normal(1, 0.1), class = b, coef = cid2, nlpar = a),
#                 prior(normal(0, 0.3), class = b, coef = cid1, nlpar = b),
#                 prior(normal(0, 0.3), class = b, coef = cid2, nlpar = b),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H03 <- brms::add_criterion(b08H03, criterion = c("waic", "loo"))
# saveRDS(b08H03, file = a_file)
summary(b08H03)
```

### (a) {-}

See section 7.5.2 on how to show outliers


```{r}
dp <- tibble(pareto_k = b08H03$criteria$loo$diagnostics$pareto_k,
       p_waic = b08H03$criteria$waic$pointwise[, "p_waic"],
       country = d$country,
       is_africa = d$is_africa)
# glimpse(dp)
waic_max <- 0.3
k_max <- 0.3
ggplot(dp, aes(x = pareto_k, y = p_waic, color = is_africa)) +
  geom_vline(xintercept = waic_max, linetype = 2, color = "purple") +
  geom_hline(yintercept = k_max, linetype = 2, color = "purple") +
  geom_point() +
  ggrepel::geom_text_repel(data = . %>% filter(p_waic >= waic_max),
                           aes(label = country)) +
  scale_color_manual(values = c("Africa" = "darkgreen", "Not Africa" = "violetred")) +
  scale_shape_manual(values = c(19, 19)) +
  theme_minimal() +
  theme(legend.position = c(0.1, 0.85),
        legend.title = element_blank(),
        title = element_text(color = "midnightblue")) +
  labs(title = "Practice 8H3 (a)",
       subtitle = deparse1(b08H03$formula$formula))
```
Beside Seychelles, Swizterland is also an outlier.  Probably because Switzerland
has a high GDP in spite of being rugged.

### (b) {-}

See section 7.5.2 on ow to do the robust regression with student distribution.

```{r}
a_file <- here::here("fits", "b08H03t.rds")
b08H03t <- readRDS(file = a_file)
# b08H03t <-
#   brm(data = d,
#       family = student,
#       formula = bf(log_gdp_s ~ 0 + a + b * rugged_sc,
#          a ~ 0 + cid,
#          b ~ 0 + cid,
#          nl = TRUE,
#          nu = 2),
#       prior = c(prior(normal(1, 0.1), class = b, coef = cid1, nlpar = a),
#                 prior(normal(1, 0.1), class = b, coef = cid2, nlpar = a),
#                 prior(normal(0, 0.3), class = b, coef = cid1, nlpar = b),
#                 prior(normal(0, 0.3), class = b, coef = cid2, nlpar = b),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H03t <- brms::add_criterion(b08H03t, criterion = c("waic", "loo"))
# saveRDS(b08H03t, file = a_file)
summary(b08H03t)
```

and comparing the results


```{r}
w <- loo::loo_compare(b08H03, b08H03t, criterion = "waic")
print(w, simplify = FALSE)
```
Therefore the Student distribution has less precision . . . but is more robust.
That is, it is less impacted by outliers.  This is a clasic trade-off between
precision and robustness.


and to visualize the outliers which have much less impact now we have
the following plot


```{r}
dp <- tibble(pareto_k = b08H03t$criteria$loo$diagnostics$pareto_k,
       p_waic = b08H03t$criteria$waic$pointwise[, "p_waic"],
       country = d$country,
       is_africa = d$is_africa)
# glimpse(dp)
waic_max <- 0.3
k_max <- 0.3
ggplot(dp, aes(x = pareto_k, y = p_waic, color = is_africa)) +
  geom_vline(xintercept = waic_max, linetype = 2, color = "purple") +
  geom_hline(yintercept = k_max, linetype = 2, color = "purple") +
  geom_point() +
  ggrepel::geom_text_repel(data = . %>% filter(p_waic >= waic_max),
                           aes(label = country)) +
  scale_color_manual(values = c("Africa" = "darkgreen", "Not Africa" = "violetred")) +
  scale_shape_manual(values = c(19, 19)) +
  theme_minimal() +
  theme(legend.position = c(0.1, 0.85),
        legend.title = element_blank(),
        title = element_text(color = "midnightblue")) +
  labs(title = "Practice 8H3 (b) - Student distribution",
       subtitle = deparse1(b08H03t$formula$formula))
```
## 8H4 {-}

As required in the question, we use $log(lang.per.cap)$. This gives
$lang.per.cap.log \in [-10,0]$.  To avoid the negative outcome which cause
a positive slope (required by our hypothesis), we rescale $lang.per.cap.log$
to be in $[0,10]$

We also rescale $mean.growing.season$ and $sd.growing.season$ to $[0,10]$


```{r}
data(nettle)
d <- nettle %>%
  mutate(area.log = scales::rescale(log(area), to = c(0, 10)),
         mean.growing.season = scales::rescale(mean.growing.season, to = c(0, 10)),
         sd.growing.season = scales::rescale(sd.growing.season, to = c(0, 10)),
         lang.per.cap = num.lang / k.pop,
         lang.per.cap.log = scales::rescale(log(lang.per.cap), to = c(0, 10)))
rm(nettle)
skimr::skim(d)
```


### (a) {-}

#### The priors {-}

See section 8.1.1 on how to estimate the priors.

Since $lang.per.cap.log \in [0,10]$ with mean about 5 then we use
$\alpha \sim \mathcal{N}(5,2.5)$.

Since $lang.per.cap.log \in [0,10]$ $mean.growing.season \in [0,10]$ 
which gives a maximum slope of $\frac{10-0}{10-0} \approx 1$ which should be a 
positive slope since we have the hypothesis that language diversity increases 
with the $mean.growing.season$. Therefore $\beta_{GM} &\sim \mathcal{N}(0.5,0.25)$

Similarly, since $lang.per.cap.log \in [0,10]$ and $area.log \in [0,10]$ 
which gives a maximum slope of $\frac{10-0}{10-0} = 1$ which should be 
positive slope since we have the hypothesis that language diversity increases with the $area.log$.
Therefore $\beta_{A} &\sim \mathcal{N}(0.5,0.25)$


#### The models {-}

We will create 4 models who are variations of the following full model

$$
\begin{align*}
lang.per.cap.log_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_{GM} \cdot mean.growing.season_i + \beta_A \cdot area.log_i \\
\alpha &\sim \mathcal{N}(5,2.5) \\
\beta_{GM} &\sim \mathcal{N}(0.5,0.25) \\
\beta_{A} &\sim \mathcal{N}(0.5,0.25) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$


#### The fit {-}

The *null* model

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a0.rds")
b08H04a0 <- readRDS(file = a_file)
# b08H04a0 <- brm(
#   data = d,
#   formula = lang.per.cap.log ~ 1,
#   family = gaussian,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),
#   seed = 8
# )
# b08H04a0 <- brms::add_criterion(b08H04a0, criterion = c("waic", "loo"))
# saveRDS(b08H04a0, file = a_file)
print(b08H04a0, digits = 3)
```


with the *mean.growing.season* effect

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a1.rds")
b08H04a1 <- readRDS(file = a_file)
# b08H04a1 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + mean.growing.season,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "mean.growing.season"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04a1 <- brms::add_criterion(b08H04a1, criterion = c("waic", "loo"))
# saveRDS(b08H04a1, file = a_file)
print(b08H04a1, digits = 3)
```

with the *area.log* effect

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a2.rds")
b08H04a2 <- readRDS(file = a_file)
# b08H04a2 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + area.log,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "area.log"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04a2 <- brms::add_criterion(b08H04a2, criterion = c("waic", "loo"))
# saveRDS(b08H04a2, file = a_file)
print(b08H04a2, digits = 3)
```

with both *mean.growing.season* and *area.log*


```{r}
a_file <- here::here(getwd(), "fits", "b08H04a3.rds")
b08H04a3 <- readRDS(file = a_file)
# b08H04a3 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + mean.growing.season + area.log,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "mean.growing.season"),
#     prior(normal(0.5, 0.25), class = b, coef = "area.log"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04a3 <- brms::add_criterion(b08H04a3, criterion = c("waic", "loo"))
# saveRDS(b08H04a3, file = a_file)
print(b08H04a3, digits = 3)
```


#### Validate the priors {-}



```{r}
set.seed(8)
b08H04a1_prior <- prior_samples(b08H04a1)
# glimpse(b08H04a1_prior)
pd <-
  b08H04a1_prior %>%
  slice_sample(n = 50) %>%
  tibble::rownames_to_column() %>%
  expand(nesting(rowname, Intercept, b_mean.growing.season), mean.growing.season = c(0, 10)) %>%
  mutate(lang.per.cap.log = Intercept + b_mean.growing.season * mean.growing.season)
         # rugged_s  = rugged_sc + mean(dd$rugged_s))
glimpse(pd)

p1 <- ggplot(pd, aes(x = mean.growing.season, y = lang.per.cap.log, group = rowname)) +
  geom_line(color = "lavender") +
  geom_hline(yintercept = range(d$lang.per.cap.log),
             size = 1, linetype = 2, color = "royalblue") +
  coord_cartesian(xlim = c(0, 10), ylim = c(-5, 15)) +
  labs(
    subtitle = "Intercept ~ dnorm(5, 2.5)\nb ~ dnorm(0.5, 0.25)",
    x = "mean.growing.season",
    y = "lang.per.cap.log") +
  ggthemes::theme_hc()
# p1
b08H04a2_prior <- prior_samples(b08H04a2)
pd <-
  b08H04a2_prior %>%
  slice_sample(n = 50) %>%
  tibble::rownames_to_column() %>%
  expand(nesting(rowname, Intercept, b_area.log), area.log = c(0, 10)) %>%
  mutate(lang.per.cap.log = Intercept + b_area.log * area.log)
p2 <- ggplot(pd, aes(x = area.log, y = lang.per.cap.log, group = rowname)) +
  geom_line(color = "lavender") +
  geom_hline(yintercept = range(d$lang.per.cap.log),
             size = 1, linetype = 2, color = "royalblue") +
  coord_cartesian(xlim = c(0, 10), ylim = c(-5, 15)) +
  labs(
    subtitle = "Intercept ~ dnorm(5, 2.5)\nb ~ dnorm(0.75, 0.5)",
    x = "area.log",
    y = "lang.per.cap.log") +
  ggthemes::theme_hc()
# p2
p1 + p2
```

#### Compare the models {-}

```{r}
w <- loo::loo_compare(b08H04a0, b08H04a1, b08H04a2, b08H04a3, criterion = "waic")
print(w, simplify = FALSE)
```

with the models' weights

```{r}
brms::model_weights(b08H04a0, b08H04a1, b08H04a2, b08H04a3, weights = "waic") %>% 
  round(digits = 3)
```
which seems to indicate that the model with `mean.growing.season` is the most
informative.  A mix of the univariate model with `mean.growing.season` and the
multivariate model can be considered based on the weights.

Given that the `elpd_diff` for b08H04a3 is -0.6 which exceeds the `se_diff` of
b08H04a1 then we select b08H04a1 as our model of choice.


#### Plotting the model



```{r}
b08H04a_seq <- data.frame(
  mean.growing.season = seq(from = 0, to = 10, length.out = 30))
# glimpse(b08H04a_seq)
b08H04a_fitted <- fitted(b08H04a1, newdata = b08H04a_seq, probs = c(0.015, 0.985)) %>%
  data.frame() %>%
  bind_cols(b08H04a_seq)
# glimpse(b08H04a_fitted)
```


```{r}
ggplot(d, aes(x = mean.growing.season, 
              y = lang.per.cap.log)) +
  geom_point(aes(size = area.log, color = mean.growing.season)) +
  geom_smooth(data = b08H04a_fitted, aes(x = mean.growing.season, y = Estimate, 
                                         ymin = Q1.5, ymax = Q98.5),
              fill = "slategray1",
              color = "slateblue1",
              stat = "identity",
              alpha = 1/4, size = 1) +
  scale_color_paletteer_c(palette = "grDevices::Heat") +
  theme_minimal() +
  theme(legend.position = "right") +
  labs(title = "8H4 (a)", 
       subtitle = paste("b08H04a1:", deparse1(b08H04a1$formula$formula)),
       x = "mean.growing.season (rescaled on [0,10])",
       y = "lang.per.cap (log)",
       size = "log.area", color = "sd")
```


### (b) {-}

Using the same process as in (a) just above

#### The fit {-}

The *null* model, same as in (a) above

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a0.rds")
b08H04a0 <- readRDS(file = a_file)
print(b08H04a0, digits = 3)
```


with the *sd.growing.season* effect

```{r}
a_file <- here::here(getwd(), "fits", "b08H04b1.rds")
b08H04b1 <- readRDS(file = a_file)
# b08H04b1 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + sd.growing.season,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "sd.growing.season"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04b1 <- brms::add_criterion(b08H04b1, criterion = c("waic", "loo"))
# saveRDS(b08H04b1, file = a_file)
print(b08H04b1, digits = 3)
```

with the *area.log* effect, same as before in (a)

```{r}
a_file <- here::here(getwd(), "fits", "b08H04a2.rds")
b08H04a2 <- readRDS(file = a_file)
print(b08H04a2, digits = 3)
```

with both *sd.growing.season* and *area.log*


```{r}
a_file <- here::here(getwd(), "fits", "b08H04b3.rds")
b08H04b3 <- readRDS(file = a_file)
# b08H04b3 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + sd.growing.season + area.log,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "sd.growing.season"),
#     prior(normal(0.5, 0.25), class = b, coef = "area.log"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04b3 <- brms::add_criterion(b08H04b3, criterion = c("waic", "loo"))
# saveRDS(b08H04b3, file = a_file)
print(b08H04b3, digits = 3)
```


#### Compare the models {-}

```{r}
w <- loo::loo_compare(b08H04a0, b08H04b1, b08H04a2, b08H04b3, criterion = "waic")
print(w, simplify = FALSE)
```

with the models' weights

```{r}
brms::model_weights(b08H04a0, b08H04b1, b08H04a2, b08H04b3, weights = "waic") %>% 
  round(digits = 3)
```
In this case, the elpd_diff are very small and the model weights similar.  None of
the effects, even together seem to make a big difference.

Therefore the anayliss support the hypothesis that $sd.gorwing.season$ has a
negative effect on language diversity.  However this effect seems rather small
with a higher degree of certeinty than the $mean.growing.season$ effect.


#### Plotting the model

We use the model b08H4b1 to visualize, there is so little elpd_diff with the
other models that its use is no worse than using the other models.

```{r}
b08H04b_seq <- data.frame(
  sd.growing.season = seq(from = 0, to = 10, length.out = 30))
# glimpse(b08H04b_seq)
b08H04b_fitted <- fitted(b08H04b1, newdata = b08H04b_seq, probs = c(0.015, 0.985)) %>%
  data.frame() %>%
  bind_cols(b08H04b_seq)
# glimpse(b08H04b_fitted)
```


```{r}
ggplot(d, aes(x = sd.growing.season, 
              y = lang.per.cap.log)) +
  geom_point(aes(size = area.log, color = mean.growing.season)) +
  geom_smooth(data = b08H04b_fitted, aes(x = sd.growing.season, y = Estimate, 
                                         ymin = Q1.5, ymax = Q98.5),
              fill = "wheat1",
              color = "tan1",
              stat = "identity",
              alpha = 1/4, size = 1) +
  scale_color_paletteer_c(palette = "grDevices::Heat 2") +
  theme_minimal() +
  theme(legend.position = "right") +
  labs(title = "8H4 (b)", 
       subtitle = paste("b08H04b1:", deparse1(b08H04b1$formula$formula)),
       x = "sd.growing.season (rescaled on [0,10])",
       y = "lang.per.cap (log)",
       size = "log.area", color = "mean")
```


### (c) {-}

Now using an interaction between $mean.growing.season$ and $sd.growing.season$
we have the following model


$$
\begin{align*}
lang.per.cap.log_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_{M} \cdot mean.growing.season_i + 
 \beta_{S} \cdot sd.growing.season_i + 
 \beta_{MS} \cdot mean.growing.season_i \cdot sd.growing.season_i \\
\alpha &\sim \mathcal{N}(5,2.5) \\
\beta_{GM} &\sim \mathcal{N}(0.5,0.25) \\
\beta_{GS} &\sim \mathcal{N}(0.5,0.25) \\
\beta_{MS} &\sim \mathcal{N}(0.5,0.25) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

```{r}
a_file <- here::here(getwd(), "fits", "b08H04c1.rds")
b08H04c1 <- readRDS(file = a_file)
# b08H04c1 <- update(
#   object = b08H04a0,
#   newdata = d,
#   formula = lang.per.cap.log ~ 1 + mean.growing.season + sd.growing.season + 
#     mean.growing.season:sd.growing.season,
#   prior = c(
#     prior(normal(5, 2.5), class = Intercept),
#     prior(normal(0.5, 0.25), class = b, coef = "mean.growing.season"),
#     prior(normal(0.5, 0.25), class = b, coef = "sd.growing.season"),
#     prior(normal(0.5, 0.25), class = b, coef = "mean.growing.season:sd.growing.season"),
#     prior(exponential(1), class = sigma)
#   ),
#   sample_prior = TRUE,
#   seed = 8
# )
# b08H04c1 <- brms::add_criterion(b08H04c1, criterion = c("waic", "loo"))
# saveRDS(b08H04c1, file = a_file)
print(b08H04c1, digits = 3)
```

#### Compare the models {-}

```{r}
w <- loo::loo_compare(b08H04a0, b08H04a1, b08H04a2, b08H04a3, 
                      b08H04b1, b08H04b3,
                      b08H04c1, criterion = "waic")
print(w, simplify = FALSE)
```

with the models' weights

```{r}
brms::model_weights(b08H04a0, b08H04a1, b08H04a2, b08H04a3, 
                      b08H04b1, b08H04b3,
                      b08H04c1, weights = "waic") %>% 
  round(digits = 3)
```
In this case, the comparison is in favor of the model with interactions
between $mean.growing.season$ and $sd.growing.season$.  The model is actually
better than all models considered so far. The difference is significant as
all other models have a `elpd_diff` greater than `se_diff`.

Therefore the hypotheses defined in (c) seems to be the best one.


#### Plotting

```{r}
b08H04c_seq <- crossing(
  mean.growing.season = seq(from = 0, to =10, length.out = 20), 
  sd.growing.season = seq(from = 0, to = 10, length.out = 6))

b08H04c_fitted <- fitted(b08H04c1, newdata = b08H04c_seq, probs = c(0.015, 0.985)) %>%
  data.frame() %>%
  bind_cols(b08H04c_seq) %>%
  mutate(
    id = sprintf("sd = %02d", sd.growing.season)
  ) %>%
  arrange(id)
glimpse(b08H04c_fitted)
```

```{r}
ggplot(b08H04c_fitted, aes(x = mean.growing.season, y = Estimate, ymin = Q1.5, ymax = Q98.5)) +
  geom_smooth(stat = "identity", fill = "aquamarine",
              alpha = 1/4, size = 1/2) +
  # geom_point(data = d, color = "steelblue") +
  # scale_x_continuous(breaks = c(-1, 0, 1)) +
  # scale_y_continuous(breaks = c(0, .5, 1)) +
  # coord_cartesian(xlim = c(-1, 1), ylim = c(0, 1)) +
  theme_minimal() +
  theme(legend.position = "none",
        strip.background = element_rect(fill = "lightsalmon")) +
  labs(title = "8H4 (c)", 
       subtitle = paste("b08H04c1:", deparse1(b08H04c1$formula$formula)),
       x = "sd.growing.season (rescaled on [0,10])", y = "ang.per.cap (log)") +
  facet_wrap(. ~ id, nrow = 2)
```



## 8H5 {-}

```{r}
data(Wines2012)
d <- Wines2012 %>%
  mutate(flight = as.factor(flight),
         judge.a = ifelse(judge.amer == 0, "NotAmJudge", "AmJudge"),
         wine.a = ifelse(wine.amer == 0, "NotAmWine", "AmWine"),
         judge.a = as.factor(judge.a),
         wine.a = as.factor(wine.a),
         score.s = as.vector(scale(score)))
rm(Wines2012)
skimr::skim(d)
# glimpse(d)
```

We have to use index variables with 2 variables.  See @kurtz2020b in his
section 5.3.2 with model b5.11.

```{r}
a_file <- here::here(getwd(), "fits", "b08H05a.rds")
b08H05a <- readRDS(file = a_file)
# b08H05a <-
#   brm(data = d,
#       family = gaussian,
#       formula = bf(score.s ~ 0 + j + w,
#                    j ~ 0 + judge,
#                    w ~ 0 + wine,
#                    nl = TRUE),
#       prior = c(prior(normal(0, 0.5), nlpar = j),
#                 prior(normal(0, 0.5), nlpar = w),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H05a <- brms::add_criterion(b08H05a, criterion = c("waic", "loo"))
# saveRDS(b08H05a, file = a_file)
print(b08H05a, digits = 3)
```
```{r}
b08H05_fitted <- fitted(b08H05a) %>%
  as_tibble()
glimpse(b08H05_fitted)
```

```{r}
get_variables(b08H05a)
```

```{r}
df <- b08H05a %>%
  posterior_samples() %>%
  select(-sigma, -lp__) %>%
  pivot_longer(cols = everything(), names_to = "vars") %>%
  group_by(vars) %>%
  summarize(y = ggdist::mean_hdi(value, width = 0.97)[1, "y"],
            ymin = ggdist::mean_hdi(value, width = 0.97)[1, "ymin"],
            ymax = ggdist::mean_hdi(value, width = 0.97)[1, "ymax"]) %>%
  mutate(is_wine = grepl(pattern = "^b_w_", x = vars),
         id = gsub(pattern = "b_w_|b_j_|judge", replacement = "", x = vars))
glimpse(df)

ggplot(data = df, aes(x = id, y = y, ymin = ymin, ymax = ymax, color = is_wine)) +
  geom_pointinterval() +
  ggrepel::geom_text_repel(aes(label = round(y, 2)), size = 3) +
  scale_color_manual(values = c("FALSE" = "blue", "TRUE" = "red")) + 
  coord_flip() +
  theme_classic() +
  theme(legend.position = "none") +
  labs(title = "8H5: Coeficient plot",
       x = NULL,
       y = "mean and hdi interval of width 97%")
  # facet_wrap(. ~ is_wine)
```

The heatmap in this case will help answer the questions

```{r}
pd <- d %>%
  select(judge, wine, score.s) %>%
  pivot_wider(names_from = judge, values_from = score.s) %>%
  tibble::column_to_rownames("wine") %>%
  as.matrix()
# glimpse(pd)
pheat <- superheat::superheat(X = pd, 
                              X.text = round(pd, 2), X.text.size = 3,
                              clustering.method = "hierarchical",
                              bottom.label.text.size = 3,
                              bottom.label.text.angle = 30,
                              bottom.label.text.alignment = "right",
                              left.label.text.size = 3,
                              title = "Wine Heatmap")
pheat
```
How to interpret variations: Some judges, such as JeanMMCaderbat and Robert Hodgston 
have generally more negative views whereas John Foy if genrally more positive

Notice patterns: Yes wine I2 seems to be an outlier and John Foy more positive than all other judges.

Best rated wines: B2

Worst rated wine: I2


## 8H6 {-}


For `brms` formula, see similar treatment in 8H5 just above

```{r}
a_file <- here::here(getwd(), "fits", "b08H06a.rds")
b08H06a <- readRDS(file = a_file)
# b08H06a <-
#   brm(data = d,
#       family = gaussian,
#       formula = bf(score.s ~ 0 + f + j + w,
#                    f ~ 0 + flight,
#                    j ~ 0 + judge.a,
#                    w ~ 0 + wine.a,
#                    nl = TRUE),
#       prior = c(prior(normal(0, 0.5), nlpar = f),
#                 prior(normal(0, 0.5), nlpar = j),
#                 prior(normal(0, 0.5), nlpar = w),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(), seed = 8)
# b08H06a <- brms::add_criterion(b08H06a, criterion = c("waic", "loo"))
# saveRDS(b08H06a, file = a_file)
print(b08H06a, digits = 3)
```

American judges seem to be generally more favorable than non American ones.
American wine seem t obtain a more negative score on average.

Whether the wine is red or wine seems to have little effect.

The favorable american judge effect could be related to judge John Foy
as mentioned in the previous problem.

## 8H7 {-}


```{r echo=FALSE}
message("TODO")
```
