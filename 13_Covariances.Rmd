```{r include=FALSE}
library(rethinking)
library(brms)
library(tidybayes)
library(tidyr)
library(dplyr)
library(ggplot2)
library(bayesplot)
```


# Adventures in Covariance {#Covariance}



## Varying slopes by construction


### Simulate the population

```{r}
a <- 3.5  # average morning wait time
b <- -1  # average difference afternoon wait time
sigma_a <- 1  # std dev of intercepts
sigma_b <- 0.5  # std dev of slopes
rho_val <- -0.7  # correlation between intercepts and slopes

# these lines simply combines the constants just above
mu <- c(a, b)  # vector of means
cov_ab <- sigma_a * sigma_b * rho_val
```


McElrath mentions a difficulty using the `matrix` function.  He misses that there 
is the argument `byrow` which resolve this.

```{r}
# use byrow = TRUE to solve McElrath's issue
matrix(1:4, nrow = 2, ncol = 2, byrow = TRUE)
```

we get the covariance matrix `sigma` as follows

```{r}
sigmas <- c(sigma_a, sigma_b)  # vector of sigmas
rho <- matrix(c(1, rho_val, rho_val, 1), nrow = 2)  # matrix of correlation
sigma <- diag(sigmas) %*% rho %*% diag(sigmas)
```


and we simulate the bivariate normal distribution

```{r}
n_cafes <- 20
set.seed(13)
vary_effects <- MASS::mvrnorm(n = n_cafes, mu = mu, Sigma = sigma) %>%
  as_tibble() %>%
  rename("a_cafe" = V1,
         "b_cafe" = V2) %>%
  mutate(cafe = seq_len(n_cafes)) %>%
  relocate(cafe, after = 0)
str(vary_effects)
```

and we plot the simulated data which represents the intercept and slope

```{r}
ggplot(vary_effects, aes(x = a_cafe, y = b_cafe)) +
  geom_point() +
  ggthemes::theme_solarized() +
  # stat_density2d(aes(color = ..level..)) +
  stat_ellipse(type = "norm", level = 0.25, linetype = "dotted", size = 0.25) +
  stat_ellipse(type = "norm", level = 0.50, linetype = "dotted", size = 0.25) +
  stat_ellipse(type = "norm", level = 0.75, linetype = "dotted", size = 0.25) +
  theme(legend.position = "none") +
  labs(title = sprintf("Distribution of intercept and slopes for %d cafes", n_cafes),
       x = "intercepts (a_cafe)", y = "slope (b_cafe)")
```


### Simulate the observations (visits by cafe)

Now using the simulated intercepts and slopes, we create the simulated visits
to each cafe.


```{r}
n_visits <- 10  # nb of visits to each cafe by robot
sigma <- 0.5  # std dev within cafes

set.seed(13)
d <- vary_effects %>%
  expand(nesting(cafe, a_cafe, b_cafe), visit = seq_len(n_visits)) %>%
  mutate(afternoon = rep(0:1, times = n()/2)) %>%
  mutate(mu = a_cafe + b_cafe * afternoon) %>%
  mutate(wait = rnorm(n = n(), mean = mu, sd = sigma))
```

and plot the simulated observations. We first create dataframe used for plotting

```{r}
pdf <- d %>%
  mutate(afternoon = if_else(afternoon == 0, "M", "A"),
         day = rep(rep(1:5, each = 2), times = n_cafes),
         cafe = paste("cafe", cafe)) %>%
  filter(cafe %in% c("cafe 3", "cafe 5"))
# str(pdf)
```

and we create he plot

```{r}
ggplot(pdf, aes(x = visit, y = wait, group = day)) +
  geom_point(aes(color = afternoon), size = 2) +
  geom_line(color = "green") +
  scale_color_manual(values = c("M" = "royalblue", "A" = "hotpink")) +
  ggthemes::theme_solarized_2() +
  theme(legend.position = "none") +
  labs(title = "Varying slopes simulation") +
  facet_wrap(~ cafe, ncol = 1)
```

### The varying slopes model


#### The model

$$
wait_i \sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i = \alpha_{cafe[i]} + \beta_{cafe[i]} \cdot afternoon_i \\
\begin{bmatrix}
\alpha_{cafe} \\
\beta_{cafe}
\end{bmatrix}
\sim
\mathcal{MVNormal}(
\begin{bmatrix}
\alpha \\
\beta
\end{bmatrix}
,
\textbf{S}
) \\
S=
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta}
\end{bmatrix}
\begin{bmatrix}
1 & \rho \\
\rho & 1
\end{bmatrix}
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta}
\end{bmatrix} \\
\alpha \sim \mathcal{N}(0, 10) \\
\beta \sim \mathcal{N}(0, 10) \\
\sigma \sim \mathcal{HalfCauchy}(0, 1) \\
\sigma_{\alpha} \sim \mathcal{HalfCauchy}(0, 1) \\
\sigma_{\beta} \sim \mathcal{HalfCauchy}(0, 1) \\
\begin{bmatrix}
1 & \rho \\
\rho & 1
\end{bmatrix} \sim \mathcal{LKJcorr}(K=2, \eta=2)
$$

#### The fit

```{r}
a_file <- here::here("fits", "b13_01.rds")  # rds file location
stopifnot(file.exists(a_file))
b13.1 <- readRDS(file = a_file)  # load the file
# b13.1 <- brm(data = d, 
#              family = gaussian,
#              wait ~ 1 + afternoon + (1 + afternoon | cafe),
#              prior = c(prior(normal(0, 10), class = Intercept),
#                        prior(normal(0, 10), class = b),
#                        prior(cauchy(0, 2), class = sd),
#                        prior(cauchy(0, 2), class = sigma),
#                        prior(lkj(2), class = cor)),
#              iter = 5000, warmup = 2000, chains = 2, cores = 2,
#              seed = 13)
# b13.1 <- add_criterion(b13.1, c("loo", "waic"))
# saveRDS(object = b13.1, file = a_file)
```


and we use the posterior sample to assess the posterior correlation vs
the prior correlation


```{r}
bpost13.1 <- posterior_samples(b13.1)
str(bpost13.1)
```
```{r}
df_lki <- rlkjcorr(n = nrow(bpost13.1), K = 2, eta = 2) %>%
  as_tibble()
```


and plot for the correlations is

```{r}
ggplot(data = bpost13.1, aes(x = cor_cafe__Intercept__afternoon)) +
  geom_density(data = df_lki, aes(x = V2, y = ..scaled..),
               color = "transparent", fill = "rosybrown1", alpha = 1/3) +
  geom_density(aes(y = ..scaled..), color = "transparent", 
               fill = "rosybrown", alpha = 2/3) +
  # geom_text(data = tibble(x     = c(.83, .62, .46),
  #                         y     = c(.54, .74, 1),
  #                         label = c("eta = 1", "eta = 2", "eta = 4")),
  #           aes(x = x, y = y, label = label),
  #           color = "#A65141", family = "Courier") +
  theme_classic() +
  labs(title = expression(posterior ~ rho ~ vs ~ prior ~ rho),
       x = expression(rho), y = "density")
```


and the posterior intercept and slope by cafe is given by the `Estimate` of each dataframe
of `Intercept` and `afternoon` which is the `Slope`.  This is important to remember
as the `morning` is therefore the intercept and the afternnon is the `Intercept`
 with the `Slope`

```{r}
# str(coef(b13.1)$cafe)
# coef(b13.1)$cafe
# coef(b13.1)$cafe[, 1, 1:2]
# First lets identify what is the Intercept and the slope
# and what is the morning (same as Intercept) and the afternoon
# which is the Intercpet + the Slope
partial_pooled_params <- coef(b13.1)$cafe[, 1, 1:2] %>%
  as_tibble() %>%
  mutate(cafe = seq_len(n())) %>%
  relocate(cafe, after = 0) %>%
  rename(Slope = afternoon) %>%
  mutate(morning = Intercept,
         afternoon= Intercept + Slope,
         id = "partpooled")
partial_pooled_params
```

the intercept and slope from the raw data is obtained simply by putting
the mean waiting time as `Intercept`, from the morning wait, and `Slope`
from the difference between the morning and afternoon.


```{r}
un_pooled_params <- d %>%
  group_by(cafe, afternoon) %>%
  summarise(wait = mean(wait)) %>%
  ungroup() %>%
  mutate(afternoon = ifelse(afternoon == 0, "morning", "afternoon")) %>%
  pivot_wider(id_cols = "cafe", names_from = "afternoon", values_from = "wait") %>%
  mutate(Intercept = morning,
         Slope = afternoon - morning,
         id = "unpooled") %>%
  relocate(cafe, Intercept, Slope, after = 0)
un_pooled_params
```

and we put the 2 dataframe, partially pooled which is the model, and the unpooled
which is the raw data together

```{r}
params <- partial_pooled_params %>%
  bind_rows(un_pooled_params)
params
stopifnot(nrow(params) == nrow(partial_pooled_params) + nrow(un_pooled_params))
```

#### Plot the fit vs the simulated data

And we create the 2 plots


```{r}
p1 <-
  ggplot(data = params, aes(x = Intercept, y = Slope)) +
  # nesting `stat_ellipse()` within `mapply()` is a less redundant way to produce the 
  # ten-layered semitransparent ellipses we did with ten lines of `stat_ellipse()` 
  # functions in the previous plot
  mapply(function(level) {
    stat_ellipse(geom  = "polygon", type = "norm",
                 size  = 0, alpha = 1/20, fill = "green",
                 level = level)
    }, 
    # enter the levels here
    level = c(seq(from = 1/10, to = 9/10, by = 1/10), .99)) +
  geom_point(aes(group = cafe, color = id)) +
  geom_line(aes(group = cafe), size = 1/4) +
  scale_color_manual(values = c("partpooled" = "blue", "unpooled" = "red")) +
  coord_cartesian(xlim = range(params$Intercept),
                  ylim = range(params$Slope)) +
  theme_light() +
  labs(title = "Shrinkage in 2 dimensions - Partially pooled vs Unpooled",
       subtitle = sprintf("%d cafes", n_cafes),
       x = "Intercept",
       y = "Slope",
       color = NULL)
# p1
```





```{r}
p2 <-
  ggplot(data = params, aes(x = morning, y = afternoon)) +
  # nesting `stat_ellipse()` within `mapply()` is a less redundant way to produce the 
  # ten-layered semitransparent ellipses we did with ten lines of `stat_ellipse()` 
  # functions in the previous plot
  mapply(function(level) {
    stat_ellipse(geom  = "polygon", type = "norm",
                 size  = 0, alpha = 1/20, fill = "yellow",
                 level = level)
    }, 
    # enter the levels here
    level = c(seq(from = 1/10, to = 9/10, by = 1/10), .99)) +
  geom_point(aes(group = cafe, color = id)) +
  geom_line(aes(group = cafe), size = 1/4) +
  scale_color_manual(values = c("partpooled" = "blue", "unpooled" = "red")) +
  coord_cartesian(xlim = range(params$morning),
                  ylim = range(params$afternoon)) +
  theme_light() +
  labs(title = "Shrinkage in 2 dimensions - Partially pooled vs Unpooled",
       subtitle = sprintf("%d cafes", n_cafes),
       x = "morning average wait time in min.",
       y = "afternoon average wait time in min.",
       color = NULL)
# p2
```


which together gives

```{r}
cowplot::plot_grid(p1 + theme(legend.position = "none") + labs(title = NULL, subtitle = NULL), 
                   p2 + theme(legend.position = "none") + labs(title = NULL, subtitle = NULL))
```




## Example: Admission decisions and gender

```{r}
data(UCBadmit)
d <- UCBadmit
d <- d %>%
  mutate(male = as.integer(applicant.gender == "male"),
         dept_id = rethinking::coerce_index(dept))
str(d)
```

```{r}
ggplot(d, aes(x = applications, y = reject, color = applicant.gender)) +
  geom_point() +
  theme_classic() +
  labs(title = "Student Admissions at UC Berkeley",
       color = "Gender")
```




### Varying intercepts

$$
admit_i \sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) = \alpha_{dept[i]} + \beta m_i \\
\alpha_{dept} \sim \mathcal{N}(\alpha, \sigma) \\
\alpha \sim \mathcal{N}(0, 10) \\
\beta \sim \mathcal{N}(0, 1) \\
\sigma \sim \mathcal{HalfCauchy}(0, 2)
$$


```{r}
a_file <- here::here("fits", "b13_02.rds")  # rds file location
stopifnot(file.exists(a_file))
b13.2 <- readRDS(file = a_file)  # load the file
# b13.2 <- 
#   brm(data = d, 
#       family = binomial,
#       admit | trials(applications) ~ 1 + male + (1 | dept_id),
#       prior = c(prior(normal(0, 10), class = Intercept),
#                 prior(normal(0, 1), class = b),
#                 prior(cauchy(0, 2), class = sd)),
#       iter = 4500, warmup = 500, chains = 3, cores = 3,
#       seed = 13,
#       control = list(adapt_delta = .99))
# b13.2 <- add_criterion(b13.2, c("loo", "waic"))
# saveRDS(object = b13.2, file = a_file)
```

```{r}
b13.2
```

using `tidybayes` we can obtain the information in proper format.

First the list of variables

```{r}
tidybayes::get_variables(b13.2)
```

and we get the posterior samples using `tidybayes::spread_draws` which is the same
as `brms::posterior_samples`. `spread_draws` gives 72000 rows because it is in the
long format and therefore repeats each of the 6 departments for the 12000 samples
which are actually returned by `posterior_samples`.

```{r}
tidybayes::spread_draws(b13.2, b_Intercept, b_male, r_dept_id[dept, term],
                        sd_dept_id__Intercept) %>%
  str()
```

which compares to `brms::posterior_samples`

```{r}
str(brms::posterior_samples(b13.2))
```




and we comptute the mean by dept, with interval

```{r}
b13.2 %>% tidybayes::spread_draws(b_Intercept, b_male, r_dept_id[dept,]) %>%
  mutate(dept_mean = b_Intercept + r_dept_id) %>%
  mean_qi(dept_mean)
```

and plotting the coefficients by dept

```{r}
b13.2 %>% tidybayes::spread_draws(b_Intercept, r_dept_id[dept,]) %>%
  mutate(dept_mean = b_Intercept + r_dept_id) %>%
  mean_qi(dept_mean) %>%
  ggplot(aes(y = dept, x = dept_mean, xmin = .lower, xmax = .upper)) +
  geom_pointinterval() +
  theme_minimal()
```



which gives the following parameters **which are not centered** contrary to the
`rethinking` package.

>The `fit` gives the same result as just above but without having to compute
`dept_mean = b_Intercept + r_dept_id`


```{r}
b13.2$fit
```

Since every dept intercept `r_dept_id` is *a difference from the global intercept* 
`b_Intercept` then their average is about 0.

```{r}
mean(c(1.27, 1.23, 0.01, -0.02, -0.46, -2.01))
```



to obtain the centered parameters in `brms` is

```{r}
coef(b13.2)
```

and now the average of the **centered** random effects is about the same as the 
global meann. 

>To understand this it is important to note that every random effects
(i.e. dept) is centered on itself and thus the average of these means (centers)
is the global average.

```{r}
mean(coef(b13.2)$dept_id[, "Estimate", "Intercept"])
```


we can also obtain the **expected values of the posterior predictive distribution**
with `brms::fitted.brmsfit()` which is an alias for `posterior_epred.brmsfit` but
with additional arguments to create summaries

```{r}
fitted(b13.2)
```


### Varying effects of being male (Varying slope of male)

The model


$$
admit_i \sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) = \alpha_{dept[i]} + \beta_{dept[i]} m_i \\
\begin{bmatrix}
\alpha_{dept} \\
\beta_{dept}
\end{bmatrix}
\sim
\mathcal{MVNormal}(
\begin{bmatrix}
\alpha \\
\beta
\end{bmatrix}, 
\textbf{S}
) \\
\textbf{S} = 
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta}
\end{bmatrix}
\textbf{R}
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\beta}
\end{bmatrix} \\
\alpha \sim \mathcal{N}(0, 10) \\
\beta \sim \mathcal{N}(0, 1) \\
(\sigma_{\alpha}, \sigma_{\beta}) \sim \mathcal{HalfCauchy}(0, 2) \\
\textbf{R} \sim \mathcal{LKJcorr}(2)
$$

```{r}
a_file <- here::here("fits", "b13_03.rds")  # rds file location
stopifnot(file.exists(a_file))
b13.3 <- readRDS(file = a_file)  # load the file
# b13.3 <- 
#   brm(data = d, 
#       family = binomial,
#       admit | trials(applications) ~ 1 + male + (1 + male | dept_id),
#       prior = c(prior(normal(0, 10), class = Intercept),
#                 prior(normal(0, 1), class = b),
#                 prior(cauchy(0, 2), class = sd),
#                 prior(lkj(2), class = cor)),
#       iter = 5000, warmup = 1000, chains = 4, cores = 4,
#       seed = 13,
#       control = list(adapt_delta = .99,
#                      max_treedepth = 12))
# b13.3 <- add_criterion(b13.3, c("loo", "waic"))
# saveRDS(object = b13.3, file = a_file)
```

and to help with the functions below we look at the variables

```{r}
tidybayes::get_variables(b13.3)
```

dept__term = paste(term, dept, sep = "-")

and we comptute the mean by dept, with interval

```{r}
b13.3 %>% tidybayes::spread_draws(b_Intercept, r_dept_id[dept, term]) %>%
  mutate(dept_mean = ifelse(term == "Intercept", b_Intercept + r_dept_id, r_dept_id)) %>%
  mean_qi(dept_mean) %>%
  unite(col = "term_dept", term, dept, sep = "-", remove = FALSE)
```

and plotting the coefficients by dept

```{r}
b13.3 %>% tidybayes::spread_draws(b_Intercept, r_dept_id[dept, term]) %>%
  mutate(dept_mean = ifelse(term == "Intercept", b_Intercept + r_dept_id, r_dept_id)) %>%
  mean_qi(dept_mean) %>%
  unite(col = "term_dept", term, dept, sep = "-", remove = FALSE) %>%
  ggplot(aes(y = term_dept, x = dept_mean, xmin = .lower, xmax = .upper)) +
  geom_pointinterval() +
  theme_minimal() +
  labs(title = "Coefficients for model b12.3")
```


### Shrinkage



### Model comparison

We fit a model that ignores gender.  That is

$$
admit_i \sim \mathcal{Binomial}(n_i, p_i) \\
logit(p_i) = \alpha_{dept[i]} \\
\alpha_{dept} \sim \mathcal{N}(\alpha, \sigma) \\
\alpha \sim \mathcal{N}(0, 10) \\
\sigma \sim \mathcal{HalfCauchy}(0, 2)
$$

which gives this fit


```{r}
a_file <- here::here("fits", "b13_04.rds")  # rds file location
stopifnot(file.exists(a_file))
b13.4 <- readRDS(file = a_file)  # load the file
# b13.4 <-
#   brm(data = d,
#       family = binomial,
#       admit | trials(applications) ~ 1 + (1 | dept_id),
#       prior = c(prior(normal(0, 10), class = Intercept),
#                 prior(cauchy(0, 2), class = sd)),
#       iter = 5000, warmup = 1000, chains = 4, cores = 4,
#       seed = 13,
#       control = list(adapt_delta = .99,
#                      max_treedepth = 12))
# b13.4 <- add_criterion(b13.4, c("loo", "waic"))
# saveRDS(object = b13.4, file = a_file)
```


and comparing the models

```{r}
loo_compare(b13.2, b13.3, b13.4, criterion = "waic") %>%
  print(simplify = FALSE)
```

with the weights which shows that `b13.3` dominates

```{r}
model_weights(b13.2, b13.3, b13.4, weights = "waic") %>%
  round(digits = 3)
```



## Example: Cross-classified chimpanzees with varying slopes

### The model

$$
pulled\_left_i \sim \mathcal{Binomial}(n=1, p_i) \\
logit(p_i) = \alpha_i + (\beta_{1,i} + \beta_{2,i} condition_i) \cdot prosoc\_left_i \\
\alpha_i = \alpha + \alpha_{actor[i]} + \alpha_{block[i]} \\
\beta_{1,i} = \beta_1 + \beta_{1,actor[i]} + \beta_{1,block[i]} \\
\beta_{2,i} = \beta_2 + \beta_{2,actor[i]} + \beta_{2,block[i]} \\

\alpha \sim \mathcal{N}(0,1) \\
\beta_1 \sim \mathcal{N}(0,1) \\
\beta_2 \sim \mathcal{N}(0,1) \\


\begin{bmatrix}
\alpha_{actor} \\
\beta_{1, actor} \\
\beta_{2, actor}
\end{bmatrix}
\sim
\mathcal{MVNormal}(
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}, 
\mathbf{S}_{actor}
) \\


\begin{bmatrix}
\alpha_{block} \\
\beta_{1, block} \\
\beta_{2, block}
\end{bmatrix}
\sim
\mathcal{MVNormal}(
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}, 
\mathbf{S}_{block}
) \\

\mathbf{S}_{actor} = \mathbf{\Sigma}_{actor} \mathbf{R}_{actor} \mathbf{\Sigma}_{actor}\\

\mathbf{S}_{actor} = \mathbf{\Sigma}_{block} \mathbf{R}_{block} \mathbf{\Sigma}_{block}\\

\mathbf{\Sigma}_{actor} = 
\begin{bmatrix}
\sigma_{\alpha_{actor}} & 0 & 0 \\
0 & \sigma_{\beta_{1,actor}} & 0 \\
0 & 0 & \sigma_{\beta_{1,actor}} \\
\end{bmatrix} \\


\mathbf{\Sigma}_{block} = 
\begin{bmatrix}
\sigma_{\alpha_{block}} & 0 & 0 \\
0 & \sigma_{\beta_{1,block}} & 0 \\
0 & 0 & \sigma_{\beta_{1,block}} \\
\end{bmatrix} \\

\mathbf{R}_{actor} = 
\begin{bmatrix}
1 & \rho_{\alpha_{actor}, \beta_{1,actor}} & \rho_{\alpha_{actor}, \beta_{2,actor}} \\
\rho_{\beta_{1,actor}, \alpha_{actor}} & 1 & \rho_{\beta_{1,actor}, \beta_{2,actor}} \\
\rho_{\beta_{2,actor}, \alpha_{actor}} & \rho_{\beta_{2,actor}, \beta_{1,actor}} & 1 \\
\end{bmatrix} \\

\mathbf{R}_{block} = 
\begin{bmatrix}
1 & \rho_{\alpha_{block}, \beta_{1,block}} & \rho_{\alpha_{block}, \beta_{2,block}} \\
\rho_{\beta_{1,block}, \alpha_{block}} & 1 & \rho_{\beta_{1,block}, \beta_{2,block}} \\
\rho_{\beta_{2,block}, \alpha_{block}} & \rho_{\beta_{2,block}, \beta_{1,block}} & 1 \\
\end{bmatrix} \\

\sigma_{\alpha_{actor[i]}}, \sigma_{\beta_{1,actor[i]}}, \sigma_{\beta_{2,actor[i]}} \sim \mathcal{HalfCauchy}(0,2) \\
\sigma_{\alpha_{block[i]}}, \sigma_{\beta_{1,block[i]}}, \sigma_{\beta_{2,block[i]}} \sim \mathcal{HalfCauchy}(0,2) \\

\mathbf{R}_{actor} \sim \mathcal{LKJcorr}(K=3, \eta = 4) \\
\mathbf{R}_{block} \sim \mathcal{LKJcorr}(K=3, \eta = 4)
$$

### The fit

```{r}
library(rethinking)
data(chimpanzees)
d <- chimpanzees %>%
  select(-recipient) %>%
  rename(block_id = block)
str(d)
```

```{r}
a_file <- here::here("fits", "b13_06.rds")
stopifnot(file.exists(a_file))
b13.6 <- readRDS(file = a_file)
# b13.6 <- 
#   brm(data = d, 
#       family = binomial,
#       pulled_left | trials(1) ~ 1 + prosoc_left + condition:prosoc_left +
#         (1 + prosoc_left + condition:prosoc_left | actor) +
#         (1 + prosoc_left + condition:prosoc_left | block_id),
#       prior = c(prior(normal(0, 1), class = Intercept),
#                 prior(normal(0, 1), class = b),
#                 prior(cauchy(0, 2), class = sd),
#                 prior(lkj(4), class = cor)),
#       iter = 5000, warmup = 1000, chains = 3, cores = 3,
#       seed = 13)
# b13.6 <- add_criterion(b13.6, c("loo", "waic"))
# saveRDS(object = b13.6, file = a_file)
```


with the summary

```{r}
summary(b13.6)
```



## Continuous categories and the Gaussian process


### Example: Spatial autocorrelation in Oceanic tools

#### The model

```{r}
data(islandsDistMatrix)

d_mat <- islandsDistMatrix
colnames(d_mat) <- c("Ml", "Ti", "SC", "Ya", "Fi", "Tr", "Ch", "Mn", "To", "Ha")
str(d_mat)
```
and plot the distance matrix

```{r}
pdf <- as.data.frame(d_mat) %>%
  tibble::rownames_to_column(var = "island_from") %>%
  pivot_longer(cols = colnames(d_mat), names_to = "island_to", values_to = "distance") %>%
  arrange(island_from, island_to)
pdf
ggplot(pdf, aes(x=island_from, y = island_to, fill = distance)) +
  geom_tile() +
  geom_text(mapping = aes(label = distance, 
                          color = ifelse(distance<2, "gold", "darkblue"))) +
  paletteer::scale_fill_paletteer_c(palette = "scico::tokyo") +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Oceanic distance matrix", x = NULL, y = NULL)
```




$$
T_i \sim Poisson(\lambda_i) \\
log(\lambda_i) = \alpha + \gamma_{society[i]} + \beta_P \cdot \log{P_i} \\
\gamma \sim \mathcal{MVNormal}([0, ..., 0], \mathbf{K}) \\
K_{i,j} = \eta^2 \exp{(-\rho^2 D_{i,j}^2)}+ \delta_{i,j}\sigma^2 \\
\alpha \sim \mathcal{N}(0, 10) \\
\beta_P \sim \mathcal{N}(0, 1) \\
\eta^2 \sim \mathcal{HalfChauchy}(0, 1) \\
\rho^2 \sim \mathcal{HalfChauchy}(0, 1) 
$$

#### The fit

Load the data

The way `brms` works for gaussain process is quite dofferent than `rethinking`
see Solomon Kurz for details.

```{r}
data(Kline2)
# convert lat and lon2 to thousands of km
d <- Kline2 %>%
  mutate(society = seq_len(nrow(Kline2)),
         lat_adj = lat * 0.11132,
         lon2_adj = lon2 * 0.11132) %>%
  relocate(society, after = 0)
# d
```

and we do the fit with `brms`

```{r}
a_file <- here::here("fits", "b13_07.rds")
stopifnot(file.exists(a_file))
b13.7 <- readRDS(file = a_file)
# b13.7 <-
#   brm(data = d, 
#       family = poisson,
#       # set scale = FALSE, (otherwise all scaled distance are between 0 and 1
#       # gp() is for the gaussian process
#       total_tools ~ 1 + gp(lat_adj, lon2_adj, scale = FALSE) + logpop,
#       prior = c(prior(normal(0, 10), class = Intercept),
#                 prior(normal(0, 1), class = b, coef = logpop),
#                 prior(inv_gamma(2.874624, 2.941204), class = lscale, coef = gplat_adjlon2_adj),
#                 prior(cauchy(0, 1), class = sdgp)),
#       iter = 1e4, warmup = 2000, chains = 4, cores = 4,
#       seed = 13,
#       control = list(adapt_delta = .999))
# b13.7 <- add_criterion(b13.7, c("loo", "waic"))
# saveRDS(object = b13.7, file = a_file)
```


and the model summary



```{r}
tidybayes::get_variables(b13.7)
```

dept__term = paste(term, dept, sep = "-")

and we comptute the mean by dept, with interval

```{r}
b13.7 %>% tidybayes::spread_draws(b_Intercept, b_logpop, sdgp_gplat_adjlon2_adj, 
                                  lscale_gplat_adjlon2_adj, zgp_gplat_adjlon2_adj["society"]) %>%
  mutate(society_mean = b_Intercept + zgp_gplat_adjlon2_adj) %>%
  mean_qi(b_Intercept, b_logpop, zgp_gplat_adjlon2_adj) %>%
  mutate(across(.cols = where(is.double), .fns = round, digits = 2))
  # unite(col = "term_dept", term, dept, sep = "-", remove = FALSE)

```

```{r}
summary(b13.7)
```




```{r}
bpost13.7 <- posterior_samples(b13.7)
brms::posterior_summary(bpost13.7) %>%
  as.data.frame() %>%
  mutate(across(.cols = where(is.double), .fns = round, digit = 2))
```




## Summary



## Practice
