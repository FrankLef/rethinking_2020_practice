```{r include=FALSE}
library(rethinking)
library(brms)
library(INLA)
library(dplyr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(tidybayes, quietly = TRUE)
library(ggdist, quietly = TRUE)
library(patchwork, quietly = TRUE)
library(paletteer, quietly = TRUE)
```

# Linear Models {#linear}

Custom functions used, to avoid repeating codes and avoid error

```{r}
# Pivot a dataframe from ggdist::point_interval to longer format
#  For example, this is a useful function when plotting with ggrepel
gather_interval <- function(df, value_var, func=ggdist::median_qi, width = c(2/3, 0.89),
                            names_to="stat", values_to="value") {
  val_col <- deparse1(substitute(value_var))
  df %>%
    func({{value_var}}, .width = width) %>%
    select(-.interval) %>%
    pivot_longer(cols = all_of(c(val_col, ".lower", ".upper")), 
                 names_to = names_to, 
                 values_to = values_to) %>%
    filter(!(stat == val_col & .width != .width[1]))  ## remove repeated "value"
}

# test the function
nsamples <- 10
df <- data.frame(x = rep(c("blue", "red"), times = nsamples),
                 y = c(rnorm(n = nsamples), rnorm(n = nsamples, mean = 10, sd = 5)))
# test with grouping variable
df <- df %>%
  group_by(x) %>%
  gather_interval(value_var = y, func = median_qi, width = c(2/3, 0.89))
# df
# every line must be uniquely identified
stopifnot(any(!duplicated(paste(df$x, df$stat, df$.width))))
```


```{r}
# find the mode
mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```



## 4E1 {-}

See section 4.4.1

$y_i \sim \mathcal{N}(\mu, \sigma)$

## 4E2 {-}

2 parameters, $\mu$ and $\sigma$ which are in the posterior distribution
$y_i \sim \mathcal{N}(\mu, \sigma)$

## 4E3 {-}

See Overthinking in section 4.3.1

$$
\begin{align*}
P(\mu, \sigma \mid y) &=

\frac{
    P(y, \mu, \sigma)
}{
    P(y)
} \\

&= \frac{
    P(y, \mu, \sigma)
}{
    \int_{\sigma} \int_{\mu} P(y \mid \mu, \sigma) \cdot P(\mu, \sigma) d\mu d\sigma \\
} \\

&= 

\frac{
    \prod_i P(y_i, \mu, \sigma)
}{
    \int_{\sigma} \int_{\mu} \prod_i P(y_i \mid \mu, \sigma) \cdot P(\mu, \sigma) d\mu d\sigma \\
} \\

&=

\frac{
    \prod_i P(y_i \mid \mu, \sigma) \cdot P(\mu) \cdot P(\sigma)
}{
    \int_{\sigma} \int_{\mu} \prod_i P(y_i \mid \mu, \sigma) \cdot P(\mu) \cdot P(\sigma) d\mu d\sigma \\
} \\

&=

\frac{
    \prod_i \mathcal{N}(y_i \mid \mu, \sigma) \cdot \mathcal{N}(\mu \mid mean = 0, sd = 10) \cdot \mathcal{Exponential}(\sigma \mid rate = 1)
}{
    \int_{\sigma} \int_{\mu}{
        \prod_{i=1}^n \mathcal{N}(y_i \mid \mu, \sigma) \cdot \mathcal{N}(\mu \mid mean = 0, sd = 10) \cdot \mathcal{Exponential}(\sigma \mid rate = 1)
    }
    d\mu d\sigma
}

\end{align*}
$$


## 4E4 {-}

$\mu_i = \alpha + \beta x_i$

## 4E5 {-}

2 parameters, $\mu$ and $\sigma$

## 4M1 {-}

See R code 4.13 in section 4.3.2 using this model

```{r}
# simulate the heights using the prior, not the posterior
set.seed(4)  # set the seed as random sample can vary and give error later
nsamples <- 1e4
sample_mu <- rnorm(n = nsamples, mean = 0, sd = 10)
sample_sigma <- rexp(n = nsamples, rate = 1)
df <- data.frame(height = rnorm(n = nsamples, mean = sample_mu, sd = sample_sigma))
```

```{r}
a_width <- c(2/3, 0.95, 1)

# dataframe of intervals used by ggrepel::geom_text_repel
df1 <- df %>%
  # see gather_interval() at the beginning
  gather_interval(value_var = height, func = median_qi, width = a_width)
# df1

ggplot(data = df, mapping = aes(x = height)) +
  ggdist::stat_halfeye(aes(fill = stat(cut_cdf_qi(cdf, .width = a_width))),
                       color = "darkorange") +
  scale_x_continuous(breaks = df1$value, labels = round(df1$value, 1)) +
  scale_fill_paletteer_d("ggsci::indigo_material", 
                         direction = 1,
                         name = "levels %",
                         labels = round(100 * a_width, 0),
                         na.translate = FALSE) +
  ggrepel::geom_text_repel(data = df1,
                           aes(x = value, label = round(value, 1), y = 0),
                           inherit.aes = FALSE,
                           color = "violetred") +
  theme_void() +
  theme(legend.position = c(0.8, 0.8),
        title = element_text(color = "midnightblue")) +
  labs(title = "Prior prediction of height", 
       subtitle = sprintf("4M1, sample size = %d", nrow(df)))
```

## 4M2 {-}

### with `quap` {-}

See section 4.4.2 on how to use `quap`, R code 4.43 with linear equation with
the `quap` formula, i.e. `flist = alist(...)`.


```{r eval=FALSE}
alist(
    height ~ dnorm(mean = mu, sd = sigma),
    mu = a + b * x,
    a ~ dnorm(mean = 0, sd = 10),
    b ~ dnorm(mean = 0, sd = 1),
    sigma ~ dexp(rate = 1)
    )
```


## 4M3 {-}

Make sure you remember to index the $y$ so that it is $y_i$ as well as $\mu$.
See section 4.4.2.  The published answer does not put an index on $\mu$ but it
has one on $\y$ which involves a constant $\mu$ which is normally the intercept!
This question is confusing, here we assume the same meaning as in section 4.4.2.,
that is $\mu$ varies for each $x_i$

$$
\begin{align*}
y_i &\sim \mathcal{N}(mean = \mu_i, sd = \sigma)\\
\mu_i &= \alpha + \beta x_i \\
\alpha &\sim \mathcal{N}(mean = 0, sd = 10) \\
\beta &\sim \mathcal{Uniform}(mean = 0, sd = 1) \\
\sigma &\sim \mathcal{Exponential}(\lambda = 1)
\end{align*}
$$

## 4M4 {-}

Don't forget the index so that $height$ is $height_i$.

This will be giving the average height per year.  The question is not clear
that it wants it by student also.

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot year_i \\
\alpha &\sim \mathcal{N}(100, 10) \\
\beta &\sim \mathcal{Uniform}(0, 10) \\
\sigma &\sim \mathcal{Exponential}(1)
\end{align*}
$$

## 4M5 {-}

This tells us that $\beta$ should always be positive be with large values unlikely.
We therefore use the log-normal dist as a prior for $\beta$. See section 4.4.2.

$$
\begin{align*}
height_i &\sim Normal(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot year_i \\
\alpha &\sim \mathcal{Normal}(100, 10) \\
\beta &\sim \mathcal{LogNormal}(0, 1) \\
\sigma &\sim \mathcal{Exponential}(1)
\end{align*}
$$

## 4M6 {-}

Instead of using the average range as a prior for $\sigma$ we would use
$\sigma = \sqrt{64} = 8$.

> In the official solution solution McElreath says it should be 
$\sigma \sim Uniform(0, 64)$, no sqrt of the *variance* to obtain the
*standard deviation* is done.

$$
height_i \sim Normal(\mu_i, \sigma) \\
mu_i = \alpha + \beta \cdot year_i \\
\alpha \sim Normal(120, 10) \\
\beta \sim Normal(0, 10) \\
\sigma \sim Uniform(0, 8)
$$

## 4M7 {-}

See section 4.4.2 for model m4.3.  We add the centered weight to the data
and call it $weight_c$.

```{r}
data(Howell1)
data04M07 <- Howell1 %>%
  filter(age  >= 18) %>%
  mutate(weight_c = as.vector(scale(weight, center = TRUE, scale = FALSE)))
rm(Howell1)
skimr::skim(data04M07)
```

### Model {-}

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta(x_i - \bar{x}) \\
\alpha &\sim \mathcal{N}(178, 20) \\
\beta &\sim \mathcal{LogNormal}(0, 1) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### Priors {-}


The following priors are evaluated by comparing the prior distribution
and the prior predictive distribution (also called likelihood).

```{r}
priors <- list(
  alpha_mean = 178,
  alpha_sd = 20,
  beta_mean = 0,
  beta_sd = 1,
  sigma_rate = 1,
  # nb of samples from the prior
  nsamples = 100,
  # nb of observations for each of the prior sample
  ntrials = 100
)
# alpha_mean <- 178
# alpha_sd <- 20
# beta_mean <- 0
# beta_sd <- 1
# sigma_rate <- 1
# n_samples <- 100  # nb of samples from the prior
# n_trials <- 100  # nb of observations for each of the prior sample item
```

The prior predictive distribution is simulated as follows.  This is heavily
inspired by https://vasishth.github.io/bayescogsci/book/sec-priorpred.html.

**Important:** We could use the prior prediction from the ``brms` fit
objects.  However then we depend on the `rstan` sampler which is subject
to possible convergence problems.  This method is independent of the fitting
methodology.  Not to mention it makes one really understand what is going on
which is the avowed objective of this book.

```{r}
set.seed(4)
x_pred = modelr::seq_range(x=data04M07$weight_c , n = priors$nsamples)
sim <- list(
  alpha = rnorm(n = priors$nsamples, mean = priors$alpha_mean, sd = priors$alpha_sd),
  beta = rlnorm(n = priors$nsamples, meanlog = priors$beta_mean, sdlog = priors$beta_sd),
  sigma = rexp(n = priors$nsamples, rate = priors$sigma_rate)
  )
sim$mu <- sim$alpha + sim$beta * x_pred
# alpha_sim <- rnorm(n = priors$nsamples, mean = priors$alpha_mean, sd = priors$alpha_sd)
# beta_sim <- rlnorm(n = priors$nsamples, meanlog = priors$beta_mean, sdlog = priors$beta_sd)
# sigma_sim <- rexp(n = priors$nsamples, rate = priors$sigma_rate)
# mu_sim <- alpha_sim + beta_sim * x_pred

prior_pred <- purrr::map2_dfr(.x = sim$mu, .y = sim$sigma, 
                              .f = function(mu, sigma) {
                                tibble(
                                  trial = seq_len(priors$ntrials),
                                  predict = rnorm(n = priors$ntrials , 
                                                  mean = mu, sd = sigma)
                                )
                              }, .id = "iter") %>%
  mutate(iter = as.integer(iter))
# str(prior_pred)

ggplot(prior_pred) +
  geom_density(aes(x = predict, y = ..scaled.., color = "prior predicted"),
               size = 1, alpha = 0.8) +
  geom_density(data = data04M07, aes(x = height, y = ..scaled.., color = "observed"),
               size = 1, alpha = 0.8) +
  scale_color_manual(values = c("prior predicted" = "mediumvioletred", 
                                "observed" = "mediumseagreen")) +
  ggdist::theme_ggdist() +
  theme(legend.position = c(0.8, 0.8),
        ) +
  labs(title = "Comparing prior predictive distribution vs observed distribution",
       subtitle = "4M7",
       x = "height", y = NULL, color = NULL)
  
```

The prior is reasonable as it reflects an opinion on the overall general
population.


### Fit `quap` {-}

#### Centered scale {-}

The fit using the centered, model m4.3 in textbook.


```{r}
a_file <- here::here("fits", "m04M07ctr.rds")
m04M07ctr <- readRDS(file = a_file)
# df <- data04M07
# m04M07ctr <- quap(
#   flist = alist(
#     height ~ dnorm(mu, sigma),
#     mu <- a + b * weight_c,
#     a ~ dnorm(178, 20),
#     b ~ dlnorm(0, 1),
#     sigma ~ dunif(0, 50)
#   ),
#   data = df,
#   start = list(a = mean(df$weight), b = 0.5)
# )
# saveRDS(object = m04M07ctr, file = a_file)
precis(m04M07ctr)[, 1:2]
```


#### Natural scale {-}

The fit using the predictor on the natural scale


```{r}
a_file <- here::here("fits", "m04M07nat.rds")
m04M07nat <- readRDS(file = a_file)
# df <- data04M07
# m04M07nat <- quap(
#   flist = alist(
#     height ~ dnorm(mu, sigma),
#     mu <- a + b * weight,
#     a ~ dnorm(178, 20),
#     b ~ dlnorm(0, 1),
#     sigma ~ dunif(0, 50)
#   ),
#   data = df,
#   start = list(a = mean(df$weight), b = 0.5)
# )
# saveRDS(object = m04M07nat, file = a_file)
precis(m04M07nat)[, 1:2]
```

#### Covariances

The parameter `corr = TRUE` does not seem to work
in `precis` so we use the var-cov matrix and convert it to correlations.

```{r}
round(cov2cor(vcov(m04M07ctr)), 4)
```


```{r}
round(cov2cor(vcov(m04M07nat)), 4)
```

Comments:

* The effect ($b$) and sigma are the same but the $a$ (Intercepts) coefficients
are different.
* The correlations are strong on the natural scale and
non-existent on the centered scale.  This is an effect that is well documented with
the correlation coefficient when *distant data points from the origin* are observed
* The 2 models, on centered and natural scales give the same prediction.

#### Posteriors

```{r}
m04M07ctr_post <- extract.samples(
  object = m04M07ctr,
  n = 1000)
m04M07nat_post <- extract.samples(
  object = m04M07nat,
  n = 1000)

m04M07all_post <- m04M07ctr_post %>%
  bind_rows(m04M07nat_post) %>%
  mutate(model = factor(
    c(rep("center", length.out = n() / 2),
      rep("natural", length.out = n() / 2)
      ))) %>%
  pivot_longer(cols = c("a", "b", "sigma"), names_to = "vars")
```

the function and intervals used to plot the posteriors

```{r}
# Function to create the plot of posterior with halfeye geom
plot_post <- function(df, df1, x_var = "value", y_var = "model", 
                     fill_var = "model", x1_var = "value", y1_var = "model",
                     func, width = c(0.89), round = 0, text_size = 3,
                     the_labs = NULL,
                     clrs = list(color = "yellowgreen", 
                                 fill = "ggsci::default_nejm",
                                 title = "midnightblue")) {
  ggplot(df, 
         aes(x = .data[[x_var]], y = .data[[y_var]], fill = .data[[fill_var]])) +
  stat_halfeye(point_interval = func, .width = width,
               color = clrs$color) +
  scale_fill_paletteer_d(clrs$fill) +
  ggrepel::geom_text_repel(data = df1, 
                           aes(label = c(round(.data[[x1_var]], round)), 
                               y = .data[[y1_var]]),
                           color = "black", size = text_size) +
  ggthemes::theme_tufte() +
  theme(legend.position = "none",
        title = element_text(color = clrs$title),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()) +
    the_labs
}

# Function to create the dataframe used for geom_text_repel
# need to remove the mean ("value") which repeats itself
df_post <- function(df, grp1_var, grp2_var, value_var, func = ggdist::median_qi, 
                    width = c(2/3)) {
  df %>%
    group_by({{grp1_var}}, {{grp2_var}}) %>%
    func({{value_var}}, .width = width) %>%
    select(-.interval) %>%
    pivot_longer(cols = c("value", ".lower", ".upper"), names_to = "stat") %>%
    filter(!(stat == "value" & .width != .width[1]))  ## remove repetitions of value
}
```



```{r}
a_func <- ggdist::median_qi
a_width <- c(2/3)

post_intervl <- m04M07all_post %>%
  select(model, vars, value) %>%
  group_by(model, vars) %>%
  gather_interval(value_var = value, func = a_func, width = a_width)

df <- m04M07all_post %>%
  filter(vars == "a")
df1 <- post_intervl %>%
  filter(vars == "a")
pA <- plot_post(df, df1, x_var = "value", y_var = "model", fill_var = "model", 
                x1_var = "value", y1_var = "model",
                func = a_func, width = a_width, round = 0, 
                the_labs = labs(title = "Intercept", x = NULL, y = NULL)) +
  theme(legend.position = "right")
# pA


df <- m04M07all_post %>%
  filter(vars == "b")
df1 <- post_intervl %>%
  filter(vars == "b")
pB <- plot_post(df, df1, x_var = "value", y_var = "model", fill_var = "model", 
                x1_var = "value", y1_var = "model",
                func = a_func, width = a_width, round = 2, 
                the_labs = labs(title = "b slope", x = NULL, y = NULL))
# pB


df <- m04M07all_post %>%
  filter(vars == "sigma")
df1 <- post_intervl %>%
  filter(vars == "sigma")
pSigma <- plot_post(df, df1, x_var = "value", y_var = "model", fill_var = "model", 
                    x1_var = "value", y1_var = "model",
                    func = a_func, width = a_width, round = 1, 
                    the_labs = labs(title = "Sigma", x = NULL, y = NULL))
# pSigma


p <- pA / (pB | pSigma) +
  plot_annotation(title = "Posterior comparisons by model",
                  theme = theme(title = element_text(color = "darkblue")))
p
```


#### Posterior predictions

First we extract the simulated data for the mu values (the fit) and for the 
predicted heights with the models.

The functions and variables used

```{r}
# get the interval from the quap object
get_pred <- function(df, x_pred, func = ggdist::mean_qi, width = c(0.89)) {
  # must be exactly of length 1, do not use multiple intervals
  stopifnot(length(width) == 1)
  
  df %>%
    as.data.frame() %>%
    purrr::map_dfr(.f = func, .width = width) %>%
    mutate(x = x_pred) %>%
    relocate(x)
}

# plot the predictions and the fit against the raw data
plot_all <- function(df, df_fitted, df_predict, x_var, y_var, color_var,
                     colrs = list(
                       pred_fill = "lightgoldenrod1",
                       fit_fill = "palegreen1",
                       fit_color = "palegreen4",
                       raw_pal = "scico::lapaz"),
                     the_labs) {
  ggplot(as.data.frame(fit@data), aes(x = .data[[x_var]], 
                                      y = .data[[y_var]], 
                                      color = .data[[color_var]])) +
  geom_ribbon(data = df_predict,
              aes(x = x, ymin = ymin, ymax = ymax),
              inherit.aes = FALSE, fill = colrs$pred_fill) +
  geom_lineribbon(data = df_fitted,
                          aes(x = x, y = y, ymin = ymin, ymax = ymax),
                          inherit.aes = FALSE, fill = colrs$fit_fill,
                          color = colrs$fit_color) +
  geom_point() +
  scale_color_paletteer_c(colrs$raw_pal) +
  theme_ggdist() +
  theme(legend.position = "none",
        title = element_text(size = 10)) +
  the_labs
}

npred <- 30  # nb of predictions
nsamples <- 1000  # nb of samples
a_width = 2/3  # default width used
a_func <- ggdist::mean_qi  # function used for intervals
```

The model on the centered scale

```{r}
fit <- m04M07ctr  # the fit object

# the sequence of weights to predict height
weight_pred <- range(fit@data$weight_c)
weight_pred <- seq(from = weight_pred[1], to = weight_pred[2], length.out = npred)
weight_mean <- mean(fit@data$weight)  # to use with inverse transform in plot

# the posterior predictions with intervals
pred_center <- rethinking::sim(fit, data = list(weight_c = weight_pred), n = nsamples)
pred_center <- get_pred(pred_center, x_pred = weight_pred + weight_mean, 
                        func = a_func, width = a_width)
# pred_center

# the posterior fit
fitted_center <- rethinking::link(fit, data = list(weight_c = weight_pred), n = nsamples)
fitted_center <- get_pred(fitted_center, x_pred = weight_pred + weight_mean, 
                          func = a_func, width = a_width)
# fitted_center

p_center <- plot_all(df = as.data.frame(fit@data), 
                     df_fitted = fitted_center, df_predict = pred_center,
                     x_var = "weight", y_var = "height", color_var = "age",
                     the_labs = labs(title = "Model on centered scale",
                                     subtitle = sprintf("%.0f%% interval", 100 * a_width)))
# p_center
```

The model on the natural scale

```{r}
fit <- m04M07nat

# the sequence of weights to predict height
weight_pred <- range(fit@data$weight)
weight_pred <- seq(from = weight_pred[1], to = weight_pred[2], length.out = npred)

# the posterior predictions
pred_natural <- rethinking::sim(fit, data = list(weight = weight_pred), n = nsamples)
pred_natural <- get_pred(pred_natural, x_pred = weight_pred, 
                        func = a_func, width = a_width)
# glimpse(pred_natural)

# the posterior fit
fitted_natural <- rethinking::link(fit, data = list(weight = weight_pred), n = nsamples)
fitted_natural <- get_pred(fitted_natural, x_pred = weight_pred, 
                        func = a_func, width = a_width)
# glimpse(fitted_natural)

p_natural <- plot_all(df = as.data.frame(fit@data), 
                     df_fitted = fitted_center, df_predict = pred_center,
                     x_var = "weight", y_var = "height", color_var = "age",
                     colrs = list(
                       pred_fill = "palegreen1",
                       fit_fill = "lightgoldenrod1",
                       fit_color = "lightgoldenrod4",
                       raw_pal = "scico::lapaz"),
                     the_labs = labs(title = "Model on natural scale",
                                     subtitle = sprintf("%.0f%% interval", 100 * a_width)))
# p_natural
```

with the 2 plots

```{r}
p_center + p_natural +
  plot_annotation(title = "Both model give the same predictions.")
```


and comparing the 2 sets of predictions

```{r}
df <- data.frame(
  centered = pred_center$y,
  natural = fitted_center$y
)
ggplot(df, aes(x = centered, y = natural)) +
  geom_point() +
  theme_ggdist() +
  labs(title = "Predictions from model with natural scal vs model with centered scale")
```



### Using `brm` {-}

#### Centered scale {-}


```{r}
a_file <- here::here("fits", "b04M07ctr.rds")
b04M07ctr <- readRDS(file = a_file)
# b04M07ctr <- brms::brm(
#   data = data04M07,
#   family = gaussian,
#   formula = height ~ 1 + weight_c,
#   prior = c(
#     prior(normal(178, 20), class = Intercept),
#     prior(lognormal(0, 1), class = b, lb = 0, ub = 3),
#     prior(exponential(1), class = sigma)),
#   iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),  seed = 4)
# saveRDS(b04M07ctr, file = a_file)
```

```{r}
summary(b04M07ctr)
```

#### Natural scale {-}

```{r}
a_file <- here::here("fits", "b04M07nat.rds")
b04M07nat <- readRDS(file = a_file)
# b04M07nat <- brms::brm(
#   data = data04M07,
#   family = gaussian,
#   formula = height ~ 1 + weight,
#   prior = c(
#     prior(normal(178, 20), class = Intercept),
#     prior(lognormal(0, 1), class = b, lb = 0, ub = 3),
#     prior(exponential(1), class = sigma)),
#   iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),  seed = 4)
# saveRDS(b04M07nat, file = a_file)
```


```{r}
summary(b04M07nat)
```

and to calculate the correlations and visualize we sample the posterior


```{r}
b04M07ctr_post <- posterior_samples(b04M07ctr)
b04M07nat_post <- posterior_samples(b04M07nat)
```

which gives the following correlations which are the same as with `quap` above

```{r}
b04M07ctr_post %>%
  select(-lp__) %>%
  cor() %>%
  round(digits=2)
```


```{r}
b04M07nat_post %>%
  select(-lp__) %>%
  cor() %>%
  round(digits=2)
```
#### Predictions

and we plot the posterior predictions which is easier with `brms` because
we can use the `ggdist` and `tidybayes` packages.

```{r}
# the data and variables used in this chunk
df_raw <- data04M07
n_pred <- 30  # nb of predictions
n_samples <- 1000  # nb of samples
a_width <- c(0.67, 0.80, 0.95)
weight_mean <- mean(df_raw$weight)  # used to inverse the transform

# plot prediction using the model on the centered scale
p_center <- df_raw %>%
  expand(weight_c) %>%
  modelr::seq_range(n = n_pred) %>%
  data.frame(weight_c = .) %>%
  tidybayes::add_predicted_draws(b04M07ctr, ndraws = n_samples) %>%
  ggplot(aes(x = weight_c)) +
  stat_lineribbon(aes(y = .prediction), .width = a_width) +
  geom_point(data = df_raw, aes(y = height, color = age)) +
  scale_x_continuous(breaks = scales::breaks_extended(n = 7),
                     labels = function(x) round(x + weight_mean, 1)) +
  scale_fill_paletteer_d("ggsci::deep_purple_material") +
  scale_color_paletteer_c("scico::lapaz") +
  theme_ggdist() +
  labs(title = "Predictions with model on centered scale",
       x = "centered weight + mean(weight)", y = "height")
# p_center


# plot prediction using the model on the natural scale
p_natural <- df_raw %>%
  expand(weight) %>%
  modelr::seq_range(n = n_pred) %>%
  data.frame(weight = .) %>%
  tidybayes::add_predicted_draws(b04M07nat, ndraws = n_samples) %>%
  ggplot(aes(x = weight)) +
  stat_lineribbon(aes(y = .prediction), .width = a_width) +
  geom_point(data = df_raw, aes(y = height, color = age)) +
  scale_x_continuous(breaks = scales::breaks_extended(n = 7)) +
  scale_fill_paletteer_d("ggsci::deep_orange_material") +
  scale_color_paletteer_c("scico::lapaz") +
  theme_ggdist() +
  labs(title = "Predictions with model on natural scale",
       x = "weight", y = "height")
# p_natural


p_center / p_natural +
  plot_annotation(title = "Comparing 2 models", subtitle = "04M07")
```


and again with the same results as when using `quap`.


### Using `inla` {-}


The prior in `inla` use `precision` rather than `sd` and we therefore
convert the sd to precision for the intercept

```{r}
1 / (20 ^ 2)
```


```{r}
a_file <- here::here("fits", "i04M07nat.rds")
i04M07nat <- readRDS(file = a_file)
# i04M07nat <- inla(
#   formula = height ~ weight,
#   family = "gaussian",
#   data = data04M07,
#   control.fixed=list(mean.intercept = 178, prec.intercept = 1 / 20^2, prec=0.001),
#   control.compute = list(config=TRUE, dic = TRUE, waic = TRUE))
# saveRDS(i04M07nat, file = a_file)
```


```{r}
# the fixed coefficients
i04M07nat$summary.fixed[c("(Intercept)", "weight"), c("mean", "sd")] %>%
  bind_cols(as.data.frame(fixef(b04M07nat)[, c("Estimate", "Est.Error")])) %>%
  round(digits = 2)
```


and for the standard deviation (sigma)

```{r}
imh <- i04M07nat$internal.marginals.hyperpar
# convert internal (log) precision to sd
imh <- inla.tmarginal(fun = function(x) 1 / sqrt(exp(x)), marginal = imh[[1]])
q <- c(0.025, 0.5, 0.975)
i04M07nat_hsumm <- imh %>%
  as.data.frame() %>%
  summarize(mean = inla.emarginal(fun = function(x) x, marginal = .),
            sd = sqrt(max(0, inla.emarginal(fun = function(x) x^2 - mean^2, marginal = .))),
            data.frame(t(inla.qmarginal(q, marginal = .))) %>% setNames(paste0("q", q)),
            mode = inla.mmarginal(.))
i04M07nat_hsumm
```

which we compare to the brm fit


```{r}
posterior_summary(b04M07nat) %>%
  as.data.frame() %>%
  tibble::rownames_to_column() %>%
  select(rowname, Estimate, Est.Error) %>%
  filter(rowname == "sigma") %>%
  bind_cols(i04M07nat_hsumm[, c("mean", "sd")]) %>%
  tibble::remove_rownames() %>%
  tibble::column_to_rownames()
```

and, optionaly, could be done with `zmarginal`

```{r}
inla.zmarginal(imh)
```



```{r}
# i04M07nat$summary.fixed
# i04M07nat$summary.fitted.values
# i04M07nat$summary.linear.predictor
```

#### Plot posteriors

The parameters posterior

```{r}
get_variables(b04M07nat)
```
Get the posterior from `brm`

```{r}
pdf1 <- gather_draws(b04M07nat, b_Intercept, b_weight, sigma) %>%
  select(.variable, .value) %>%
  mutate(fit = "brm",
         .variable = case_when(.variable == "b_Intercept" ~ "Intercept",
                                .variable == "b_weight" ~ "weight",
                                TRUE ~ as.character(.variable)))
# str(pdf1)
```


```{r}
nsamples <- 2000
pdf2 <- data.frame("Intercept" = 
                     sample(x = i04M07nat$marginals.fixed[["(Intercept)"]][, "x"],
                            size = nsamples,
                            prob = i04M07nat$marginals.fixed[["(Intercept)"]][, "y"],
                            replace = TRUE),
                   "weight" = 
                     sample(x = i04M07nat$marginals.fixed[["weight"]][, "x"],
                            size = nsamples,
                            prob = i04M07nat$marginals.fixed[["weight"]][, "y"],
                            replace = TRUE)) %>%
  pivot_longer(cols = c("Intercept", "weight"), 
               names_to = ".variable", values_to = ".value") %>%
  mutate(fit = "inla")
# pdf2

# the sigma posterior
pdf3 <- i04M07nat$internal.marginals.hyperpar[[1]]
pdf3 <- inla.tmarginal(marginal = pdf3, fun = function(tau) 1 / sqrt(exp(tau)))
pdf3 <- data.frame(.variable = "sigma",
                   .value = sample(x = pdf3[, "x"], size = nsamples, 
                                   prob = pdf3[, "y"], replace = TRUE),
                   fit = "inla")

# all data together
pdf <- rbind(pdf1, pdf2, pdf3) %>%
  mutate(.variable = factor(.variable, levels = c("Intercept", "weight", "sigma"),
                            ordered = TRUE))
# the mode by variable and fit
pdf_mode <- pdf %>%
  group_by(.variable, fit) %>%
  summarize(mode = mode(.value))
# pdf_mode
```


```{r}
ggplot(data = pdf, aes(x = .value, color = fit)) +
  geom_density(aes(y = ..scaled..)) +
  geom_vline(data = pdf_mode, aes(xintercept = mode, color = fit),
             linetype = "dashed") +
  scale_color_manual(values = c("brm" = "mediumvioletred", 
                                "inla" = "mediumseagreen")) +
  theme_ggdist() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = "bottom") +
  labs(title = "brm vs inla densities with mode (vertical line)",
       subtitle = "4M7",
       x = NULL, y = NULL, color = NULL) + 
  facet_wrap(. ~ .variable, scales = "free")
```


#### Plot fit

```{r}
str(data04M07)
xseq <- modelr::seq_range(x = data04M07$weight, n = 30)
# xseq <- data04M07$weight
```



```{r}
fit_brm <- fitted(b04M07nat, newdata = data.frame(weight = xseq), 
                  probs = c(0.025, 0.975)) %>%
  as.data.frame() %>%
  mutate(weight = xseq)
str(fit_brm)
```


```{r}
# with inla we have to redo the object with new predictor values and
# NA for outcome
str(data04M07)
new_df <- data.frame(height = NA_real_, weight = xseq)
new_df <- data04M07 %>%
  select(height, weight) %>%
  bind_rows(new_df)
new_df

new_fit <- inla(
  formula = height ~ weight,
  family = "gaussian",
  data = new_df,
  control.fixed=list(mean.intercept = 178, prec.intercept = 1 / 20^2, prec=0.001),
  control.compute = list(config=TRUE, dic = TRUE, waic = TRUE))


fit_inla <- new_fit$summary.linear.predictor %>%
  select(mean, sd, `0.025quant`, `0.975quant`) %>%
  slice_tail(n = length(xseq)) %>%
  mutate(weight = xseq)
# str(fit_inla)
```

```{r}
p1 <- ggplot(data = fit_brm, aes(x = weight, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_lineribbon(size = 1, color = "deepskyblue", fill = "lightskyblue1") +
  ggdist::theme_ggdist() +
  labs(title = "brm fit", y = "mean")
# p1
```



```{r}
p2 <- ggplot(data = fit_inla, aes(x = weight, y = mean, ymin = `0.025quant`, ymax = `0.975quant`)) +
  geom_lineribbon(size = 1, color = "rosybrown", fill = "rosybrown1") +
  ggdist::theme_ggdist() +
  labs(title = "inla fit", y = "mean")
# p2
```


```{r}
df <- data.frame(brm = fit_brm$Estimate, inla = fit_inla$mean)
p3 <- ggplot(df, aes(x = brm, y = inla)) +
  geom_point() +
  ggdist::theme_ggdist() +
  labs(title = "inla vs brm")
# p3
p1 + p2 + p3
```


#### Plot predictions

```{r}
# new_fit$marginals.fixed
```



```{r}
# the fit values for the new predictions
fit_inla <- new_fit$summary.fitted.values %>%
  select(mean, sd, `0.025quant`, `0.975quant`) %>%
  slice_tail(n = length(xseq)) %>%
  mutate(weight = xseq)
# fit_inla

# the sigma values for the new predictions
sigma_inla <- new_fit$internal.marginals.hyperpar[[1]]
sigma_inla <- inla.tmarginal(marginal = sigma_inla, 
                             fun = function(tau) 1 / sqrt(exp(tau))) %>%
  as.data.frame()


set.seed(4)
# sample of mu values to use in sim
sample_mu <- rnorm(n = nrow(fit_inla), mean = fit_inla$mean, sd = fit_inla$sd)
# sample of sigma values to use in sim
sample_sigma <- sample(x = sigma_inla$x, size = nrow(fit_inla),
                       replace = TRUE, prob = sigma_inla$x)
nsamples <- 500
df <- fit_inla %>%
  select(weight, mean, sd) %>%
  mutate(sigma = sample_sigma) %>%
  mutate(mu_sim = rnorm(n = nrow(.), mean = mean, sd = sd)) %>%
  expand(nesting(weight, mu_sim, sigma)) %>%
  mutate(height_sim = purrr::map2(.x = mu_sim, .y = sigma, 
                             .f = ~ rnorm(n = nsamples, mean = .x, sd = .y))) %>%
  unnest(cols = c(height_sim))
  # group_by(weight) %>%
  # summarize(height.mean = mean(height_sim),
  #           height.lower = quantile(height_sim, probs = 0.025),
            # height.upper = quantile(height_sim, probs = 0.975))
# df

p <- ggplot(df, aes(x = weight)) +
  stat_lineribbon(aes(y = height_sim), .width = c(0.67, 0.80, 0.95),
                  color = "steelblue4") +
  geom_point(data = data04M07, mapping = aes(x = weight, y = height),
             inherit.aes = FALSE, color = "indianred") +
  scale_fill_paletteer_d("ggsci::teal_material") +
  ggdist::theme_ggdist() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.15, 0.8)) +
  labs(title = "Predictions with INLA", subtitle = "4M7",
       x = "weight", y = "height")
p
```


## 4M8 {-}

The methodology used here comes from section 4.5 of @kurtz2020b to whom
I am forever grateful for the wonderful books he gives us.


We remove the rows with `NA` in the `doy` variable.

```{r}
data("cherry_blossoms")
data04M08 <- cherry_blossoms %>%
  drop_na(doy)
rm(cherry_blossoms)
skimr::skim(data04M08)
```

### Model

$$
\begin{align*}
doy_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \sum_{k=1}^Kw_kB_{k, i} \\
\alpha &\sim \mathcal{N}(100, 10) \\
w_j &\sim \mathcal{N}(0, 10) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$
### a) Knots = 15, $w_j \sim \mathcal{N}(0, 10)$


```{r}
nknots <- 15
knots <- quantile(data04M08$year, probs = seq(from = 0, to = 1, length.out = nknots))
knots
```


```{r}
colr <- unclass(paletteer::paletteer_d("futurevisions::cancri"))
ggplot(data04M08, aes(x = year, y = doy, color = temp)) +
  geom_vline(xintercept = knots, color = "slateblue", alpha = 1/2) +
  geom_point(shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous(breaks = knots, labels = knots) +
  scale_color_gradientn(colors = colr) +
  theme_classic() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.05, 0.8),
        axis.text.x = element_text(size = rel(0.9))
        ) +
  labs(title = sprintf("Cherry Blossom in Japan with %d knots", nknots),
       subtitle = "4M8 a)")
```
Create the bias function with degree 3 (cubic spline) and an intercept

```{r}
library(splines)
# must specify intercept = TRUE
B <- splines::bs(x = data04M08$year, knots = knots[-c(1, nknots)], 
                 degree = 3, intercept = TRUE)
# str(B)
# this data.frame will be reused below with the posteriors
df_bias <- B %>%
  as.data.frame() %>%
  setNames(sprintf("B%02d", seq_len(ncol(.)))) %>%
  mutate(year = data04M08$year) %>%
  pivot_longer(cols = -year, names_to = "bias_func", values_to = "bias")
# str(df_bias)
```


then the data structure used to fit

```{r}
dfB <- data04M08 %>%
  mutate(B = B)
# the last column is a matrix column, with same nb of rows as the other
# columns but with a column including 17 subcolumns (!)
# glimpse(dfB)
```



```{r}
a_file <- here::here("fits", "b04M08a.rds")
b04M08a <- readRDS(file = a_file)
# b04M08a <- brm(data = dfB,
#       family = gaussian,
#       doy ~ 1 + B,
#       prior = c(prior(normal(100, 10), class = Intercept),
#                 prior(normal(0, 10), class = b),
#                 prior(exponential(1), class = sigma)),
#       cores = detectCores(), seed = 4)
# saveRDS(b04M08a, file = a_file)
```
```{r}
summary(b04M08a)
```




```{r}
df <- fitted(b04M08a) %>%
  as.data.frame() %>%
  bind_cols(data04M08)
str(df)
clrs <- unclass(paletteer::paletteer_d("futurevisions::cancri"))
pA <- ggplot(df, aes(x = year, y = doy)) +
  geom_vline(xintercept = knots[-c(1, length(knots))], color = "slateblue", alpha = 1/2) +
  geom_point(aes(color = temp)) +
  geom_lineribbon(aes(x = year, y = Estimate, ymin = Q2.5, ymax = Q97.5),
                  color = "blueviolet", fill = "cornflowerblue", alpha = 1/2) +
  scale_x_continuous(breaks = knots, labels = knots) +
  scale_color_gradientn(colors = clrs) +
  ggthemes::theme_tufte() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = "none",
        axis.text.x = element_text(size = rel(0.9))) +
  labs(title = sprintf("Cherry Blossom in Japan with %d knots", nknots),
       subtitle = "4M8 a)")
pA
```

### b) Knots = 25, $w_j \sim \mathcal{N}(0, 10)$


```{r}
nknots <- 25
knots <- quantile(data04M08$year, probs = seq(from = 0, to = 1, length.out = nknots))
knots
```


Create the bias functions with degree 3 (cubic spline) and an intercept

```{r}
library(splines)
# must specify intercept = TRUE
B <- splines::bs(x = data04M08$year, knots = knots[-c(1, nknots)], 
                 degree = 3, intercept = TRUE)
# str(B)
# this data.frame will be reused below with the posteriors
df_bias <- B %>%
  as.data.frame() %>%
  setNames(sprintf("B%02d", seq_len(ncol(.)))) %>%
  mutate(year = data04M08$year) %>%
  pivot_longer(cols = -year, names_to = "bias_func", values_to = "bias")
# str(df_bias)
```


then the data structure used to fit

```{r}
dfB <- data04M08 %>%
  mutate(B = B)
# the last column is a matrix column, with same nb of rows as the other
# columns but with a column including 17 subcolumns (!)
# glimpse(dfB)
```



```{r}
a_file <- here::here("fits", "b04M08b.rds")
b04M08b <- readRDS(file = a_file)
# b04M08b <- brm(data = dfB,
#       family = gaussian,
#       doy ~ 1 + B,
#       prior = c(prior(normal(100, 10), class = Intercept),
#                 prior(normal(0, 10), class = b),
#                 prior(exponential(1), class = sigma)),
#       cores = detectCores(), seed = 4)
# saveRDS(b04M08b, file = a_file)
```




```{r}
df <- fitted(b04M08b) %>%
  as.data.frame() %>%
  bind_cols(data04M08)
str(df)
clrs <- unclass(paletteer::paletteer_d("futurevisions::cancri"))
pB <- ggplot(df, aes(x = year, y = doy)) +
  geom_vline(xintercept = knots[-c(1, length(knots))], color = "slateblue", alpha = 1/2) +
  geom_point(aes(color = temp)) +
  geom_lineribbon(aes(x = year, y = Estimate, ymin = Q2.5, ymax = Q97.5),
                  color = "blueviolet", fill = "cornflowerblue", alpha = 1/2) +
  scale_color_gradientn(colors = clrs) +
  ggthemes::theme_tufte() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = "none",
        axis.text.x = element_text(size = rel(0.9))) +
  labs(title = sprintf("Cherry Blossom in Japan with %d knots", nknots),
       subtitle = "4M8 b)")
pB
```

### c) Knots = 25, $w_j \sim \mathcal{N}(0, 20)$


```{r}
nknots <- 25
knots <- quantile(data04M08$year, probs = seq(from = 0, to = 1, length.out = nknots))
knots
```


Create the bias functions with degree 3 (cubic spline) and an intercept

```{r}
library(splines)
# must specify intercept = TRUE
B <- splines::bs(x = data04M08$year, knots = knots[-c(1, nknots)], 
                 degree = 3, intercept = TRUE)
# str(B)
# this data.frame will be reused below with the posteriors
df_bias <- B %>%
  as.data.frame() %>%
  setNames(sprintf("B%02d", seq_len(ncol(.)))) %>%
  mutate(year = data04M08$year) %>%
  pivot_longer(cols = -year, names_to = "bias_func", values_to = "bias")
# str(df_bias)
```


then the data structure used to fit

```{r}
dfB <- data04M08 %>%
  mutate(B = B)
# the last column is a matrix column, with same nb of rows as the other
# columns but with a column including 17 subcolumns (!)
# glimpse(dfB)
```



```{r}
a_file <- here::here("fits", "b04M08c.rds")
b04M08c <- readRDS(file = a_file)
# b04M08c <- brm(data = dfB,
#       family = gaussian,
#       doy ~ 1 + B,
#       prior = c(prior(normal(100, 10), class = Intercept),
#                 prior(normal(0, 20), class = b),
#                 prior(exponential(1), class = sigma)),
#       cores = detectCores(), seed = 4)
# saveRDS(b04M08c, file = a_file)
```




```{r}
df <- fitted(b04M08c) %>%
  as.data.frame() %>%
  bind_cols(data04M08)
str(df)
clrs <- unclass(paletteer::paletteer_d("futurevisions::cancri"))
pC <- ggplot(df, aes(x = year, y = doy)) +
  geom_vline(xintercept = knots[-c(1, length(knots))], color = "slateblue", alpha = 1/2) +
  geom_point(aes(color = temp)) +
  geom_lineribbon(aes(x = year, y = Estimate, ymin = Q2.5, ymax = Q97.5),
                  color = "blueviolet", fill = "cornflowerblue", alpha = 1/2) +
  scale_color_gradientn(colors = clrs) +
  ggthemes::theme_tufte() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = "none",
        axis.text.x = element_text(size = rel(0.9))) +
  labs(title = sprintf("Cherry Blossom in Japan with %d knots and increased weight sd to 20", nknots),
       subtitle = "4M8 c)")
# pC
```

### Conclusion

#### Plots

The increase of nb of knots increases the fits (i.e. nb of turns)

```{r}
pA / pB
```

and the increase in variability of the weight increase the range of the coefficient.
However this is not visually obvious when looking at the scatter plot.
See just below the coefficient comparisons which is more informative.

```{r}
pB / pC
```


#### Summaries

```{r}
summA <- data.frame(model = "A", fixef(b04M08a)) %>%
  tibble::rownames_to_column(var = "variable")
summB <- data.frame(model = "B", fixef(b04M08b)) %>%
  tibble::rownames_to_column(var = "variable")
summC <- data.frame(model = "C", fixef(b04M08c)) %>%
  tibble::rownames_to_column(var = "variable")
df <- bind_rows(summA, summB, summC) %>%
  mutate(variable = factor(variable,
                           levels = c("Intercept", sprintf("B%d", 1:27)),
                           ordered = TRUE))

ggplot(df, aes(x = variable, y = Estimate, ymin = Q2.5, ymax = Q97.5, color = model)) +
  geom_pointinterval(position = position_dodge(width = 1/2)) +
  scale_color_paletteer_d("futurevisions::cancri") +
  ggthemes::theme_tufte() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.15, 0.8),
        axis.text.x = element_text(size = rel(0.85))) +
  labs(title = "Comparing the models' coefficients",
       subtitle = "4M8",
       x = NULL, y = NULL)
  # coord_flip()
```

We can see that the model are similar expect that

* Model A has significantly lower B16 and B17 coefficients. They are
nonetheless similar to the B26 and B27 coefficients of models B and C
* Model B and C have the same coefficient but model C which is the model
with the increased prior variance for the weights has a wider confidence range
for all coefficients

## 4H1 {-}

We first create the dataframes in many of the following practices.

```{r}
data("Howell1")
d <- Howell1 %>%
  filter(age >= 18) %>%
  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE))
rm("Howell1")
stopifnot(nrow(d) == 352)
```

and the model that will be used


$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot weight_i \\
\alpha &\sim \mathcal{N}(178, 20) \\
\beta &\sim \mathcal{LogNormal}(1, 0.5) \\
\sigma &\sim \mathcal{Exponential}(1)
\end{align*}
$$

and get the fit with `quap`


```{r}
a_file <- here::here("fits", "m04H01.rds")
m04H01 <- readRDS(file = a_file)
# m04H01 <- quap(
#   flist = alist(
#     height ~ dnorm(mu, sigma),
#     mu <- a + b * weight,
#     a ~ dnorm(178, 20),
#     b ~ dlnorm(1, 0.5),
#     sigma ~ dexp(1)
#   ),
#   data = d,
#   start = list(a = mean(d$height), b = 0.5)
# )
# saveRDS(object = m04H01, file = a_file)
```

```{r}
vcov(m04H01)
# matrixcalc::is.positive.definite(vcov(m04H01), tol = 1e-4)
```


get the posterior

```{r}
# the center used when centering was done, this is a constant
m04H01_post <- extract.samples(m04H01)
m04H01_pred <- rnorm(n = nrow(m04H01_post), 
                   mean = m04H01_post$a + m04H01_post$b * 46.95,
                   sd = m04H01_post$sigma)
ggdist::mean_hdi(m04H01_pred, .width = 0.89)
```

and find the predictions using the detailed method as described
in overthinking box of section 4.4.3.4. The `rethinking::link()` function
does that.

```{r}
the_weights <- c(46.95, 43.72, 64.78, 32.59, 54.63)
the_preds <- t(sapply(X = the_weights, FUN = function(x) {
  y <- rnorm(n = nrow(m04H01_post), 
             mean = m04H01_post$a + m04H01_post$b * x,
             sd = m04H01_post$sigma)
  ggdist::mean_hdi(y, .width = 0.89)
}))
# the_preds
```



## 4H2 {-}

Load the data


```{r}
data("Howell1")
d <- Howell1 %>%
  filter(age < 18) %>%
  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE))
rm("Howell1")
# there should be 192 rows
stopifnot(nrow(d) == 192)
skimr::skim(d)
```


The model used is

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta \cdot weight_i \\
\alpha &\sim \mathcal{N}(80, 40) \\
\beta &\sim \mathcal{LogNormal}(1, 0.5) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### 4H2 a) with `quap` {-}

* Note on priors
  - Using sigma ~ dexp(rate = 1) which seems to work well with this model
  - a ~ dnorm(80, 40) is based on the average height of the kids
  - b ~ dlnorm(1, 0.5) since we assume the growth rate is positive

* Start values
  - using start data helps very much for this model converge consistently
  - for $a$ simply use the average height
  - for $b$ we use 1 as it should be strictly positive and assuming kids 
  grow faster than adults.


```{r}
a_file <- here::here("fits", "m04H02.rds")
m04H02 <- readRDS(file = a_file)
# m04H02 <- quap(
#     flist = alist(
#         height ~ dnorm(mu, sigma),
#         mu <- a + b * weight,
#         a ~ dnorm(80, 40),
#         b ~ dlnorm(1, 0.5),
#         sigma ~ dexp(1)
#         ),
#     data = d,
#     start = list(a = mean(d$height), b = 1)
# )
# saveRDS(m04H02, file = a_file)
m04H02_summ <- rethinking::precis(m04H02, prob = 0.89)
m04H02_summ
```

for 10 more units of weights the child should be taller between 26 and 28 cm.

### 4H2 b) with `quap` {-}

#### Get the fitted values with `quap` {-}

See section 4.4.3.4 for more details.

```{r}
weight_seq <- round(range(d$weight), 0)
weight_seq <- seq(from = weight_seq[1], to = weight_seq[2], by  = 1)
weight_seq <- data.frame(weight = weight_seq)
```

```{r}
precis(m04H02)
# m04H02_post <- extract.samples(m04H02)
```

See the overthinking box in section 4.4.3.4 to explain `rethinking::link()`

```{r}
m04H02_fitted <- rethinking::link(fit = m04H02, 
                                 data = weight_seq, 
                                 n = 1000)
# str(m04H02_fitted)
m04H02_fitted_inrvl <- apply(X = m04H02_fitted, MARGIN = 2, FUN = function(x) {
  c("mean" = mean(x), rethinking::HPDI(x))
}) %>%
  t() %>%
  bind_cols(weight = weight_seq) %>%
  as.data.frame()
# m04H02_fitted_inrvl
```
and the prediction intervals are obtained as described in section 4.4.3.5
using `rethinking::sim()`

```{r}
m04H02_predict <- rethinking::sim(fit = m04H02,
                                 data = data.frame(weight = weight_seq),
                                 n = 1000)
m04H02_predict_inrvl <- apply(X = m04H02_predict, MARGIN = 2, FUN = function(x) {
  c("mean" = mean(x), rethinking::HPDI(x))
}) %>% 
  t() %>%
  bind_cols(weight = weight_seq) %>%
  as.data.frame()
# m04H02_predict_inrvl
```




```{r}
ggplot(data = d, aes(x = weight)) +
  geom_ribbon(data = m04H02_predict_inrvl,
              aes(ymin = `|0.89`, ymax = `0.89|`),
              fill = "lightcyan") +
  geom_smooth(data = m04H02_fitted_inrvl,
              aes(y = mean, ymin = `|0.89`, ymax = `0.89|`),
              stat = "identity",
              fill = "lightcyan3", color = "black", alpha = 1, size = 1/2) +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.linear_kryw_5_100_c67") +
  coord_cartesian(xlim = range(d$weight), ylim = range(d$height)) +
  theme_minimal() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.1, 0.8)) +
  labs(title = "quap fit - Practice 4H2", x = "weight", y = "height")
```


### 4H2 a) with `brm` {-}

Same comments and conclusion as for `quap` above

```{r}
a_file <- here::here("fits", "b04H02.rds")  # save to rds file
b04H02 <- readRDS(file = a_file)
# b04H02 <- brms::brm(data = d,
#                          formula = height ~ 1 + weight,
#                          family = gaussian(),
#                          prior = c(
#                            prior(normal(100, 50), class = Intercept),
#                            prior(lognormal(0, 2), class = b, lb = 0),
#                            prior(cauchy(0, 1), class = sigma)),
#                          iter = 2000, warmup = 1000, chains = 4,
#                          cores = detectCores(), seed = 4)
# saveRDS(b04H02, file = a_file)
b04H02_fixf <- brms::fixef(b04H02)
b04H02_fixf
```

### 4H2 b) with `brm` {-}


```{r}
weight_seq <- round(range(d$weight), 0)
weight_seq <- seq(from = weight_seq[1], to = weight_seq[2], by  = 1)
weight_seq <- data.frame(weight = weight_seq)
```


```{r}
b04H02_fitted <-
  fitted(b04H02, newdata = weight_seq, probs = c(0.055, 0.945)) %>%
  data.frame() %>%
  bind_cols(weight_seq)
# glimpse(b04H02_fitted)

b04H02_predict <-
  predict(b04H02, newdata = weight_seq, probs = c(0.055, 0.945)) %>%
  data.frame() %>%
  bind_cols(weight_seq)
# glimpse(b04H02_predict)
```


and we illustrate the results


```{r}
ggplot(data = d, aes(x = weight)) +
  geom_ribbon(data = b04H02_predict,
              aes(ymin = Q5.5, ymax = Q94.5),
              fill = "lightcyan") +
  geom_smooth(data = b04H02_fitted,
              aes(y = Estimate, ymin = Q5.5, ymax = Q94.5),
              stat = "identity",
              fill = "lightcyan3", color = "black", alpha = 1, size = 1/2) +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.linear_kryw_5_100_c67") +
  coord_cartesian(xlim = range(d$weight), ylim = range(d$height)) +
  theme_minimal() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.1, 0.8)) +
  labs(title = "BRMS fit - Practice 4H2", x = "weight", y = "height")
```


### 4H2 c) {-}

The data points seem to have a nonlinear relation with weight, visually, it seems, maybe,
that a quadratice might be a better fit.


## 4H3 {-}

This is covered by section 4.5.1 polynomial regression but instead of polynomial
we use a log equation.

The data is

```{r}
data("Howell1")
d <- Howell1 %>%
  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE))
rm("Howell1")
skimr::skim(d)
```


The model used is

$$
\begin{align*}
height_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \log{(\beta)} \cdot weight_i \\
\alpha &\sim \mathcal{N}(178, 20) \\
\beta &\sim \mathcal{N}(0, 10) \\
\sigma &\sim \mathcal{Uniform}(0, 50)
\end{align*}
$$

### 4H3 a) using `quap` {-}

> Important: We have to use `dunif` for sigma to make the `quap` converge. Otherwise
the cov matrix is not positive definite.

```{r}
a_file <- here::here("fits", "m04H03.rds")  # save to rds file
m04H03 <- readRDS(file = a_file)
# m04H03 <- rethinking::quap(
#     flist = alist(
#         height ~ dnorm(mu, sigma),
#         mu <- a + b * log(weight),
#         a ~ dnorm(178, 20),
#         b ~ dnorm(0, 10),
#         sigma ~ dunif(0, 50)
#         ),
#     data = d
# )
# saveRDS(m04H03, file = a_file)
precis(m04H03, prob = 0.89)
```

Since we use $\log{weight}$ than any change of $\log{weight}$ represents
a percentage change of $weight$, therefore $b$ represents that, for every
percentage increase of the weight, the height is reduced by -2.65 of a percentage.


### 4H3 b) using `quap` {-}

We use the same process as in 4H2 just above

```{r}
weight_seq <- round(range(d$weight), 0)
weight_seq <- seq(from = weight_seq[1], to = weight_seq[2], by  = 1)
weight_seq <- data.frame(weight = weight_seq)
```

same process as in 4H2 above

```{r}
m04H03_fitted <- rethinking::link(fit = m04H03, 
                                 data = weight_seq, 
                                 n = 1000)
# str(m04H03_fitted)
m04H03_fitted_inrvl <- apply(X = m04H03_fitted, MARGIN = 2, FUN = function(x) {
  c("mean" = mean(x), rethinking::HPDI(x, prob = 0.97))
}) %>%
  t() %>%
  bind_cols(weight = weight_seq) %>%
  as.data.frame()
# m04H03_fitted_inrvl
```
and the prediction intervals are obtained as described in section 4.4.3.5
using `rethinking::sim()` (sames as in 4H2 above)

```{r}
m04H03_predict <- rethinking::sim(fit = m04H03,
                                 data = data.frame(weight = weight_seq),
                                 n = 1000)
m04H03_predict_inrvl <- apply(X = m04H03_predict, MARGIN = 2, FUN = function(x) {
  c("mean" = mean(x), rethinking::HPDI(x, prob = 0.97))
}) %>% 
  t() %>%
  bind_cols(weight = weight_seq) %>%
  as.data.frame()
# m04H03_predict_inrvl
```




```{r}
ggplot(data = d, aes(x = weight)) +
  geom_ribbon(data = m04H03_predict_inrvl,
              aes(ymin = `|0.97`, ymax = `0.97|`),
              fill = "aquamarine1") +
  geom_smooth(data = m04H03_fitted_inrvl,
              aes(y = mean, ymin = `|0.97`, ymax = `0.97|`),
              stat = "identity",
              fill = "aquamarine4", color = "black", alpha = 1, size = 1/2) +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.linear_kry_5_98_c75") +
  coord_cartesian(xlim = range(d$weight), ylim = range(d$height)) +
  theme_minimal() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.1, 0.8)) +
  labs(title = "quap fit - Practice 4H3", x = "weight", y = "height")
```


### 4H3 a) using `brm` {-}


Same comments and conclusion as for `quap` above. The results are very similar.

```{r}
a_file <- here::here("fits", "b04H03.rds")  # save to rds file
b04H03 <- readRDS(file = a_file)
# b04H03 <- brms::brm(data = d,
#                    formula = height ~ 1 + log(weight),
#                    family = gaussian,
#                    prior =
#                      c(prior(normal(178, 20), class = Intercept),
#                        prior(normal(0, 10), class = b),
#                        prior(cauchy(0, 1), class = sigma)),
#                    iter = 2000, warmup = 1000, chains = 4,
#                    cores = detectCores(), seed = 4)
# saveRDS(b04H03, file = a_file)
b04H03_fixf <- brms::fixef(b04H03)
b04H03_fixf
```

prior(cauchy(0, 1), class = sigma)

### 4H3 b) using `brm` {-}


```{r}
weight_seq <- round(range(d$weight), 0)
weight_seq <- seq(from = weight_seq[1], to = weight_seq[2], by  = 1)
weight_seq <- data.frame(weight = weight_seq)
```


```{r}
b04H03_fitted <-
  fitted(b04H03, newdata = weight_seq, probs = c(0.015, 0.985)) %>%
  data.frame() %>%
  bind_cols(weight_seq)
# glimpse(b04H03_fitted)

b04H03_predict <-
  predict(b04H03, newdata = weight_seq, probs = c(0.015, 0.985)) %>%
  data.frame() %>%
  bind_cols(weight_seq)
# glimpse(b04H03_predict)
```


and we illustrate the results


```{r}
ggplot(data = d, aes(x = weight)) +
  geom_ribbon(data = b04H03_predict,
              aes(ymin = Q1.5, ymax = Q98.5),
              fill = "aquamarine1") +
  geom_smooth(data = b04H03_fitted,
              aes(y = Estimate, ymin = Q1.5, ymax = Q98.5),
              stat = "identity",
              fill = "aquamarine4", color = "black", alpha = 1, size = 1/2) +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.linear_kry_5_98_c75") +
  coord_cartesian(xlim = range(d$weight), ylim = range(d$height)) +
  theme_minimal() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.1, 0.8)) +
  labs(title = "BRMS fit - Practice 4H3", x = "weight", y = "height")
```

## 4H4 {-}

See section 4.5.1  for reference to this practice. R code 4.65 (p. 111)

The data is as in section 4.5.1.  This practice is using techniques that
are illustrated at the beginning of section 5.1 in the next chapter.

```{r}
data("Howell1")
df04H4 <- Howell1 %>%
  mutate(weight_c = scale(weight, center = TRUE, scale = FALSE),
         weight_c2 = weight_c ^ 2)
skimr::skim(df04H4)
```


the model has been slightly modified by using the centered weight instead of
the standard weight.  It seems to work better with `quap`.

The values for $a$ are from the summary using `skimr` just above.


$$
\begin{align*}
h_i &\sim \mathcal{N}(\mu_i, \sigma)\\
\mu_i &= \alpha + \beta_1 \cdot weight\_c_i + \beta_2 \cdot weight\_c^2_i \\
\alpha &\sim \mathcal{N}(138, 50) \\
\beta_1 &\sim \mathcal{LogNormal}(0,1) \\
\beta_2 &\sim \mathcal{N}(0,1) \\
\sigma &\sim \mathcal{Exp}(1)
\end{align*}
$$

### 4H4 using `quap` {-}




```{r}
a_file <- here::here("fits", "m04H04.rds")  # save to rds file
m04H04 <- readRDS(file = a_file)
# m04H04 <- quap(
#   flist = alist(
#     height ~ dnorm(mu, sigma),
#     mu <- a + b1 * weight_c + b2 * weight_c2,
#     a ~ dnorm(138, 50),
#     b1 ~ dlnorm(0, 1),
#     b2 ~ dnorm(0, 1),
#     sigma ~ exp(1)
#   ),
#   data = df04H4
# )
# saveRDS(m04H04, file = a_file)
rethinking::precis(m04H04)
```
The function `rethinking::extract.prior()` is used to extract the sample distributions
from the fit.  Then the process of finding the mus is the same as the overthinking box
of section 4.4.3.4 (p.107).  Or in other words, using the `link` function with
the prior used in the `post` argument
.

```{r}
m04H04_prior <- extract.prior(m04H04, n = 1000) %>%
  as.data.frame()
str(extract.prior(m04H04, n = 1000))
```

and find the predictions using the detailed method as described
in overthinking box of section 4.4.3.4. The `rethinking::link()` function
does that. For an example, see at the beginning of section 5.1 in the next chapter, 
R code 5.4.

For this exercise, we will do it the long way.

```{r}
weight_seq <- round(range(df04H4$weight_c), 0)
weight_seq <- seq(from = weight_seq[1], to = weight_seq[2], 
                  by = 1)
weight_seq <- data.frame(weight_c = weight_seq)
# str(weight_seq)
```


```{r}
m04H04_prior$sigma

the_prior_preds <- lapply(X = weight_seq$weight_c, FUN = function(x) {
  mu <- m04H04_prior$a + m04H04_prior$b1 * x + m04H04_prior$b2 * x^2
  y <- rnorm(n = length(mu),
             mean = mu,
             sd = m04H04_prior$sigma)
  ggdist::mean_hdi(y, .width = 0.89)
})
the_prior_preds <- do.call(rbind, the_prior_preds) %>%
  bind_cols(weight_seq) %>%
  as.data.frame()
# str(the_prior_preds)
```


```{r}
ggplot(data = df04H4, aes(x = weight_c)) +
  geom_line(data = the_prior_preds, aes(y = y), size = 1, color = "purple") +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
  scale_x_continuous( breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.rainbow_bgyrm_35_85_c71") +
  theme_minimal() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.85, 0.30)) +
  labs(title = "quap fit with PRIOR - Practice 4H4", x = "weight", y = "height")
```

which shows that the prior is not so bad, it's shape aligns with the data, only
the intercept actually need to be modified.

> Conclusion: It's a very good idea to simulate the priors.  It tells us
if they make sense.  It helps greatly in having a converging fit.


### 4H4 using `brm` {-}

**Note the use of `sample_prior = TRUE`** to be able to obtain the prior
samples.  We use the prior $b1 \sim \mathcla{N}(0,1)$ instead of $\mathcal{LogNormal}$
which gives a much better prior in this case.

```{r}
a_file <- here::here("fits", "b04H04.rds")
b04H04 <- readRDS(file = a_file)
# b04H04 <- brms::brm(data = df04H4,
#                    formula = height ~ 1 + weight_c + weight_c2,
#                    family = gaussian,
#                    prior =
#                      c(prior(normal(138, 50), class = Intercept),
#                        prior(normal(0, 1), class = b, coef = "weight_c"),
#                        prior(normal(0, 1), class = b, coef = "weight_c2"),
#                        prior(cauchy(0, 1), class = sigma)),
#                    iter = 2000, warmup = 1000, chains = 4,
#                    sample_prior = TRUE,
#                    cores = detectCores(), seed = 4)
# saveRDS(b04H04, file = a_file)
brms::fixef(b04H04)
```

create the sequence of weights to use

```{r}
weight_seq <- round(range(df04H4$weight_c), 0)
weight_seq <- seq(from = weight_seq[1], to = weight_seq[2], length.outt = 30)
weight_seq <- data.frame(weight_c = weight_seq) %>%
  mutate(weight_c2 = weight_c^2)
# glimpse(weight_seq)
```

sample the prior and create the fit

```{r}
b04H04_prior <- brms::prior_samples(b04H04)
b04H04_prior_fit <- b04H04_prior %>%
  slice_sample(n = 100) %>%
  tibble::rownames_to_column("draw") %>%
  expand(nesting(draw, Intercept, b_weight_c, b_weight_c2),
                 x = weight_seq$weight_c, x2 = weight_seq$weight_c2) %>%
  mutate(height_fit = Intercept + b_weight_c * x + b_weight_c2 * x2)
glimpse(b04H04_prior_fit)
b04H04_prior_fit_interval <- b04H04_prior_fit %>%
  group_by(x) %>%
  do(ggdist::mean_hdi(.$height_fit, .width = 0.89)) %>%
  rename("mu" = x, "height" = y)
glimpse(b04H04_prior_fit_interval)
```


get the posterior fit($\mu$) and prediction  ($\hat{y}$)

```{r}
b04H04_fitted <-
  fitted(b04H04, newdata = weight_seq, probs = c(0.055, 0.945)) %>%
  data.frame() %>%
  bind_cols(weight_seq)
# glimpse(b04H04_fitted)

b04H04_predict <-
  predict(b04H04, newdata = weight_seq, probs = c(0.055, 0.945)) %>%
  data.frame() %>%
  bind_cols(weight_seq)
# glimpse(b04H04_predict)
```


visualize the prior and posterior

```{r}
ggplot(df04H4, aes(x = weight_c)) +
  geom_ribbon(data = b04H04_predict,
              aes(ymin = Q5.5, ymax = Q94.5),
              fill = "slategray1") +
  geom_smooth(data = b04H04_fitted,
              aes(y = Estimate, ymin = Q5.5, ymax = Q94.5),
              stat = "identity",
              fill = "slategray4", color = "black", alpha = 1, size = 1/2) +
  geom_line(data = b04H04_prior_pred_interval, aes(y = height), 
            size = 1, color = "purple") +
  geom_point(aes(y = height, color = age), shape = 20, size = 2, alpha = 2/3) +
    theme_minimal() +
  scale_x_continuous(breaks = scales::breaks_extended(n = 7)) +
  scale_color_paletteer_c("pals::kovesi.rainbow_bgyrm_35_85_c71") +
  coord_cartesian(xlim = range(weight_seq$weight_c)) +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.80, 0.30)) +
  labs(title = "BRMS fit with PRIOR - Practice 4H4", x = "weight", y = "height")
```
