```{r include=FALSE}
library(dplyr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(tidybayes, quietly = TRUE)
library(rethinking)
library(brms)
library(loo)
library(dagitty, quietly = TRUE)
library(ggdag, quietly = TRUE)
library(ggdist, quietly = TRUE)
library(patchwork, quietly = TRUE)
library(paletteer, quietly = TRUE)
```


# Ulysses' Compass {#information}


## 7E1 {-}

See section 7.2.2.

* Continuous: there should be no "jump" in the index.
* Measure of uncertainty is increasing: As the number of possible choices increases, the uncertainty increases and so should the measure
* Measure should be additive: We should be able to add the uncertainty of an event to the uncertainty of another event so that the total uncertainty is higher

## 7E2 {-}

See equation 7.1 in section 7.2.2.

```{r}
p <- c(0.7, 0.3)
sum(-p * log(p))
```

## 7E3 {-}

See equation 7.1 in section 7.2.2.

```{r}
p <- c(0.2, 0.25, 0.25, 0.3)
sum(-p * log(p))
```


## 7E4 {-}

In this case, since the last probability = 0 we don't include it. See the Overthinking
box at the end of section 7.2.2 about L'Hopital's rule.

```{r}
p <- rep(1/3, times = 3)
sum(-p * log(p))
```


## 7M1 {-}

### AIC {-}

See beginning of section 7.4.2 for AIC

$$
AIC = D_{train} + 2 \cdot p = -2 \cdot lppd + 2 \cdot p
$$
The assumptions on which AIC is based are

1. priors are flat or overwhelmed by data
2. posterior distribution is approximately multivariate Gaussian
3. The sample size $N$ is much greater than the number of parameters $k$, $N \gg k$


### WAIC {-}

See section 7.4.2 for definition


$$
WAIC = -2 (lppd - p_{WAIC}) = -2 (lppd - \sum_{i=1}^N{var_{\theta} \log{p(y_i \mid \theta)}})
$$
where $p_{waic}$ is called the penalty term or effective number of parameters.

WAIC makes no assumption about the shape of the posterior. *It provides an
approximation of the out-of-sample deviance that converges to the cross-validation 
approximation in a large sample.* Section 7.4.2, p. 220.


## 7M2 {-}

Model selection and model comparison are defined in the introduction of
section 7.5.

### Model selection {-}

Selecting the model with the lowest information criterion value (WAIC, LOO) 
and discard the other models. It should be avoided as you loose the information
about the relative model accuracy contained in the different criteria.

### Model comparison {-}

Using multiple models t understand how different variables influence predictions
and implied conditional independencies which explain causality.

2 issues arise in model comparison
1. Distinction between models for predictions and models for causation
2. Pointwise nature of model comparison to understand the influential data points.

## 7M3 {-}

See rethinking box at the end of section 7.4.3 which explains that all the
information criteria assume that the data is **generated by the same process**.

In addition 2 more technical details are to be remembered to justify
data cleaning

1. If you don't remove the missing cases, the internal routines of the stat functions might treat them differently without you knowing about it
2. The information criteria is sensitive to the number of observations, therefore make sure no dropping of NA, NaN or Inf occurs unexpectedly my cleaning up the data before performing the analysis.

## 7M4 {-}

A shown in figure 7.9 of section 7.4.3  as the number of parameters increases (i.e. the priors are less concentrated) than the effective number of parameters increase and the average
deviance is reduced.

## 7M5 {-}

Because they provide a more relevant range of hypothesis thus reduced the 
importance given to marginal values of the parameters.

## 7M6 {-}

Because they reduce the range of hypothesis to be tested so narrowly that relevant values and/or parameters are not given enough relevance to appear in the final model.


## 7H1 {-}


```{r}
data(Laffer)
d <- Laffer
skimr::skim(d)
```

```{r}
a_file <- here::here("fits", "b07H01.rds")
b07H01 <- readRDS(file = a_file)
# b07H01 <- brm(
#   data = d,
#   formula = tax_revenue ~ 1 + tax_rate,
#   family = gaussian,
#   prior = c(
#     prior(normal(25, 10), class = Intercept),
#     prior(normal(0, 0.5), class = b),
#     prior(exponential(1), class = sigma)
#     ),
#   iter = 2000, warmup = 1000, chains = detectCores(),
#   core = detectCores(), seed = 7
#  )
# b07H01 <- brms::add_criterion(b07H01, criterion = c("waic", "loo"))
# saveRDS(b07H01, file = a_file)
summary(b07H01)
```

get the fitted and predicted values.

```{r}
rate_seq <- tibble(tax_rate = seq(from = 0, to = 36, by = 1))

b07H01_fitted <-
  fitted(b07H01, newdata = rate_seq) %>%
  data.frame() %>%
  bind_cols(rate_seq)
glimpse(b07H01_fitted)

b07H01_predict <-
  predict(b07H01, newdata = rate_seq) %>%
  data.frame() %>%
  bind_cols(rate_seq)  
glimpse(b07H01_predict)
```


plot the data

```{r}
ggplot(data = d, aes(x = tax_rate)) +
  geom_ribbon(data = b07H01_predict,
              aes(ymin = Q2.5, ymax = Q97.5),
              fill = "lightcyan") +
  geom_smooth(data = b07H01_fitted,
              aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
              stat = "identity",
              fill = "lightcyan3", color = "black", alpha = 1, size = 1/2) +
  geom_point(aes(y = tax_revenue), color = "purple", shape = 20, size = 3, alpha = 2/3) +
  scale_x_continuous(breaks = scales::breaks_extended(n = 7)) +
  coord_cartesian(xlim = range(d$tax_rate), ylim = range(d$tax_revenue)) +
  theme_minimal() +
  theme(title = element_text(color = "midnightblue"),
        legend.position = c(0.1, 0.8)) +
  labs(title = "Laffer model", x = "tax rate", y = "tax revenue")
```


## 7H2 {-}

### Use WAIC and PSIS to evaluate the outliers {-}

See section 7.5.2, figure 7.10.


```{r}
dp <- tibble(pareto_k = b07H01$criteria$loo$diagnostics$pareto_k,
       p_waic   = b07H01$criteria$waic$pointwise[, "p_waic"],
       tax_rate      = d$tax_rate,
       out = p_waic > 0.5)
ggplot(dp, aes(x = pareto_k, y = p_waic, color = out)) +
    geom_vline(xintercept = 0.5, linetype = 2, color = "red", alpha = 1/2) +
    geom_point() +
    ggrepel::geom_text_repel(aes(label = round(tax_rate, 1))) +
    scale_color_manual(values = c("darkgreen", "violetred")) +
    scale_shape_manual(values = c(19, 19)) +
    theme_minimal() +
    theme(legend.position = "none") +
    labs(title = "Lafer model - Gaussian likelihood", subtitle = "Labels represents tax rates",
         x = "WAIC", y = "PSIS")
```


### Robust regression with t-student distribution {-}

See section 7.5.2, R code 7.35

```{r}
a_file <- here::here("fits", "b07H02.rds")
b07H02 <- readRDS(a_file)
# b07H02 <-
#   brm(data = d,
#       family = student,
#       bf(tax_revenue ~ 1 + tax_rate, nu = 2),
#       prior = c(prior(normal(25, 10), class = Intercept),
#                 prior(normal(0, 0.5), class = b),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),
#       seed = 7)
# b07H02 <- brms::add_criterion(b07H02, criterion = c("waic", "loo"))
# saveRDS(b07H02, file = a_file)
summary(b07H02)
```



```{r}
dp <- tibble(pareto_k = b07H02$criteria$loo$diagnostics$pareto_k,
       p_waic   = b07H02$criteria$waic$pointwise[, "p_waic"],
       tax_rate      = d$tax_rate,
       out = p_waic > 0.5)
ggplot(dp, aes(x = pareto_k, y = p_waic, color = out)) +
    geom_vline(xintercept = 0.5, linetype = 2, color = "red", alpha = 1/2) +
    geom_point() +
    ggrepel::geom_text_repel(aes(label = round(tax_rate, 1))) +
    scale_color_manual(values = c("darkgreen", "violetred")) +
    scale_shape_manual(values = c(19, 19)) +
    theme_minimal() +
    theme(legend.position = "none") +
    labs(title = "Lafer model - t-Student likelihood", 
         subtitle = "Labels represents tax rates",
         x = "WAIC", y = "PSIS")
```

## 7H3 {-}

```{r}
d <- data.frame(
  A = c(0.2, 0.8, 0.05),
  B = c(0.2, 0.1, 0.15),
  C = c(0.2, 0.05, 0.7),
  D = c(0.2, 0.025, 0.05),
  E = c(0.2, 0.025, 0.05)
)
row.names(d) <- paste("island", 1:3)
stopifnot(sum(d[1, ]) == 1, sum(d[2, ]) == 1, sum(d[3, ]) == 1)
d
```

### islands' entropies {-}

```{r}
apply(d, MARGIN = 1, FUN = function(p) -sum(p * log(p)))
```
Island 1 has a distribution with maximum entropy, i.e. less information, because
the bird population is uniform and therefore the same everywhere on the island
which is the similar knowing nothing about the island.

Island 2 has the least entropy, that is the most informaiton to reduce uncertainty.
The information seems to be more specific about ehrer the birds are located.


### Kullback-Leiber divergence {-}


```{r}
apply(d, MARGIN = 1, FUN = function(p) {
  apply(d, MARGIN = 1, FUN = function(q) {
    sum(p * (log(p) - log(q)))
  })
})
```
overall, the $D_{KL}$ is lowest with island 1 and therefore points out
to island as the best prior to use.  This is caused by the fact that island 1
having a uniform prior, i.e. assuming nothing about the distribution of the
other islands, it will be looking at more possibilities for it's prediction.

See discussion in section 7.2.3 in page 208, near the end.


## 7H4 {-}

See section 6.3.1 for the data used.


```{r}
d <- rethinking::sim_happiness(seed = 1977, N_years = 1000)
# select age > 17 and rescale to [0, 1] and create indexed factor
# creating factor makes it easer with brms
d2 <- d %>%
  filter(age > 17) %>%
  mutate(A = scales::rescale(age, to = c(0, 1)),
         mid = factor(married + 1, labels = c("single", "married")))
glimpse(d2)
```

```{r}
a_file <- here::here("fits", "b07H4a.rds")
b07H4a <- readRDS(a_file)
# b07H4a <-
#   brm(data = d2,
#       family = gaussian,
#       happiness ~ 0 + mid + A,
#       prior = c(prior(normal(0, 1), class = b, coef = midmarried),
#                 prior(normal(0, 1), class = b, coef = midsingle),
#                 prior(normal(0, 2), class = b, coef = A),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),
#       seed = 7)
# b07H4a <- brms::add_criterion(b07H4a, criterion = c("waic", "loo"))
# saveRDS(b07H4a, file = a_file)
brms::posterior_summary(b07H4a)
```

The fit finds that the effect of age on happiness is negative


now lets do it without the marriage factor

```{r}
a_file <- here::here("fits", "b07H4b.rds")
b07H4b <- readRDS(a_file)
# b07H4b <-
#   brm(data = d2,
#       family = gaussian,
#       happiness ~ 1 + A,
#       prior = c(prior(normal(0, 1), class = Intercept),
#                 prior(normal(0, 2), class = b),
#                 prior(exponential(1), class = sigma)),
#       iter = 2000, warmup = 1000, chains = 4, cores = detectCores(),
#       seed = 7)
# b07H4b <- brms::add_criterion(b07H4b, criterion = c("waic", "loo"))
# saveRDS(b07H4b, file = a_file)
brms::posterior_summary(b07H4b)
```

## 7H5 {-}

See practice 6H2 to 6H5 in chapter 6 for corresponding exercises.


```{r}
data(foxes)
d <- foxes %>%
  mutate(
    `F` = scale(as.vector(avgfood)),
    S = scale(as.vector(groupsize)),
    A = scale(as.vector(area)),
    W = scale(as.vector(weight))
  )
skimr::skim(d)
```

and the DAG is

```{r}
dag <- dagify(avgfood ~ area,
              groupsize ~ avgfood,
              weight ~ avgfood + groupsize)
ggplot(dag, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_dag_point(color = "aquamarine2") +
  # geom_dag_text(color = "mediumseagreen") +
  geom_dag_text_repel(aes(label = name), color = "royalblue") +
  geom_dag_edges() +
  theme_dag() +
  theme(title = element_text(color = "midnightblue")) +
  labs(title = "Practice 7H5 - foxes data")
```



### 7H5 1) {-}

$$
\begin{align*}
W_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_F \cdot F_i + \beta_S \cdot S_i + \beta_A \cdot A_i \\
\alpha &\sim \mathcal{N}(0, 0.5) \\
\beta_F &\sim \mathcal{N}(0, 0.25) \\
\beta_S &\sim \mathcal{N}(0, 0.25) \\
\beta_A &\sim \mathcal{N}(0, 0.25) \\
\sigma &\sim \mathcal{HalfCauchy}(0, 1)
\end{align*}
$$


```{r}
a_file <- here::here("fits", "b07H05a.rds")
b07H05a <- readRDS(file = a_file)
# b07H05a <- brm(
#   data = d,
#   formula = W ~ 1 + `F` + S + A,
#   family = gaussian,
#   prior = c(
#     prior(normal(0, 0.5), class = Intercept),
#     prior(normal(0, 0.25), class = b, coef = `F`),
#     prior(normal(0, 0.25), class = b, coef = S),
#     prior(normal(0, 0.25), class = b, coef = A),
#     prior(cauchy(0, 1), class = sigma)
#   ),
#   iter = 2000, warmup = 1000, chains = 4, core = detectCores(),
#   seed = 7
# )
# b07H05a <- brms::add_criterion(b07H05a, criterion = c("waic", "loo"))
# saveRDS(b07H05a, file = a_file)
summary(b07H05a)
```

### 7H5 2) {-}

$$
\begin{align*}
W_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_F \cdot F_i + \beta_S \cdot S_i \\
\alpha &\sim \mathcal{N}(0, 0.5) \\
\beta_F &\sim \mathcal{N}(0, 0.25) \\
\beta_S &\sim \mathcal{N}(0, 0.25) \\
\sigma &\sim \mathcal{HalfCauchy}(0, 1)
\end{align*}
$$


```{r}
a_file <- here::here("fits", "b07H05b.rds")
b07H05b <- readRDS(file = a_file)
# b07H05b <- update(b07H05a,
#                   newdata = d,
#                   formula = W ~ 1 + `F` + S, seed = 7)
# b07H05b <- brms::add_criterion(b07H05b, criterion = c("waic", "loo"))
# saveRDS(b07H05b, file = a_file)
summary(b07H05b)
```

### 7H5 3) {-}

$$
\begin{align*}
W_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_S \cdot S_i + \beta_A \cdot A_i \\
\alpha &\sim \mathcal{N}(0, 0.5) \\
\beta_S &\sim \mathcal{N}(0, 0.25) \\
\beta_A &\sim \mathcal{N}(0, 0.25) \\
\sigma &\sim \mathcal{HalfCauchy}(0, 1)
\end{align*}
$$


```{r}
a_file <- here::here("fits", "b07H05c.rds")
b07H05c <- readRDS(file = a_file)
# b07H05c <- update(b07H05a,
#                   newdata = d,
#                   formula = W ~ 1 + S + A, seed = 7)
# b07H05c <- brms::add_criterion(b07H05c, criterion = c("waic", "loo"))
# saveRDS(b07H05c, file = a_file)
summary(b07H05c)
```

### 7H5 4) {-}

$$
\begin{align*}
W_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_F \cdot F_i \\
\alpha &\sim \mathcal{N}(0, 0.5) \\
\beta_F &\sim \mathcal{N}(0, 0.25) \\
\sigma &\sim \mathcal{HalfCauchy}(0, 1)
\end{align*}
$$


```{r}
a_file <- here::here("fits", "b07H05d.rds")
b07H05d <- readRDS(file = a_file)
# b07H05d <- update(b07H05a,
#                   newdata = d,
#                   formula = W ~ 1 + `F`, seed = 7)
# b07H05d <- brms::add_criterion(b07H05d, criterion = c("waic", "loo"))
# saveRDS(b07H05d, file = a_file)
summary(b07H05d)
```


### 7H5 5) {-}

$$
\begin{align*}
W_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_A \cdot A_i \\
\alpha &\sim \mathcal{N}(0, 0.5) \\
\beta_A &\sim \mathcal{N}(0, 0.25) \\
\sigma &\sim \mathcal{HalfCauchy}(0, 1)
\end{align*}
$$


```{r}
a_file <- here::here("fits", "b07H05e.rds")
b07H05e <- readRDS(file = a_file)
# b07H05e <- update(b07H05a,
#                   newdata = d,
#                   formula = W ~ 1 + A, seed = 7)
# b07H05e <- brms::add_criterion(b07H05e, criterion = c("waic", "loo"))
# saveRDS(b07H05e, file = a_file)
summary(b07H05e)
```



### 7H5 Model comparison {-}

See section 7.5.1 for details.


```{r}
w <- loo::loo_compare(b07H05a, b07H05b, b07H05c, b07H05d, b07H05e, 
                      criterion = "waic") %>% 
  data.frame() %>%
  tibble::rownames_to_column("model_name") %>%
  mutate(model_name = forcats::fct_reorder(model_name, waic, .desc = TRUE))
w
```

```{r}
ggplot(w, aes(x = waic, y = model_name, xmin = waic - se_waic, xmax = waic + se_waic)) +
  geom_pointrange(shape = 19, color = "aquamarine4") +
  ggrepel::geom_text_repel(aes(label = round(waic, 0))) +
  ggthemes::theme_few() +
  theme(title = element_text(color = "midnightblue"),
        panel.border = element_blank()) +
  labs(title = "7H5 WAIC plot", x = "waic", y = NULL)
```

Models b07H05d and b07H05e which are univariate have similar, higher, waic scores
and therefore are less informative than the multivariate models.

Howeer the standard errors are large and most waic are actually likely to be
less distinct then one might conclude.
