```{r include=FALSE}
library(dplyr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(tidybayes, quietly = TRUE)
library(rethinking)
library(brms)
library(loo)
library(dagitty, quietly = TRUE)
library(ggdag, quietly = TRUE)
library(ggdist, quietly = TRUE)
library(ggmcmc, quietly = TRUE)
library(bayesplot, quietly = TRUE)
library(patchwork, quietly = TRUE)
library(paletteer, quietly = TRUE)
```


# Counting and Classification {#Counting}

## 11E1 {-}

```{r}
prob <- 0.35
# using the definition of logit
lodds = log(prob / (1 - prob))
lodds
# in coding we use a predefined function such as `gtools::logit()`
stopifnot(lodds == gtools::logit(prob))
```
## 11E2 {-}

```{r}
lodds <- 3.2
prob = exp(lodds) / (1 + exp(lodds))
prob
# in coding we use a predefined function such as `gtools::inv.logit()`
stopifnot(prob == gtools::inv.logit(lodds))
```
## 11E3 {-}

See Overthinking box in section 11.1.2.


Since the logistic regression is using the link function

$$
logit(p) = \log{\frac{p}{1-p}}= \alpha + \beta x
$$

then the odds are

$$
odds(p) = \frac{p}{1-p} = \exp{(\alpha + \beta x)}
$$

and the *proportional* effect of $\beta$ is found when we increase $x$ by one unit. That is
the effect, called $z$, is found by solving for $z$

$$
\begin{align*}
\exp{(\alpha + \beta x)} \cdot z &= \exp{(\alpha + \beta (x + 1))} \\
z &= \frac{\exp{(\alpha + \beta x + 1)}}{\exp{(\alpha + \beta x)}} \\ &=
 \frac{\exp{(\beta (x + 1))}}{\exp{(\beta x)}} \\
 &= \exp(\beta)
\end{align*}
$$
Therefore the proportional change $z$ is $e^\beta$ which in this case is

```{r}
exp(1.7)
```

## 11E4 {-}

See section 11.2.3 for details.

The $\lambda$ parameter in Poisson can also
be seen as a rate.  The exposure is the denominator of that rate.  If different
observations have different exposure then an offset is required in the Poisson model.

So if we have the model

$$
\begin{align*}
y_i \sim Poisson(\lambda_i) \\
\log{\lambda_i} = \alpha + \beta x_i \\
\end{align*}
$$

Then the rate $\lambda_i$ is in fact $\lambda_i = \frac{\mu_i}{\tau_i}$ where
$\tau_i$ is the exposure and


$$
\begin{align*}
y_i &\sim Poisson(\lambda_i) \\
\log{\lambda_i} &= \log{\frac{\mu_i}{\tau_i}}  = \alpha + \beta x_i \\
\end{align*}
$$

For example if the count is over days and weeks then the exposures will be 1 and 7.


## 11M1 {-}

See beginning of section 11.1.3 for discussion.

The difference in the likelihood function is caused by the different organization
of data. In the binomial model there is only 2 outcomes for each observation
and therefore the joint probability is just a chain of bernoulli probability.

For example, in simple binomial probabilty, the probability of obtaining a $x_1=1$
and $x_2=0$ is $p(1-p)$. That is $P(x_i=1, x_2 =0) = p(1-p)= P(x_i=1, x_2 =0)$.

But if we organize the data differently and each observation is the total number
of success then $P(x_1 = 1 \mid n =2)= \binom{1}{2}p(1-p)$ because we have to take
into account there are $\binom{1}{2}$ possible orderings.


## 11M2 {-}

See 11E3 above for similar question and same method to answer.

The Poisson model is

$$
\begin{align*}
y_i &\sim \mathcal{Poisson}(\lambda_i) \\
\log{\lambda_i} &= \alpha + \beta x_i \\
&\therefore \\
\lambda_i &= \exp{(\alpha + \beta x_i)}
\end{align*}
$$

therefore the effect is found by solving the proportional change $z$ in

$$
\begin{align*}
\exp{(\alpha + \beta x_i)} \cdot z &= \exp{(\alpha + \beta (x_i + 1))} \\
z &= e^\beta
\end{align*}
$$

Therefore the effect of a coeficient of 1.7 will be a proportionally change the
rate $\lambda_i$ by

```{r}
exp(1.7)
```

## 11M3 {-}

See section 10.2.2 in chapter 10.

The $logit$ link puts the parameter $p \in [0,1]$ on the scale $(-\infty, \infty)$ so that the
Gaussian model can be used on the transformed variable.

## 11M4 {-}

See section 10.2.2 in chapter 10.

The $log$ link puts the parameter $\lambda \in [0,\infty)$ on the scale $(-\infty, \infty)$ so that the
Gaussian model can be used on the transformed variable.

## 11M5 {-}

If $\lambda \in [0,1]$ then the logit link used is justified as discussed in
11M3 above.

Poisson can be used to approximate the binomial distribution when $p$ is small.
But it is also a distribution in its own right and there could be cases where
we have $\lambda \in [0,1]$ and the goal is **not** to approximate the binomial
distribution (i.e. $p$ is not small).

As an example, when $\lambda$ is expressed  as a percentage of dark-colored
cars passing every day at an intersection.

## 11M6 {-}

See section 10.1.2 in chapter 10 for the binomial distribution.  It has maximum 
entropy when

1. there is only 2 unordered events,
2. it has a constant expected value

See section 10.2.1 for Poisson distribution.

It is a special case of the binomial distribution when the probability of 
success $p$ is very small and the number of trials is very large. 
It has the same constraints as the binomial distribution in that case.

## 11M7 {-}

```{r echo=FALSE}
message("TODO")
```


## 11M8 {-}

See section 11.2.1 for details.

```{r}
data(Kline)
d <- Kline %>%
  mutate(log_pop_s = log(population),
         log_pop_s = as.vector(scale(log_pop_s)),
         cid = factor(contact, levels = c("low", "high")))
rm(Kline)
```

$$
total\_tools_i \sim \mathcal{Poisson}(\lambda_i) \\
\log{\lambda_i} = \alpha_{cid[i]} + \beta_{cid[i]} \log{log\_pop\_s_i} \\
\alpha_j \sim \mathcal{N}(3, 0.5) \\
\beta_k \sim \mathcal{N}(0, 0.2)
$$
the fit *including* Hawaii is


```{r}
a_file <- here::here(getwd(), "fits", "b11M08a.rds")
b11M08a <- readRDS(a_file)
# b11M08a <- brm(data = d,
#              family = poisson,
#              formula = bf(total_tools ~ a + b * log_pop_s,
#                           a + b ~ 0 + cid,
#                           nl = TRUE),
#              prior = c(prior(normal(3, 0.5), nlpar = a),
#                        prior(normal(0, 0.2), nlpar = b)),
#              cores = detectCores(), seed = 11)
# b11M08a <- brms::add_criterion(b11M08a, criterion = c("waic", "loo"))
# saveRDS(b11M08a, file = a_file)
summary(b11M08a)
```

and the fit *excluding* Hawaii is



```{r}
dh <- d %>%
  filter(culture != "Hawaii")
a_file <- here::here(getwd(),"fits", "b11M08b.rds")
b11M08b <- readRDS(a_file)
# b11M08b <- brm(data = dh,
#              family = poisson,
#              formula = bf(total_tools ~ a + b * log_pop_s,
#                           a + b ~ 0 + cid,
#                           nl = TRUE),
#              prior = c(prior(normal(3, 0.5), nlpar = a),
#                        prior(normal(0, 0.2), nlpar = b)),
#              cores = detectCores(), seed = 11)
# b11M08b <- brms::add_criterion(b11M08b, criterion = c("waic", "loo"))
# saveRDS(b11M08b, file = a_file)
summary(b11M08b)
```

Conclusion: The impact is on the factor *low* which has a lower cluster factor
of 3.18 without Hawaii vs 3.32 with Hawaii.  The effect without Hawaii is also
lower with 0.19 vs 0.38 with Hawaii.

It is important ot note that these differences are relative, as described in
section 10.2.4 of chapter 10.

## 11H1 {-}


